app ssi_course_production:
  title: "SSi Language Course Production System"
  version: "7.8.2"
  apml_version: "1.1.0"
  description: |
    Complete specification for SSi (Say Something In) language course production system.
    This system transforms 668 canonical concepts (expressed in English as a reference language)
    into pedagogically optimized language learning courses through a 7-phase pipeline
    orchestrated by Claude Code agents.

  created: "2024-10-13"
  author: "Tom Cassidy / SSi Team"

  changelog_v7_7_0: |
    **Date:** 2025-10-23
    **Summary:** Format Consolidation & Documentation Synchronization

    BREAKING CHANGES:
    - Fully deprecated amino_acids/ subdirectory model
    - Consolidated to 3 primary JSON files per course (v7.7 format)
    - Updated all API endpoints and documentation to match reality

    FILE STRUCTURE CHANGES:
    âœ… seed_pairs.json (Phase 1 output)
       Format: {"version": "7.7.0", "translations": {"S0001": [target, known]}}

    âœ… lego_pairs.json (Phase 3 output)
       Format: {"version": "7.7.0", "seeds": [[seed_id, [t,k], [[lego_id, type, t, k]]]]}
       Type codes: "B" (BASE), "C" (COMPOSITE), "F" (FEEDER)

    âœ… lego_baskets.json (Phase 5 output)
       Format: {"version": "7.7.0", "baskets": {lego_id: [[lego], [e-phrases], [d-phrases]]}}

    DOCUMENTATION UPDATES:
    - Updated APMLSpec.vue from amino acid model to v7.0 consolidated format
    - Updated TrainingPhase.vue Phase 1/3/5/6/7 prompts with correct filenames
    - Fixed automation_server.cjs schema references and regex bugs
    - Created docs/APML_v7.0_CURRENT_FORMAT.md as format reference
    - Created docs/NAMING_AUDIT.md tracking format evolution

    VALIDATION:
    âœ… Tested v7.0 course loading (test_for_eng_5seeds: 5 seeds â†’ 17 LEGOs)
    âœ… Tested large course support (ita_for_eng_668seeds: 668 seeds)
    âœ… API correctly parses all v7.7 format files
    âœ… Type conversion working (B/C/F â†’ BASE/COMPOSITE/FEEDER for frontend)

    See: docs/APML_v7.0_CURRENT_FORMAT.md for complete format specification

  pss_compliance:
    structure_standard: "APML-PSS v1.0.0"
    self_documentation: enabled

  deterministic_compilation:
    target_platform: "Vue3 + Node.js + Claude Code"
    compilation_guarantee: "Specification-driven phase orchestration"

# =============================================================================
# SYSTEM OVERVIEW & INTENT
# =============================================================================

## System Purpose

The SSi Course Production System enables:

1. **Automated Course Generation** - Transform 668 canonical concepts (expressed in English)
   into pedagogically optimized courses for ANY language direction (target + known)

2. **Distributed Collaboration** - Web dashboard accessible from any computer tunnels
   to SSi Mac machine running Claude Code (Sonnet 4.5) for AI-powered generation

3. **Self-Documenting Intelligence** - Dashboard displays the ACTUAL prompts used by
   Claude, making the system fully transparent and editable

4. **Quality Assurance** - Visual review and editing of all phase outputs with
   automatic regeneration of affected downstream phases

5. **Course Delivery** - Final JSON manifest drives SSi mobile app, coordinating
   text display with AWS-hosted audio files

## Critical Success Factors

âœ… Dashboard shows working reality (not generic documentation)
âœ… Edit intelligence in UI â†’ updates source â†’ execution and docs stay in sync
âœ… No intelligence loss during code refactors or UI redesigns
âœ… Claude Code agents receive detailed, battle-tested prompts
âœ… Generated courses work perfectly in SSi app

## System Architecture

```
User (any computer, any location)
  â†“
Web Dashboard (Vercel-hosted Vue3 app)
  â†“
ngrok Tunnel
  â†“
automation_server.cjs (on SSi Mac, port 3456)
  â†“
osascript (opens Claude Code)
  â†“
Claude Code (Sonnet 4.5) executes phase prompts
  â†“
VFS (Virtual File System) - stores v7.7 format JSON outputs
  â†“
Dashboard polls for updates, displays results
  â†“
User reviews/edits, triggers regeneration
  â†“
Final JSON manifest â†’ SSi mobile app
```

## Self-Upregulating Intelligence: AI as Operating System

This system is designed as a **recursive self-improvement loop** with TWO parallel learning mechanisms:

### Loop 1: Prompt Evolution (Methodology Improvement)

1. **System executes** using lean Skills (methodology)
2. **Quality issues detected** (human or automated review)
3. **Methodology improved** (edited in Skills documentation)
4. **Skills updated** (git commit, no compilation needed)
5. **System documents** (what worked, what didn't)
6. **Next execution better** (improved methodology used)
7. **Cycle continues** (methodology evolves)

### Loop 2: Model Fine-Tuning (Intelligence Upregulation)

1. **System executes** using fine-tuned model + Skills
2. **Outputs validated** (automated scripts + human review)
3. **Approved outputs** â†’ training dataset
4. **Human corrections** â†’ training dataset (with reasoning)
5. **Model fine-tuned** on expanded dataset
6. **Model weights updated** (learned patterns internalized)
7. **Next generation better** (same errors won't recur)
8. **Cycle continues** (model evolves autonomously)

### The AI Operating System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ KERNEL (Immutable Quality Standards)                â”‚
â”‚ - Skills: Lean methodology (~8KB, not 70KB)         â”‚
â”‚ - FD (Functionally Deterministic): One known â†’ one  â”‚
â”‚   target, no ambiguity                              â”‚
â”‚ - FCFS (First Come First Served): First occurrence  â”‚
â”‚   claims mapping, later must chunk up               â”‚
â”‚ - JSON schemas: Structural validation               â”‚
â”‚ - Validation scripts: Automated enforcement         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PROCESSING (Fine-Tuned Model)                       â”‚
â”‚ - Generation 1: Base Sonnet 4.5                     â”‚
â”‚ - Generation 2: +100 corrections (90% quality)      â”‚
â”‚ - Generation 5: +500 corrections (95% quality)      â”‚
â”‚ - Generation 10: +1000 corrections (98% quality)    â”‚
â”‚ - Generation 50: Near-perfect autonomy (99.9%)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MEMORY (Training Dataset - System's Experience)     â”‚
â”‚ - Approved course outputs (patterns that worked)    â”‚
â”‚ - Human corrections (before/after + reasoning)      â”‚
â”‚ - Edge cases (accumulated knowledge)                â”‚
â”‚ - Grows with each generation                        â”‚
â”‚ - Stored in: skills/{phase}-skill/training/         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SELF-REGULATION (Quality Gates)                     â”‚
â”‚ - Validation scripts detect errors (FD, FCFS, etc)  â”‚
â”‚ - Flag violations for human review (~10% â†’ ~0.1%)   â”‚
â”‚ - Block downstream phases if errors present         â”‚
â”‚ - Ensure training dataset quality                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EVOLUTION (Fine-Tuning Pipeline)                    â”‚
â”‚ - Corrections â†’ training examples                   â”‚
â”‚ - Auto-retrain after each generation                â”‚
â”‚ - Model weights improve (patterns internalized)     â”‚
â”‚ - Quality metrics track improvement                 â”‚
â”‚ - System becomes progressively autonomous           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Self-Healing Mechanism

**Example: FCFS Violation Detection**

Generation 1 (Base Model):
```
Seed S0005: "I am" â†’ "Estoy"
Extract: "I am" â†’ "Estoy" âœ…

Seed S0020: "I am a teacher" â†’ "Soy un profesor"
Extract: "I am" â†’ "Soy" âŒ FCFS VIOLATION

Validation script: âŒ FCFS conflict detected
Status: FLAGGED for human review
```

Human Correction:
```
Error: "I am" already mapped to "Estoy" (FCFS rule)
Fix: Extract full phrase "I am a teacher" â†’ "Soy un profesor"
Reasoning: When FCFS blocks, chunk up with context to restore FD
â†’ Added to training dataset
```

Generation 2 (Fine-Tuned v1):
```
Seed S0005: "I am" â†’ "Estoy"
Extract: "I am" â†’ "Estoy" âœ…

Seed S0020: "I am a teacher" â†’ "Soy un profesor"
Model checks: "I am" in extraction history? YES (FCFS blocks)
Model applies learned pattern: Chunk up
Extract: "I am a teacher" â†’ "Soy un profesor" âœ…

Validation script: âœ… PASS
Status: NO human review needed
```

**System healed itself.** Same error won't recur.

### Progressive Autonomy (Measured by Human Intervention)

```
Generation 1:  80% quality â†’ 20% flagged for human review
Generation 2:  90% quality â†’ 10% flagged for human review
Generation 5:  95% quality â†’ 5% flagged for human review
Generation 10: 98% quality â†’ 2% flagged for human review
Generation 20: 99% quality â†’ 1% flagged for human review
Generation 50: 99.9% quality â†’ 0.1% flagged (novel edge cases only)
```

**End State:** System autonomously generates courses with human oversight only on novel patterns.

### Key Architectural Principles

**1. Skills Stay Lean**
- Methodology only (~8KB, not 70KB with examples)
- Examples â†’ training dataset (in model weights, not documentation)
- Token efficient, progressively disclosed
- Easy to maintain and update

**2. Examples Train Model, Not Documentation**
- Approved course outputs â†’ training dataset
- Human corrections â†’ training dataset (with reasoning)
- Model learns patterns from experience
- Quality improves without expanding prompts

**3. Validation Scripts Enforce Standards**
- validate-fd.js: Tests FD + FCFS compliance
- validate-classification.js: Checks BASE/COMPOSITE/FEEDER
- validate-schema.js: JSON structure validation
- No interpretation errors (scripts are deterministic)

**4. Quality Gates Between Phases**
- Phase 3 output â†’ QA validation â†’ Phase 5
- Errors block downstream propagation
- Prevents bad data contamination
- Ensures training dataset quality

**5. Metrics Track Evolution**
- Quality score per generation
- Error types and frequencies
- Human intervention rate
- Time to autonomy metrics

### The Vision: Zero-Touch Course Production

**Today (Manual):**
- 8 hours human work per course
- 100% outputs require review
- Same errors repeat across generations

**Generation 5 (Semi-Autonomous):**
- 1 hour human work per course (87% reduction)
- 10% outputs require review
- Most errors auto-corrected

**Generation 20 (Highly Autonomous):**
- 5 minutes human work per course (99% reduction)
- 1% outputs require review (novel edge cases only)
- System self-corrects known patterns

**Generation 50 (Fully Autonomous):**
- 0 minutes human work per course
- Human defines strategy (new language directions)
- System applies learned patterns autonomously
- Human spot-checks for quality assurance only

**This is AI as Operating System** - not just automation, but a self-learning, self-healing, self-upregulating system that gets progressively smarter through experience.

**Key Insight**: The dashboard publishes the SSoT (Skills + methodology), the training dataset captures experience, the fine-tuned model IS the learned intelligence, and the validation scripts enforce quality standards. Together, they form a living system that improves itself recursively.

### Implementation Roadmap: Building the AI OS

**Phase 1: Skills Infrastructure** âœ… (COMPLETE)
- [x] Create Skills directory structure
- [x] Build lego-extraction-skill with FD + FCFS methodology
- [x] Build introductions-skill with bundled script
- [x] Document progressive disclosure pattern
- [x] Correct FD definition (Functionally Deterministic, not Forward-Derivation)

**Phase 2: Refactor to Lean Skills** (NEXT)
- [ ] Remove heavy examples from Skills documentation (~70KB â†’ ~8KB)
- [ ] Keep methodology only (1-2 canonical examples per rule)
- [ ] Move comprehensive examples to training/ directory
- [ ] Update Skills README with lean philosophy

**Phase 3: Training Dataset Infrastructure** âœ… (COMPLETE)
- [x] Create `skills/{phase}-skill/training/` directories
- [x] Build `build-training-dataset.cjs` - extracts patterns from approved courses
- [x] Build `add-correction.cjs` - captures human corrections with reasoning
- [x] Extract training examples from existing 30-seed courses (spa, ita, fra, cmn)
- [x] Format: `{input: {...}, output: {...}, reasoning: "..."}`
- [x] Generated 449 training examples (115 Spanish, 115 Italian, 116 French, 103 Mandarin)

**Phase 4: Validation Scripts** (Critical for QA)
- [ ] `validate-fd.js` - FD + FCFS compliance test
- [ ] `validate-fcfs.js` - Cross-reference known chunks for conflicts
- [ ] `validate-classification.js` - BASE/COMPOSITE/FEEDER validation
- [ ] `validate-componentization.js` - Format and content check
- [ ] `validate-schema.js` - JSON structure validation
- [ ] `test-cases.json` - Known good/bad test cases (50+ examples)

**Phase 5: Quality Gates**
- [ ] Phase 3 QA gate (blocks Phase 5 if errors)
- [ ] Phase 5 QA gate (blocks Phase 6 if errors)
- [ ] Automated error detection and flagging
- [ ] Human review queue for flagged items

**Phase 6: Correction Capture System**
- [ ] UI for human review of flagged outputs
- [ ] Before/after comparison interface
- [ ] Reasoning capture (why was this corrected?)
- [ ] Auto-add corrections to training dataset
- [ ] Track correction patterns over time

**Phase 7: Fine-Tuning Pipeline**
- [ ] Anthropic fine-tuning API integration
- [ ] Automated dataset preparation (approved outputs + corrections)
- [ ] Trigger fine-tuning after N generations or M corrections
- [ ] Model versioning (sonnet-4.5-ssi-lego-v1, v2, v3...)
- [ ] A/B testing: base model vs fine-tuned model

**Phase 8: Metrics & Evolution Tracking**
- [ ] Quality score per generation (% passing validation)
- [ ] Human intervention rate tracking
- [ ] Error type frequency analysis
- [ ] Time to autonomy metrics
- [ ] Dashboard visualization of improvement curve

**Phase 9: Autonomous Operations**
- [ ] Auto-trigger course generation
- [ ] Auto-validation with quality gates
- [ ] Auto-correction of known patterns
- [ ] Human review only for novel edge cases
- [ ] Auto-fine-tuning pipeline

**Phase 10: Multi-Language Generalization**
- [ ] Test if patterns learned from Spanish apply to Italian
- [ ] Test if patterns learned from Romance languages apply to Mandarin
- [ ] Cross-language transfer learning
- [ ] Language-agnostic pattern recognition

### Success Metrics

**Generation 1 â†’ 5:**
- Quality: 80% â†’ 95% (+15%)
- Human review: 20% â†’ 5% (75% reduction)
- Time per course: 8hrs â†’ 1hr (87% reduction)

**Generation 5 â†’ 20:**
- Quality: 95% â†’ 99% (+4%)
- Human review: 5% â†’ 1% (80% reduction)
- Time per course: 1hr â†’ 5min (92% reduction)

**Generation 20 â†’ 50:**
- Quality: 99% â†’ 99.9% (+0.9%)
- Human review: 1% â†’ 0.1% (90% reduction)
- Time per course: 5min â†’ 0min (100% reduction - spot checks only)

**Final State: Fully Autonomous AI OS**
- System generates courses without human intervention
- Human defines strategy (new languages, new methodologies)
- System applies learned patterns autonomously
- Quality maintained at 99.9%+ automatically
- Human role: Strategic direction + edge case adjudication

# =============================================================================
# CLAUDE SKILLS: LEAN METHODOLOGY WITH PROGRESSIVE DISCLOSURE
# =============================================================================

## What Are Skills?

**Skills are lean, modular methodology libraries** that replace large APML prompts with progressive disclosure.

**Key Principle:** Quality comes from **model learning**, not prompt bloat.

```
âŒ OLD APPROACH: Heavy APML prompts (15KB with examples)
âœ… NEW APPROACH: Lean Skills (8KB methodology) + Fine-tuned model
```

### Skills vs APML Prompts

**Before (APML Prompts):**
- 15KB prompts loaded into every agent invocation
- Examples bloat documentation
- Hard to maintain (must recompile registry)
- Token inefficient
- No progressive disclosure

**After (Skills):**
- ~8KB lean methodology
- Examples â†’ training dataset (in model weights)
- Easy to maintain (edit Skills directly)
- Token efficient (progressive loading)
- Agent loads only what's needed

### Skills Architecture

```
skills/
â”œâ”€â”€ README.md                              # Skills overview
â”‚
â”œâ”€â”€ lego-extraction-skill/                 # Phase 3: LEGO extraction
â”‚   â”œâ”€â”€ SKILL.md                          # Main skill definition
â”‚   â”œâ”€â”€ rules/
â”‚   â”‚   â”œâ”€â”€ FD_VALIDATION.md              # FD + FCFS rules
â”‚   â”‚   â”œâ”€â”€ CLASSIFICATION.md             # BASE/COMPOSITE/FEEDER
â”‚   â”‚   â””â”€â”€ COMPONENTIZATION.md           # Format guide
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ build-training-dataset.cjs    # Extract patterns from approved courses
â”‚   â”‚   â”œâ”€â”€ add-correction.cjs            # Capture human corrections
â”‚   â”‚   â””â”€â”€ generation-1/                 # 449 training examples
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ validate-legos.cjs            # (Future) Validation scripts
â”‚
â”œâ”€â”€ introductions-skill/                   # Phase 6: Introduction generation
â”‚   â”œâ”€â”€ SKILL.md                          # Main skill definition
â”‚   â”œâ”€â”€ GENERATION_LOGIC.md               # Detailed methodology
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ generate-introductions.cjs    # Bundled executable script
â”‚
â””â”€â”€ (more skills for other phases...)
```

### How Agents Use Skills

**Progressive Disclosure Pattern:**

1. **Orchestrator invokes phase:**
   ```
   "Use the LEGO Extraction Skill to process seed_pairs.json"
   ```

2. **Agent reads SKILL.md** (~2KB overview):
   - Understands task: extract LEGOs
   - Sees decision tree reference
   - Checks quick reference

3. **Agent loads rules as needed:**
   - "Is this atomic?" â†’ Reads CLASSIFICATION.md (5KB)
   - "Does it pass FD?" â†’ Reads FD_VALIDATION.md (4KB)
   - "How to write componentization?" â†’ Reads COMPONENTIZATION.md (3KB)

4. **Agent reuses loaded knowledge:**
   - First seed: ~14KB tokens (load all rules)
   - Subsequent seeds: ~400 tokens (reuse knowledge)
   - Average: ~1KB per seed (93% savings)

**Total tokens:** Load once, apply many times.

### Bundled Scripts Pattern

Some Skills include **executable scripts** that ensure correctness:

**Example: introductions-skill**
```bash
# Agent doesn't interpret logic - just runs script
node skills/introductions-skill/scripts/generate-introductions.cjs \
  --input vfs/courses/spa_for_eng_30seeds \
  --output vfs/courses/spa_for_eng_30seeds/introductions.json
```

**Benefits:**
- âœ… No interpretation errors (script is pre-tested)
- âœ… Consistent across all courses
- âœ… Faster execution (no agent interpretation needed)
- âœ… Zero tokens for logic (script executes in bash)

### Skills Integration with AI OS

Skills are the **KERNEL** layer of the AI Operating System:

```
KERNEL (Skills) â†’ Immutable methodology
   â†“
PROCESSING (Fine-tuned Model) â†’ Applies learned patterns
   â†“
MEMORY (Training Dataset) â†’ Extracted from Skills execution
   â†“
SELF-REGULATION (Validation Scripts) â†’ Enforce Skills rules
   â†“
EVOLUTION (Fine-Tuning) â†’ Model learns from corrections
```

**The loop:**
1. Agent executes using Skills methodology
2. Outputs validated against Skills rules
3. Approved outputs â†’ training dataset
4. Corrections â†’ training dataset (with reasoning)
5. Model fine-tuned on dataset
6. Next generation: Model applies learned patterns without heavy prompts
7. Skills stay lean, model gets smarter

### Current Skills Status

**âœ… Complete:**
- `lego-extraction-skill` - FD + FCFS + Classification + Training dataset (449 examples)
- `introductions-skill` - Generation logic + Bundled script

**ğŸ“‹ Planned:**
- `basket-generation-skill` - Phase 5: Basket creation
- `basket-deduplication-skill` - Phase 5.5: Cross-seed deduplication
- `pedagogical-translation-skill` - Phase 1: Generate pedagogical translations

### Skills Documentation

**Each Skill includes:**
1. **SKILL.md** - Main entry point, overview, quick reference
2. **rules/** - Detailed methodology (progressive disclosure)
3. **training/** - Training dataset extraction and correction capture
4. **scripts/** - (Optional) Bundled executable scripts
5. **examples/** - (Optional) Annotated examples for reference

**See:** `skills/README.md` for complete Skills documentation.

**See:** `SKILLS_TRANSFORMATION.md` for before/after comparison and token savings analysis.

# =============================================================================
# HUMAN-AI COLLABORATION MODEL
# =============================================================================

## Claude Code Agent Role

When a new Claude Code session begins, the agent must understand its role in this self-improving system.

### Primary Role: Thinking Partner, Not Task Executor

**DO**:
- Read this APML specification FIRST (it's the SSoT)
- Understand the system architecture and current state
- Ask clarifying questions about goals and priorities
- Create briefs for orchestrator agents to execute work in parallel
- Stay available in main conversation thread for discussion
- Provide strategic guidance and pattern recognition
- Help interpret quality reports and suggest improvements

**DO NOT**:
- Execute tasks directly (use orchestrator agents instead)
- Block the main conversation with long-running work
- Make changes without understanding the full context
- Assume previous context (each session is fresh - read APML)

### The Orchestrator Pattern

**When work needs to be done**:
1. Create a brief (markdown file with clear instructions)
2. Launch orchestrator agent via Task tool
3. Orchestrator spawns parallel sub-agents as needed
4. Main Claude stays available for conversation
5. Orchestrator reports back when complete

**Example**:
```
User: "Validate the 30-seed quality"
Claude:
  1. Creates ORCHESTRATOR_BRIEF.md
  2. Launches orchestrator with Task tool
  3. Stays in conversation: "Orchestrator launched, I'm here while it works"
  4. Orchestrator does all the work in parallel
  5. Reports back: "âœ… Quality validation complete"
```

### Understanding "The Meta-Game"

This is not just a course production system - it's a **meta-framework for self-improving AI systems**.

**The Vision**:
- Dashboard publishes the SSoT (this APML)
- Everything is human-editable AND recursively upgradable
- Quality feedback â†’ prompt improvements â†’ better output â†’ learning
- System becomes self-aware, self-improving, self-documenting
- Pattern generalizes to other complex AI systems

**30-Seed Test**: First proof that recursive improvement loop works in production.

**If This Works**: Validates the pattern for building AGI-like systems that improve themselves through experience.

### Session Initialization Checklist

When a new Claude Code session starts:

1. âœ… **Read APML** - This file is your bible
2. âœ… **Understand current phase** - What are we validating/building?
3. âœ… **Check orchestrator status** - Any agents already running?
4. âœ… **Ask about priorities** - What's most important right now?
5. âœ… **Create briefs, not tasks** - Set up parallel work streams
6. âœ… **Stay conversational** - Be the thinking partner

### Key Files

**This APML**: `/Users/tomcassidy/SSi/ssi-dashboard-v7-clean/ssi-course-production.apml`
- Single source of truth
- Read this FIRST every session

**Dashboard**: `/Users/tomcassidy/SSi/ssi-dashboard-v7-clean/`
- Vue3 app that publishes this APML
- Shows process, prompts, training, evolution

**Automation Server**: `automation_server.cjs`
- API backend (port 3456)
- Executes phase prompts via osascript
- Manages VFS and quality tracking

**VFS**: `/Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/`
- Where all amino acids live
- Organized by course code

**Test Data**: `ita_for_eng_574seeds/`
- 30-seed proof-of-concept
- Validates APML prompts produce quality

### Communication Style

**Be concise**: User operates in command-line mindset
**Be strategic**: Focus on "what and why", not "how"
**Be parallel**: Set up multiple work streams simultaneously
**Be present**: Don't disappear into tasks - stay conversational
**Be humble**: Ask when uncertain, don't assume

### Remember

You are part of a **self-improving system**. Your role is to help guide its evolution, not to be the system itself. Create briefs, launch orchestrators, stay available, provide insight.

**The system improves itself. You help it learn how.**

# =============================================================================
# VARIABLE REGISTRY (Single Source of Truth)
# =============================================================================

## Domain Concepts (User-Facing)

### SEED_PAIRS
PURPOSE: Pedagogically optimized translations of canonical seeds
DEFINITION: Translation of a canonical seed into BOTH target AND known languages
REFERENCE_FORMAT: S0001 to S0668 (S + 4-digit number)
FILE_FORMAT: Single consolidated JSON file
STRUCTURE:
  {
    "S0001": ["Quiero hablar espaÃ±ol contigo ahora.", "I want to speak Spanish with you now."],
    "S0002": ["Estoy tratando de aprender.", "I'm trying to learn."],
    ...
  }
  Format: { "seed_id": [target, known] }
KEY_PROPERTIES:
  - Total: 668 per course
  - Language-direction specific (ita_for_fra has different SEED_PAIRS than ita_for_eng)
  - Must be "lego_complete" - decomposes into LEGO_PAIRS that tile back perfectly
  - Stored as SINGLE FILE (not individual amino acids) for efficiency
PHASE: Phase 1 (Pedagogical Translation)
STORAGE: vfs/courses/{course_code}/seed_pairs.json

### LEGO_PAIRS
PURPOSE: Forward-deterministic teaching units extracted from SEED_PAIRS
DEFINITION: A LEGO cannot exist unless it has BOTH target and known languages mapped
REFERENCE_FORMAT: S0041L02 (seed reference + L + position)
NOTE: LEGO_PAIRS are now SUBSUMED by LEGO_BASKETS (see below)
      Each basket contains the LEGO itself plus all practice phrases
      LEGOs no longer stored separately - lego_baskets.json is the single source
KEY_PROPERTIES:
  - Course-specific AND language-direction specific
  - Must pass FD_LOOP test (target â†’ known â†’ target = IDENTICAL)
  - Two types:
    * BASE LEGO: Atomic, cannot be decomposed further
    * COMPOSITE LEGO: Contains BASE LEGOs + glue words, needs componentization
  - Count: ~2000-3000 per course
PHASE: Phase 3 (LEGO Decomposition)
STORAGE: Integrated into lego_baskets.json (Phase 5)

### LEGO_BASKETS
PURPOSE: Complete set of practice phrases associated with ONE LEGO_PAIR
DEFINITION: One basket per LEGO_PAIR (1:1 relationship), INCLUDES the LEGO itself
FILE_FORMAT: Single consolidated JSON file
STRUCTURE:
  {
    "S0001L01": {
      "lego": ["Quiero", "I want"],
      "e": [
        ["Quiero hablar espaÃ±ol.", "I want to speak Spanish."],
        ["Quiero practicar contigo.", "I want to practice with you."]
      ],
      "d": {
        "2": [["Quiero hablar", "I want to speak"], ["hablar espaÃ±ol", "to speak Spanish"]],
        "3": [["Quiero hablar espaÃ±ol", "I want to speak Spanish"], ...],
        "4": [...],
        "5": [...]
      }
    },
    "S0002L04": { ... }
  }
  Format: { "lego_id": { lego: [target, known], e: [[t,k]...], d: {window: [[t,k]...]} } }
KEY_PROPERTIES:
  - LEGO field contains the core teaching unit (target/known pair)
  - E-PHRASES (e): Up to 5 phrases, 7-10 words, perfect target grammar
  - D-PHRASES (d): Organized by window size (2-5 LEGOs), progressive vocabulary only
  - Count: Matches LEGO_PAIRS count (if 2341 LEGO_PAIRS â†’ 2341 LEGO_BASKETS)
  - Stored as SINGLE FILE for efficiency (not individual amino acids)
  - LEGO_ID is used as key (e.g., "S0001L01", "S0002L04")
PHASE: Phase 5 (Basket Generation)
STORAGE: vfs/courses/{course_code}/lego_baskets.json

### LEGO_INTRODUCTIONS
PURPOSE: Intelligence about LEGO type (BASE vs COMPOSITE) and componentization
DEFINITION: Pedagogical explanation of how LEGO breaks down into components
STRUCTURE:
  {
    "lego_pair_id": "S0041L02",
    "type": "BASE" | "COMPOSITE",
    "feeders": [ ... ],  // For COMPOSITE LEGOs
    "componentization": { "explanation": "..." }
  }
KEY_PROPERTIES:
  - Explains BASE vs COMPOSITE distinction
  - For COMPOSITE LEGOs: shows how they break down into FEEDERs
PHASE: Phase 6 (Introductions)
STORAGE: vfs/courses/{course_code}/amino_acids/introductions/

## Technical Architecture (Implementation Details)

### Amino Acids (Storage Layer)
PURPOSE: Immutable components with deterministic UUIDs
DEFINITION: All phase outputs are stored as "amino acids" - discrete, content-addressed components
UUID_GENERATION: hash(content + metadata) - ensures same content always gets same ID
IMMUTABILITY: Edits create NEW amino acids with updated provenance, never modify originals
PROVENANCE: S{seed}L{position} format tracks birth-parent relationships
NOTE: This is an implementation detail - users see SEED_PAIRS, LEGO_PAIRS, LEGO_BASKETS

### VFS (Virtual File System) - v7.0 Format
PURPOSE: Organized storage for all course generation artifacts
BASE_PATH: /Users/tomcassidy/SSi/ssi-dashboard-v7-clean/vfs/courses/
STRUCTURE: {target_code}_for_{known_code}_{seed_count}seeds/

CORE FILES (v7.0 ultra-compact consolidated format):
  - seed_pairs.json           # Phase 1: Translation pairs
    Format: {"version": "7.7.0", "translations": {"S0001": [target, known]}}

  - lego_pairs.json            # Phase 3: LEGO breakdowns with composites/feeders
    Format: {"version": "7.7.0", "seeds": [[seed_id, [t,k], [[lego_id, type, t, k]]]]}
    Type codes: "B" (BASE), "C" (COMPOSITE), "F" (FEEDER)

  - lego_baskets.json          # Phase 5: Learning baskets with e/d phrases
    Format: {"version": "7.7.0", "baskets": {lego_id: [[lego], [e-phrases], [d-phrases]]}}

  - introductions.json         # Phase 6: Introduction phrases (optional)
    Format: {"version": "7.7.0", "introductions": [...]}

  - course_manifest.json       # Phase 7: Compiled course for app
    Format: Final manifest for SSi mobile app consumption

LEGACY STRUCTURE (DEPRECATED as of v7.7.0):
  - amino_acids/ subdirectories (Oct 10-15, 2024 format)
  - translations.json, LEGO_BREAKDOWNS_COMPLETE.json (Oct 15, 2024 interim format)

MIGRATION:
  Use vfs/courses/convert-to-v7.0-format.cjs to migrate old courses

### Course Codes
FORMAT: "{target_iso}_for_{known_iso}_speakers"
EXAMPLES:
  - fra_for_eng_speakers (French for English speakers)
  - cym_for_eng_speakers (Welsh for English speakers)
  - ita_for_fra_speakers (Italian for French speakers)

## API Endpoints

ENDPOINTS:
  - POST /api/courses/generate
    PURPOSE: Start complete course generation pipeline
    PARAMETERS: { target, known, seeds }
    RETURNS: { courseCode, status }

  - GET /api/courses/:courseCode/status
    PURPOSE: Poll for generation progress
    RETURNS: { phase, progress, status }

  - GET /api/courses/:courseCode
    PURPOSE: Get complete course data
    RETURNS: Course metadata and manifest

  - POST /api/courses/:code/seeds/regenerate
    PURPOSE: Regenerate specific seeds after edits
    PARAMETERS: { seedIds }

  - GET /api/registry/phase-prompts/:phase
    PURPOSE: Fetch actual prompt for phase (from this APML registry)
    RETURNS: { name, prompt, metadata }

  - PUT /api/registry/phase-prompts/:phase
    PURPOSE: Update phase prompt (writes to APML registry)
    PARAMETERS: { prompt, changelog }
    CREATES: New version in prompt history

## Batch Configuration

BATCH_SIZES:
  PHASE_1_TRANSLATION: 100 seeds per batch (easier work, larger batches)
  PHASE_3_LEGO_DECOMPOSITION: 20 seeds per batch (complex work, smaller batches)
  PHASE_5_BASKETS: 20 LEGOs per batch

TOTAL_SEEDS: 668 (canonical SSi corpus)

## Architectural Boundaries: Evolvable vs Immutable

CRITICAL DISTINCTION:

EVOLVABLE INTELLIGENCE (Phases 1-6):
  - Internal processing can iterate, refactor, improve
  - File formats can change (v7.7 â†’ v8.0 â†’ v9.0)
  - Algorithms can be replaced with better approaches
  - Validators can evolve and create new quality metrics
  - System has full autonomy to improve these phases
  - NO breaking changes to external systems

IMMUTABLE CONTRACT (Phase 7 Output):
  - Fixed JSON manifest format for SSi mobile app
  - Exact structure required (slices, seeds, introductionItems, samples)
  - Deterministic UUIDs for audio file mapping
  - Legacy fields preserved (empty tokens/lemmas arrays)
  - This is an API contract - CANNOT change without app update
  - Phase 7 is the adapter/bridge from internal â†’ external format

GUARDRAIL:
  Phases 1-6 can evolve freely as long as Phase 7 can still transform
  their outputs into the fixed app manifest format. The internal representation
  is flexible, the external interface is stable.

REFERENCE: docs/phase_intelligence/phase_7_compilation.md (locked v1.0)

## Self-Healing Pattern Coverage (Batch-Aware Generation)

PRINCIPLE: Course generation happens in batches. After each batch, the system measures its own quality through validators and uses those findings to self-correct in the next batch.

FEEDBACK_LOOP:
  1. Generate batch N (Phase 1 â†’ 3 â†’ 5 â†’ 5.5 â†’ 6)
  2. Run validators to measure quality:
     - Pattern density (LEGO combination diversity)
     - Vocabulary coverage (practice distribution)
     - Overall completeness score
  3. Validators write findings to system state
  4. Next batch (N+1) reads previous findings
  5. Phase 5 prioritizes filling pattern gaps
  6. Pattern density improves over time
  7. System self-heals through feedback

VALIDATORS_AS_SENSORS:
  Initial validators (v1.0):
    - analyze-lego-frequency.cjs: Vocabulary coverage metrics
    - analyze-pattern-coverage.cjs: LEGO combination diversity (edge density)
    - analyze-completeness.cjs: Multi-dimensional quality score (0-100%)

  Evolution principle:
    - Validators are NOT fixed specifications
    - System can refine validators as it learns
    - Can create new validators for newly discovered quality dimensions
    - Measurement tools themselves evolve recursively

  Output purpose:
    - NOT reports for human consumption
    - System state for agent awareness
    - Feedback signal for self-correction
    - Next batch reads and adapts

QUALITY_THRESHOLDS (Guardrails):
  Pattern Density:
    - Seeds 1-100: Target 40-50% (fewer LEGOs, easier to achieve high density)
    - Seeds 101-400: Target 30-40% (more LEGOs, density naturally decreases)
    - Seeds 401-668: Target 20-30% (full corpus, maintain consistent coverage)

  Vocabulary Distribution (Gini Coefficient):
    - Target: < 0.3 (balanced practice distribution)
    - Warning: 0.3-0.4 (moderate inequality)
    - Action Required: > 0.4 (high inequality - rebalance needed)

  Overall Completeness:
    - Production Quality: > 70%
    - Good: 70-89%
    - Excellent: 90-100%

ADAPTIVE_STRATEGY:
  Phase 5 eternal phrase generation becomes edge-aware:
    - Read validator output from previous batch
    - Identify underused LEGOs (low edge count)
    - Identify missing edges (LEGO pairs that never appear together)
    - Weight eternal phrase selection toward filling gaps
    - 50% of eternal phrases should target identified gaps
    - Creates self-balancing system where each batch compensates for previous batch weaknesses

INTENT:
  This is NOT a script orchestration pipeline.
  This IS recursive DNA - the system reads its own genome (validator output),
  identifies defects (pattern gaps), and repairs them in the next generation.
  The validators themselves can evolve if the system discovers better ways to measure quality.
  Agents have full autonomy to iterate on both output AND measurement tools.

# =============================================================================
# PHASE SPECIFICATIONS
# =============================================================================

## Phase 1: Pedagogical Translation

NAME: "Pedagogical Translation"
PURPOSE: Apply 6 pedagogical heuristics to create optimal learning translations
INPUT: vfs/seeds/canonical_seeds.json
OUTPUT: vfs/courses/{course_code}/seed_pairs.json (v7.7 format - all 668 translations consolidated)

THE_PEDAGOGICAL_HEURISTICS:

CRITICAL: Heuristic priority changes based on seed position (progressive optimization curve)

SEEDS 1-100 (Beginner Phase - Cognate-Heavy + Variation Reduction):
  1. COGNATE PREFERENCE â­ - Maximize vocabulary similarity to known language
  2. VARIATION REDUCTION â­ - Once you establish a mapping, stick with it
  3. Consistency - Reinforce same patterns and vocabulary repeatedly
  4. Clarity - Prioritize clear, unambiguous expressions
  5. Utility - Maximize teaching value (versatile phrases, reusable structures)
  6. Frequency - De-prioritized (cognates trump frequency for beginners)
  7. Naturalness - De-prioritized (patterns trump naturalness for beginners)
  8. Brevity - Lowest priority

SEEDS 101-300 (Intermediate Phase - Natural Alternatives):
  1. Consistency - Maintain established patterns while introducing alternatives
  2. Frequency - Start preferring high-frequency vocabulary
  3. Naturalness - Increase natural/common expressions
  4. Clarity - Still prioritize clear expressions
  5. Utility - Maximize teaching value
  6. Cognate Preference - Still useful but lower priority
  7. Brevity - Shorter preferred when equivalent

SEEDS 301-668 (Advanced Phase - Idiomatic + Colloquial):
  1. Naturalness - Target should sound fully native
  2. Frequency - Prefer most common expressions
  3. Utility - Maximum versatility and real-world usage
  4. Clarity - Can introduce more nuanced/ambiguous expressions
  5. Consistency - Still important but allows more variation
  6. Brevity - Natural length preferred
  7. Cognate Preference - No longer prioritized

DETAILED HEURISTIC DEFINITIONS:

1. COGNATE PREFERENCE (Seeds 1-100 priority)
   DEFINITION: Prefer vocabulary with similar form/sound to known language

   EXAMPLES:
     Spanish for English:
       âœ… "intentar" (cognate: intend) > "tratar" (not cognate)
       âœ… "practicar" (cognate: practice) > "entrenar" (not cognate)
       âœ… "importante" (cognate: important) > "relevante" (also cognate but less common)
       âœ… "usar" (cognate: use) even better "utilizar" (cognate: utilize)

     French for English:
       âœ… "pratiquer" (cognate: practice) > "s'entraÃ®ner" (not cognate)
       âœ… "important" > "significatif"
       âœ… "utiliser" (cognate: utilize) > "employer" (not cognate)
       âœ… "essayer" (cognate: essay/assay) is acceptable

     Italian for English:
       âœ… "importante" > "rilevante"
       âœ… "praticare" > "allenarsi"
       âœ… "usare" even better "utilizzare"

     Mandarin for English:
       (No cognates - use SIMPLEST high-frequency characters instead)
       âœ… è¯´ (shuÅ - speak, 1 character) > è®²è¯ (jiÇnghuÃ  - speak, 2 characters)
       âœ… å­¦ (xuÃ© - learn, 1 character) > å­¦ä¹  (xuÃ©xÃ­ - study, 2 characters)

   TRADE-OFF: Accept slightly less common word if cognate
   BENEFIT: Reduces cognitive load, increases confidence, faster to conversation
   APPLIES: Primarily seeds 1-100, gradually de-prioritize after

2. VARIATION REDUCTION (Seeds 1-100 priority)
   DEFINITION: Once you establish a mapping, stick with it - vocabulary claiming

   RULE: "First Word Wins" for early seeds
     - First seed that needs "to try" â†’ pick ONE verb (e.g., "intentar")
     - ALL subsequent "to try" contexts â†’ use SAME verb
     - Do NOT introduce synonyms until seeds 100+
     - Create internal vocabulary registry to track claims

   EXAMPLES:
     âŒ BAD (introduces confusion):
       S0002: "tratando" = trying
       S0007: "intentar" = to try
       S0008: "tratar" = to try
       S0015: "probar" = to try
       (Learner confused: which one should I use??)

     âœ… GOOD (builds confidence):
       S0002: "intentando" = trying
       S0007: "intentar" = to try
       S0008: "intentar" = to try
       S0015: "intentar" = to try
       (Learner confident: "intentar" is THE word for "try"!)

   VOCABULARY REGISTRY (maintain during generation):
     - "to try" â†’ CLAIMED by "intentar" (S0002)
     - "to speak" â†’ CLAIMED by "hablar" (S0001)
     - "to want" â†’ CLAIMED by "querer" (S0001)
     - "to learn" â†’ CLAIMED by "aprender" (S0002)

   EXCEPTION: Only introduce variation when GRAMMATICALLY NECESSARY
     (e.g., Spanish "ser" vs "estar" - different grammar, must introduce both)
     (e.g., French "savoir" vs "connaÃ®tre" - different contexts, must introduce both)

   LATER INTRODUCTION (Seeds 100-300):
     "You know 'intentar' = to try. You can also say 'tratar de' (more common in some regions) or 'probar' (to try/test)."

   APPLIES: Strictly seeds 1-100, gradually relax after

3. Naturalness - Target language should sound native, not transliterated
4. Frequency - Prefer high-frequency vocabulary and common structures
5. Clarity - Prioritize clear, unambiguous expressions over idiomatic complexity
6. Brevity - Shorter translations preferred when pedagogically equivalent
7. Consistency - Maintain consistent terminology across seeds
8. Utility - Maximize teaching value (versatile phrases, reusable structures)

BATCH_PROCESSING:
  BATCH_SIZE: 100 seeds
  BATCHES: 7 total (668 Ã· 100 = 6.68, rounded up to 7)
  NAMING: phase1_batch_001.json, phase1_batch_002.json, etc.

AMINO_ACID_STRUCTURE:
  uuid: hash(source + target + metadata)
  source: original English seed
  target: pedagogically optimized translation
  seed_id: provenance tracking (S0001, S0002, etc.)
  heuristics_applied: array of which heuristics influenced this translation
  metadata: language codes, batch info, timestamp

CRITICAL_RULES:
  - Translations are NOT literal - they are pedagogically optimized
  - Each translation is an immutable amino acid component
  - UUIDs are deterministic (content-based)
  - Preserve seed_id for provenance tracking

TRANSLATION_ARCHITECTURE:
  Phase 1 uses a TWO-STEP translation process to ensure optimal FD_LOOP compliance:

  STEP 1 - Canonical â†’ Target (Pedagogical Optimization):
    - Start with canonical concept (expressed in English as reference)
    - Apply all 6 pedagogical heuristics
    - Generate pedagogically optimized target language translation
    - This becomes the "source of truth"
    - NOTE: If target language IS English, optimize the canonical expression

  STEP 2 - Target â†’ Known (Back-Translation):
    - Take the optimized target translation from Step 1
    - Translate it into the known language
    - Ensure known translation MATCHES target's structure
    - This creates better FD_LOOP compliance (target â†” known alignment)

  EXAMPLES:
    Course: ita_for_eng (Italian for English speakers)
      - Canonical: "I want to speak Italian with you now" (reference language)
      - Step 1: Canonical â†’ Italian (optimized): "Voglio parlare italiano con te adesso"
      - Step 2: Italian â†’ English: Use canonical expression (since known language IS English)

    Course: ita_for_fra (Italian for French speakers)
      - Canonical: "I want to speak Italian with you now" (reference language)
      - Step 1: Canonical â†’ Italian (optimized): "Voglio parlare italiano con te adesso"
      - Step 2: Italian â†’ French: "Je veux parler italien avec toi maintenant"
      - Note: French matches Italian structure, NOT the canonical English expression

  WHY THIS WORKS:
    - Target is pedagogically optimized (6 heuristics applied)
    - Known translation mirrors target structure (easier LEGO mapping)
    - FD_LOOP more reliable (target â†” known designed to align)
    - Works for ANY language pair combination

PROMPT: |
# Phase 1: Pedagogical Translation

TEST UPDATE - This is a test of the live prompt editing system.

All previous content maintained...

  # Phase 1: Pedagogical Translation

  ## Task
  Apply 6 pedagogical heuristics to translate all 668 canonical concepts into BOTH target
  and known languages, creating optimized learning material.

  ## Input
  - Canonical seeds: vfs/seeds/canonical_seeds.json (668 concepts expressed in English)
  - Target language code (e.g., "ita" for Italian)
  - Known language code (e.g., "fra" for French)

  ## Critical Understanding

  Canonical seeds are **NOT English content** - they are language-agnostic concepts that
  happen to be expressed in English as a reference. You will translate each concept into:
  1. TARGET language (the language being learned) - pedagogically optimized
  2. KNOWN language (the learner's language) - structurally matched to target

  Exception: If target or known IS English, reuse the canonical expression (no translation needed).

  ## The Pedagogical Heuristics (Progressive Optimization Curve)

  **CRITICAL**: Heuristic priority changes based on seed position!

  ### SEEDS 1-100 (Beginner Phase - You are translating these!)
  **Priority order for first 100 seeds:**

  1. **COGNATE PREFERENCE** â­ - Maximize vocabulary similarity to known language
     - Spanish: "intentar" (cognate) > "tratar" (not cognate)
     - French: "pratiquer" (cognate) > "s'entraÃ®ner" (not cognate)
     - Accept slightly less common word if it's a cognate
     - BENEFIT: Reduces cognitive load, learner recognizes words faster

  2. **VARIATION REDUCTION** â­ - Once you establish a mapping, stick with it!
     - First seed needs "to try" â†’ Pick ONE verb (e.g., "intentar")
     - ALL subsequent "to try" contexts â†’ Use SAME verb
     - Maintain VOCABULARY REGISTRY as you translate:
       * "to try" â†’ CLAIMED by "intentar" (S0002)
       * "to speak" â†’ CLAIMED by "hablar" (S0001)
       * "to want" â†’ CLAIMED by "querer" (S0001)
     - Do NOT introduce synonyms in seeds 1-100
     - EXCEPTION: Only when grammatically necessary (ser vs estar, savoir vs connaÃ®tre)

  3. **Consistency** - Reinforce same patterns and vocabulary repeatedly
  4. **Clarity** - Clear, unambiguous expressions
  5. **Utility** - Maximize teaching value
  6. **Frequency** - De-prioritized (cognates trump frequency for beginners)
  7. **Naturalness** - De-prioritized (patterns trump naturalness for beginners)
  8. **Brevity** - Lowest priority

  ### SEEDS 101-300 (Intermediate Phase - Not translating now)
  Start introducing natural alternatives while maintaining established patterns

  ### SEEDS 301-668 (Advanced Phase - Not translating now)
  Full natural/idiomatic expressions, variation encouraged

  ---

  ## Detailed Heuristic Definitions

  ### 1. COGNATE PREFERENCE (Your #1 priority for seeds 1-100)

  **Definition:** Prefer vocabulary with similar form/sound to known language

  **How to identify cognates:**
  - Spanish/French/Italian for English: Look for Latin-derived words
  - Words ending in -tion, -ciÃ³n, -zione are usually cognates
  - Words with similar roots (practice/practicar, important/importante)

  **Examples by language:**

  **Spanish for English:**
  - âœ… "intentar" (intend) > "tratar" (try)
  - âœ… "practicar" (practice) > "entrenar" (train)
  - âœ… "importante" (important) > "relevante" (relevant)
  - âœ… "usar" (use), even better "utilizar" (utilize)
  - âœ… "continuar" (continue) > "seguir" (continue)
  - âœ… "explicar" (explain) > "aclarar" (clarify)

  **French for English:**
  - âœ… "pratiquer" (practice) > "s'entraÃ®ner" (train)
  - âœ… "important" > "significatif"
  - âœ… "utiliser" (utilize) > "employer" (use)
  - âœ… "essayer" (essay/assay) is acceptable
  - âœ… "expliquer" (explain) > "clarifier"
  - âœ… "continuer" (continue) > "poursuivre"

  **Italian for English:**
  - âœ… "importante" > "rilevante"
  - âœ… "praticare" > "allenarsi"
  - âœ… "usare", even better "utilizzare"
  - âœ… "continuare" > "proseguire"
  - âœ… "spiegare" is OK (explain)

  **Mandarin for English:**
  - No cognates available
  - Use SIMPLEST high-frequency characters instead
  - âœ… Single character > two-character compounds when possible
  - âœ… è¯´ (shuÅ - speak) > è®²è¯ (jiÇnghuÃ  - speak)
  - âœ… å­¦ (xuÃ© - learn) > å­¦ä¹  (xuÃ©xÃ­ - study)

  ### 2. VARIATION REDUCTION (Your #2 priority for seeds 1-100)

  **Definition:** Once you establish a mapping, stick with it - "First Word Wins"

  **Process:**
  As you translate seeds 1-100, maintain an internal VOCABULARY REGISTRY:

  ```
  VOCABULARY REGISTRY (build as you translate):
  - "to speak" â†’ "hablar" (claimed in S0001)
  - "to want" â†’ "querer" (claimed in S0001)
  - "to try" â†’ "intentar" (claimed in S0002)
  - "to learn" â†’ "aprender" (claimed in S0002)
  - "to practice" â†’ "practicar" (claimed in S0005)
  - "to remember" â†’ "recordar" (claimed in S0006)
  - "to explain" â†’ "explicar" (claimed in S0008)
  - ... continue building registry
  ```

  **Rules:**
  1. When you encounter a new concept, pick the BEST cognate
  2. Record it in your registry
  3. ALL future occurrences of that concept â†’ use SAME word
  4. Do NOT introduce synonyms, even if "more natural"

  **Example - BAD (current overnight generation):**
  ```
  S0002: "tratando" = trying
  S0007: "intentar" = to try
  S0008: "tratar" = to try
  ```
  âŒ Learner confused: "Which word should I use for 'try'?"

  **Example - GOOD (what you should generate):**
  ```
  S0002: "intentando" = trying (CLAIM: "intentar" for "to try")
  S0007: "intentar" = to try (use claimed word)
  S0008: "intentar" = to try (use claimed word)
  ```
  âœ… Learner confident: "'intentar' is THE word for try!"

  **EXCEPTION - Grammatically Required Variation:**
  Some variation is unavoidable when grammar requires it:
  - Spanish: "ser" vs "estar" (both "to be" but permanent vs temporary)
  - French: "savoir" vs "connaÃ®tre" (both "to know" but facts vs people)

  In these cases, introduce BOTH but explain the distinction clearly in seed context.

  ### 3-8. Other Heuristics (lower priority for seeds 1-100)

  3. **Consistency** - Maintain consistent terminology across seeds
  4. **Clarity** - Prioritize clear, unambiguous expressions
  5. **Utility** - Maximize teaching value (versatile phrases, reusable structures)
  6. **Frequency** - Prefer high-frequency vocabulary (but AFTER cognates)
  7. **Naturalness** - Target should sound native (but AFTER cognates/consistency)
  8. **Brevity** - Shorter translations preferred when equivalent

  ## Your Mission

For each canonical concept (expressed in English as reference):

1. **STEP 1: Canonical â†’ Target (Pedagogical Optimization)**
   - Apply all 6 pedagogical heuristics
   - Generate optimized target language translation
   - Validate: Natural, high-frequency, clear, brief, consistent, useful

2. **STEP 2: Target â†’ Known (Back-Translation)**
   - Take the optimized target translation
   - Translate to known language
   - Ensure known translation MATCHES target structure
   - Goal: Known â†” Target alignment for better FD_LOOP

3. **Generate Output**
   - Store ALL translations in single consolidated file
   - Format: { "S0001": [target, known], "S0002": [target, known], ... }
   - File: vfs/courses/{course_code}/seed_pairs.json

IMPORTANT: For courses where known=English (e.g., ita_for_eng):
- Step 1 produces optimized target
- Step 2 can reuse canonical English (it's already the known language)
- But verify the English phrasing aligns with target structure

For courses where knownâ‰ English (e.g., ita_for_fra):
- Step 1 produces optimized Italian
- Step 2 MUST translate Italian â†’ French (NOT English â†’ French)
- This ensures French mirrors Italian structure

  ## Critical Rules
  - Translations are NOT literal - they are pedagogically optimized
  - Each translation is an immutable amino acid component
  - UUIDs are content-based (deterministic)
  - Preserve seed_id for provenance tracking

  ## Example Translation
  Seed S42: "I would like to go"
  Literal: "Hoffwn i fynd"
  Pedagogical: "Dw i eisiau mynd" (more natural, higher frequency, clearer for learners)

  ## Success Criteria
  âœ“ All 668 seeds translated
  âœ“ All 6 heuristics applied to each
  âœ“ Deterministic UUIDs generated
  âœ“ Amino acids stored in VFS
  âœ“ Provenance preserved (seed_id in each amino acid)

## Phase 2: Corpus Intelligence

NAME: "Corpus Intelligence"
PURPOSE: Map FCFS chronological order and calculate utility scores
INPUT: vfs/courses/{course_code}/seed_pairs.json
OUTPUT: vfs/courses/{course_code}/phase_outputs/phase_2_corpus_intelligence.json

FCFS_DEFINITION: First-Can-First-Say (Semantic Priority)
  - The first word/LEGO to teach a concept CLAIMS that meaning as a BASE LEGO
  - Later words with overlapping meanings must be taught in more specific contexts
  - Example: "estoy" appears first â†’ claims "I am" as BASE
              "soy" appears later â†’ taught as "I am (permanent)" in context like "soy profesor"
  - Establishes which LEGOs get semantic priority in the teaching sequence

UTILITY_SCORING:
  FORMULA: Frequency Ã— Versatility Ã— Simplicity
  FREQUENCY: How often used in corpus
  VERSATILITY: How many contexts it appears in
  SIMPLICITY: How easy to learn/teach
  SCALE: 0-100

PURPOSE_FOR_PHASE_3:
  - FCFS provides chronological baseline for LEGO extraction
  - Utility may override FCFS for high-value teaching opportunities
  - This intelligence drives LEGO decomposition decisions

PROMPT: |
  # Phase 2: Corpus Intelligence

  ## Task
  Analyze translated corpus to determine FCFS (First-Can-First-Say) order and calculate utility scores.

  ## Input
  - Translation amino acids: vfs/amino_acids/translations/*.json

  ## Your Mission
  1. **FCFS Mapping** (First-Can-First-Say - Semantic Priority):
     - Determine which words/LEGOs appear first in the teaching sequence
     - The FIRST word to teach a concept CLAIMS that meaning as a BASE LEGO
     - Later words with overlapping meanings must be taught in more specific contexts
     - Example: If "estoy" = "I am" appears before "soy" = "I am", then:
       * "estoy" claims "I am" as its BASE meaning
       * "soy" must be taught differently (e.g., "soy profesor" = "I am a teacher (permanent)")
     - Map semantic priority: which word gets to "own" each core meaning

  2. **Utility Scoring**: Calculate pedagogical value
     - Formula: Frequency Ã— Versatility Ã— Simplicity
     - Frequency: How often used in corpus
     - Versatility: How many contexts it appears in
     - Simplicity: How easy to learn/teach

  3. **Generate Intelligence Report**:
     - FCFS rankings for all translations
     - Utility scores (0-100 scale)
     - Dependency maps
     - Teaching sequence recommendations

  ## Output Format
  vfs/phase_outputs/phase_2_corpus_intelligence.json

  {
    "fcfs_order": [ ... ],
    "utility_scores": { translation_uuid: score, ... },
    "dependencies": { ... },
    "recommendations": { ... }
  }

  ## Critical Notes
  - FCFS = "natural" chronological sequence
  - Utility may override FCFS for high-value opportunities
  - This data drives Phase 3 LEGO extraction algorithm

  ## Success Criteria
  âœ“ FCFS order complete
  âœ“ Utility scores calculated for all translations
  âœ“ Dependency maps generated
  âœ“ Ready for Phase 3 consumption

## Phase 3: LEGO Decomposition

NAME: "LEGO Extraction"
PURPOSE: Extract optimal teaching phrases while enforcing FD and FCFS rules
METHODOLOGY: See `skills/lego-extraction-skill/` for complete methodology
INPUT:
  - vfs/courses/{course_code}/seed_pairs.json (Phase 1 output)
  - vfs/phase_outputs/phase_2_corpus_intelligence.json (optional)
OUTPUT: vfs/courses/{course_code}/lego_pairs.json (v7.7 format - all LEGO breakdowns consolidated)

BATCH_PROCESSING:
  BATCH_SIZE: 20 seeds (complex work requires smaller batches)
  BATCHES: 34 total (668 Ã· 20 = 33.4, rounded up to 34)

CRITICAL_INTELLIGENCE:

**NOTE:** Complete LEGO extraction methodology is in `skills/lego-extraction-skill/`.
This section provides Phase 3 overview. See Skills for detailed rules and examples.

### FD (Functionally Deterministic) - MANDATORY FOR EVERY CHUNK

**DEFINITION:** A LEGO is functionally deterministic if showing the learner the **known chunk**
results in **exactly ONE correct target response**.

**THE TEST:**
- Learner sees: known chunk (e.g., "I want")
- Learner must know: exactly ONE target response (e.g., "Quiero")
- No ambiguity, no alternatives, no guessing

**EXAMPLES:**
  âœ… "Hello" â†’ "Hola" (one and only one target)
  âœ… "I'm trying" â†’ "Estoy intentando" (one target)
  âŒ "the" â†’ ??? (could be "el", "la", "los", "las" - FAILS FD)

**WHY CRITICAL:** Prevents ambiguous mappings that confuse learners. Learner must always know what to say.

### FD_LOOP GENDER AND CONTEXT NEUTRALITY

LEGOs must be CONTEXT-INDEPENDENT and GENDER-NEUTRAL to ensure FD compliance.

GENDER-SPECIFIC TRANSLATIONS VIOLATE FD:
  âŒ "Vuole" / "He wants" â†’ FD fails: "He wants" â†’ "Lui vuole" or "Vuole"?
  âŒ "Vuole" / "She wants" â†’ FD fails: "She wants" â†’ "Lei vuole" or "Vuole"?
  âœ… "Vuole" / "Wants" â†’ FD passes: "Wants" â†’ "Vuole" (unambiguous)

POSSESSIVE AMBIGUITY VIOLATES FD:
  âŒ "il suo nome" / "his name" â†’ FD fails: "his" could be "il suo" or "di lui"
  âŒ "il suo nome" / "her name" â†’ FD fails: "her" could be "il suo" or "di lei"
  âœ… "il suo nome" / "their name" â†’ FD passes: "their" â†’ "il suo" (singular they)

CONTEXT-DEPENDENT TRANSLATIONS VIOLATE FD:
  âŒ "que" / "what" (could be "that", "which", "what")
  âŒ "bien" / "good" (could be "well", "good", "fine", "very")
  âœ… Apply FCFS to claim primary meaning with most frequent usage
  âœ… Less frequent must add context: "muy bien" / "very good"

THE CHUNK UP PRINCIPLE (FD Rescue Strategy):
  When a word alone violates FD â†’ Don't just "apply context" â†’ CHUNK UP!

  ALGORITHM:
    1. Test word alone for FD â†’ FAIL?
    2. Add surrounding word (left or right) â†’ Test FD
    3. Still FAIL? Keep expanding
    4. Create COMPOSITE LEGO with full context that PASSES FD
    5. Extract FD components as FEEDERS
    6. Add COMPONENTIZATION explanation

  EXAMPLES:
    âŒ WRONG: "parlare" / "speaking" (context-dependent - vague!)
    âœ… RIGHT: "sta parlando" / "is speaking" (COMPOSITE includes context)
              FEEDERS: "sta" / "is", "parlare" / "to speak"

    âŒ WRONG: "ricordare" / "remember" (could be infinitive or command)
    âœ… RIGHT: "voglio ricordare" / "I want to remember" (COMPOSITE clarifies)
              FEEDERS: "voglio" / "I want", "ricordare" / "to remember"

PRINCIPLE:
  LEGOs are reusable across multiple contexts.
  Gender, number, and semantic ambiguity must be resolved via:
    1. Gender-neutral translations (they/their instead of he/she)
    2. FCFS claiming (most frequent usage claims simple form)
    3. Context addition via CHUNKING UP (create larger COMPOSITE LEGOs)
    4. NEVER leave ambiguity unresolved

### FCFS (First Come First Served) - Resolves Ambiguity

**DEFINITION:** When a known chunk *could* map to multiple target chunks, the **FIRST occurrence**
in the course claims that mapping. All subsequent occurrences must **chunk up** with context to remain FD.

**THE RULE:**
- First occurrence: Claims the simple mapping (if FD passes)
- Subsequent occurrences: Must add context to differentiate

**EXAMPLE:**
  Seed 1: "I think" â†’ "creo" âœ… (FCFS claims)
  Seed 15: "I think about you" â†’ "pienso en ti" âœ… (chunked up with context)
  NOT: "I think" â†’ "pienso" âŒ (FCFS violation - already claimed by "creo")

**WHY IT MATTERS:** Prevents learner confusion. Once "I think" â†’ "creo" is established,
every time learner sees "I think" alone, they know to say "creo".

**See `skills/lego-extraction-skill/rules/FD_VALIDATION.md` for complete FCFS methodology.**

ARTISTIC_CHOICE (Flexible mapping allowed):
  When multiple words can express the same meaning, frequency decides.

  Examples across language families:
    - Spanish: "quiero" (15x) claims "I want" â†’ "deseo" (2x) uses "I desire"
    - Italian: "voglio" (15x) claims "I want" â†’ "desidero" (2x) uses "I desire"
    - Welsh: "eisiau" (15x) claims "want" â†’ other forms differentiate with context
    - Mandarin: "æƒ³ xiÇng" (15x) claims "want" â†’ "è¦ yÃ o" (3x) uses "need/want"
    - German: "wollen" (15x) claims "to want" â†’ "mÃ¶chten" (5x) uses "would like"

  Once claimed, the mapping is LOCKED for consistency.

GRAMMATICAL_CONSTRAINT (NO flexibility):
  When target language grammar makes semantic distinctions that known language lacks,
  LEGOs MUST preserve that distinction with required context.

  NEVER allow grammatically ambiguous mappings that lose critical distinctions.

  Examples by language family:

  Spanish (ser/estar distinction - permanent vs temporary):
    âœ… "estoy aprendiendo" / "I'm learning" (temporary state - estar)
    âœ… "soy profesor" / "I'm a teacher" (permanent identity - ser)
    âŒ "estoy" / "I am" (loses ser/estar distinction)
    âŒ "soy" / "I am" (loses ser/estar distinction)
    SOLUTION: Always include context that disambiguates

  German (du/Sie distinction - formal vs informal):
    âœ… "Wie geht es Ihnen" / "How are you (formal)"
    âœ… "Wie geht es dir" / "How are you (informal)"
    âŒ "Sie/du" / "you" (loses formality distinction)
    SOLUTION: Include context or use register markers

  Japanese (honorific levels - plain/polite/humble/respectful):
    âœ… "é£Ÿã¹ã¾ã™ (tabemasu)" / "to eat (polite)"
    âœ… "é£Ÿã¹ã‚‹ (taberu)" / "to eat (plain)"
    âŒ Generic "eat" without register marker
    SOLUTION: Always mark register in known translation

  Mandarin (aspect markers - progressive/completed/experiential):
    âœ… "æˆ‘åœ¨åƒ (wÇ’ zÃ i chÄ«)" / "I'm eating (progressive åœ¨)"
    âœ… "æˆ‘åƒäº† (wÇ’ chÄ« le)" / "I ate (completed äº†)"
    âŒ "åƒ (chÄ«)" / "eat" (loses aspect distinction)
    SOLUTION: Include aspect marker in COMPOSITE LEGO

  French (tu/vous distinction):
    âœ… "Comment allez-vous" / "How are you (formal)"
    âœ… "Comment vas-tu" / "How are you (informal)"
    âŒ "tu/vous" / "you" (loses formality distinction)

CRITICAL RULE:
  If your target language has grammatical distinctions that known language doesn't,
  you MUST use CHUNK UP principle to preserve those distinctions in LEGOs.
  Never create ambiguous mappings that collapse critical grammar.

### AUTOMATIC REJECTION LIST
FUNCTION_WORDS (ALWAYS FAIL FD):
  - Articles: el/la/los/las, un/una (gender ambiguous)
  - Pronouns: le/lo/la (multiple meanings)
  - Prepositions: en (in/on/at), de (of/from/about), por/para
  - "que" (that/what/which) - context dependent

MULTI_MEANING_WITHOUT_CONSTRAINTS:
  - "bien" â†’ well/good/fine (use FCFS to claim primary meaning)
  - "muy" â†’ very/really (use FCFS for intensity)

### DUAL-PASS METHODOLOGY

PASS 1: Forward Analysis (Target â†’ Known)
  1. Start with first word of target sentence
  2. Test for FD compliance using FD_LOOP
  3. If fails, expand to include next word
  4. Continue until FD passes or sentence complete
  5. Move to next unmapped word

PASS 2: Reverse Validation (Known â†’ Target)
  1. Take each known chunk
  2. Verify it maps back to EXACT target chunk
  3. If different â†’ REJECT and re-decompose

PASS 3: Corpus-Wide Validation
  For EVERY chunk, search ALL other SEED_PAIRS in batch:
  - Find every occurrence of this chunk
  - Count frequency of each mapping
  - Apply FCFS: most frequent claims simple mapping
  - Less frequent must differentiate with context
  - If conflicts cannot be resolved â†’ FLAG for SEED_PAIR revision

PASS 4: SEED_PAIR Revision Notes
  If decomposition reveals FD conflicts:
  - Note which SEED_PAIRS need editing
  - Suggest specific changes to maintain FD
  - Example: "I want coffee" might need â†’ "I'd like coffee" if "quiero" is claimed

### LEGO TYPES

BASE_LEGO:
  DEFINITION: Fundamental FD unit that cannot be broken down further
  CHARACTERISTICS:
    - Single, atomic unit
    - FD (passes target â†’ known â†’ target)
    - Not composed of other LEGOs
  EXAMPLES:
    - "Voglio" = "I want"
    - "voy" = "I'm going"
    - "algo" = "something"

COMPOSITE_LEGO:
  DEFINITION: FD unit comprising BASE LEGOs + non-LEGO glue words
  CHARACTERISTICS:
    - Itself is FD as a complete unit
    - Contains at least ONE BASE LEGO + glue words
    - BASE LEGOs within DO NOT TILE (don't concatenate cleanly)
    - Glue words are NOT LEGOs themselves
  EXAMPLES:
    - "voy a decir" = "I'm going to say" (glue: "a")
    - "sto per esercitarmi" = "I'm going to practice" (glue: "per")
  WHEN_TO_CREATE:
    - BASE LEGOs don't TILE if concatenated directly
    - Glue words (prepositions, particles) required between
    - Unit is more useful taught as one piece

FEEDERS:
  DEFINITION: BASE LEGOs that feed into a COMPOSITE LEGO
  CHARACTERISTICS:
    - They are BASE LEGOs themselves (FD, atomic, standalone)
    - Have dual existence:
      1. As independent BASE LEGOs (own baskets, used in phrases)
      2. As components within COMPOSITE LEGO
    - Stored with F## suffix (not L##) when part of COMPOSITE
    - NOT subordinate to COMPOSITE - full LEGOs used in multiple contexts
  EXAMPLE:
    - COMPOSITE: "voy a decir" (S0005L02)
    - FEEDER 1: "voy" (S0005F01) â† Also exists as BASE LEGO elsewhere
    - FEEDER 2: "decir" (S0005F02) â† Also exists as BASE LEGO elsewhere
    - Glue: "a" (NOT a LEGO, NOT a FEEDER)

### TILING CONCEPT

DEFINITION: LEGOs that concatenate cleanly without glue words

TILES (Concatenate directly):
  - No additional words needed between LEGOs
  - Direct concatenation reconstructs sentence
  - Keep as separate BASE LEGOs
  EXAMPLE: "Voglio parlare" = "Voglio" + "parlare" âœ… TILES

DOES_NOT_TILE (Needs glue):
  - Additional words required between LEGOs
  - Cannot concatenate directly
  - Create COMPOSITE LEGO
  EXAMPLE: "voy a decir" â‰  "voy" + "decir" âŒ DOESN'T TILE (needs "a")

DECISION_RULE:
  IF (BASE LEGOs TILE):
    â†’ Keep as separate BASE LEGOs
  ELSE IF (BASE LEGOs DON'T TILE):
    â†’ Create COMPOSITE LEGO with FEEDERs

### COMPONENTIZATION (Pedagogical Explanation)

PURPOSE: Help learners understand how multi-word LEGOs break down

TWO TYPES:

1. For BASE LEGOs that TILE:
   - LEGOs remain separate in structure
   - But add explanation for learner clarity
   - Example: "parlare italiano" stays as two LEGOs (parlare + italiano)
   - Add: "parler italien = parlare italiano, oÃ¹ parlare = parler et italiano = italien"

2. For COMPOSITE LEGOs:
   - LEGO is structurally one unit (doesn't tile)
   - Show FEEDERs to help learner understand components
   - Example: "voy a decir" is ONE COMPOSITE LEGO
   - FEEDERs: voy (F01), decir (F02)
   - Explanation: "voy a decir = I'm going to say, where voy = I'm going, a = [particle], decir = to say"

RULE: Add componentization when BOTH target AND known are multi-word

FORMAT: Simple word mappings in KNOWN language
  "[known LEGO] = [target LEGO], where [target1] = [known1] and [target2] = [known2]"

CRITICAL: Write ALL componentization in KNOWN language, NOT English!
  - French speakers: Use "oÃ¹" (not "where"), "et" (not "and")
  - Spanish speakers: Use "donde" (not "where"), "y" (not "and")

### IRON RULE
ABSOLUTE_CONSTRAINT: No LEGO begins or ends with a STANDALONE preposition

CRITICAL CLARIFICATION - Prepositional Phrases:
  - Standalone prepositions WITHOUT objects: âŒ FORBIDDEN
  - Complete prepositional phrases WITH objects: âœ… ALLOWED

ALLOWED (Complete prepositional phrases):
  âœ… "con te" / "with you" (complete prepositional phrase)
  âœ… "con me" / "with me" (complete prepositional phrase)
  âœ… "in italiano" / "in Italian" (complete prepositional phrase)
  âœ… "avec tous les autres" / "with everyone else" (complete prepositional phrase)
  âœ… "con tutti gli altri" / "with everyone else" (complete prepositional phrase)

NOT ALLOWED (Standalone prepositions):
  âŒ "con" / "with" (standalone preposition)
  âŒ "in" / "in" (standalone preposition)
  âŒ "per" / "to" (standalone preposition)
  âŒ "de" / "of" (standalone preposition)
  âŒ "da" / "from" (standalone preposition)

INFINITIVE MARKER CLARIFICATION:
  - The infinitive marker "to" (as in "to speak") is NOT a preposition
  - It is a grammatical marker that forms part of the infinitive verb
  - Full infinitives like "to speak", "to learn" are ALLOWED and FD-compliant
  - Bare infinitives are NOT FD (conflict with commands and conjugations)

EXAMPLES:
  âœ… "to speak" / "parlare" (infinitive marker + verb)
  âœ… "to learn" / "imparare" (infinitive marker + verb)
  âŒ "to the" / "al" (directional preposition - needs object!)

PRINCIPLE: Prepositional phrases are complete, meaningful, FD-compliant units.
          The issue is orphaned prepositions without objects, not complete phrases.

NON_NEGOTIABLE: No standalone prepositions at LEGO boundaries

### UID FORMAT
MANDATORY_STRUCTURE:
  LEGOs: S{seed_id}L{position}
  FEEDERs: S{seed_id}F{position}

EXAMPLES:
  - Seed S0001 â†’ LEGOs: S0001L01, S0001L02, S0001L03
  - Seed S0001 â†’ FEEDERs: S0001F01, S0001F02

NEVER_USE:
  âŒ L0001 (missing parent seed ID)
  âŒ F0001 (missing parent seed ID)

### CONCRETE EXAMPLE

INPUT (from Phase 1):
{
  "seed_id": "S0001",
  "target": "Voglio parlare italiano con te adesso.",
  "known": "Je veux parler italien avec toi maintenant."
}

OUTPUT (Phase 3 decomposition):
{
  "seed_id": "S0001",
  "original_target": "Voglio parlare italiano con te adesso.",
  "original_known": "Je veux parler italien avec toi maintenant.",
  "lego_pairs": [
    {
      "lego_id": "S0001L01",
      "target_chunk": "Voglio",
      "known_chunk": "Je veux",
      "fd_validated": true
    },
    {
      "lego_id": "S0001L02",
      "target_chunk": "parlare italiano",
      "known_chunk": "parler italien",
      "fd_validated": true
    },
    {
      "lego_id": "S0001L03",
      "target_chunk": "con te",
      "known_chunk": "avec toi",
      "fd_validated": true
    },
    {
      "lego_id": "S0001L04",
      "target_chunk": "adesso",
      "known_chunk": "maintenant",
      "fd_validated": true
    }
  ],
  "feeder_pairs": [
    {
      "feeder_id": "S0001F01",
      "target_chunk": "parlare",
      "known_chunk": "parler"
    },
    {
      "feeder_id": "S0001F02",
      "target_chunk": "italiano",
      "known_chunk": "italien"
    }
  ],
  "componentization": [
    {
      "lego_id": "S0001L02",
      "explanation": "parler italien = parlare italiano, oÃ¹ parlare = parler et italiano = italien"
    },
    {
      "lego_id": "S0001L03",
      "explanation": "avec toi = con te, oÃ¹ con = avec et te = toi"
    }
  ]
}

### PHASE 3 REFINEMENTS (Validated from Italian 30-seed production test)

These 10 critical refinements emerged from real-world decomposition testing and
should be applied to ALL language pair combinations.

#### 1. IRON RULE CLARIFICATION - Prepositional Phrases
**Prepositional phrases WITH objects are FD-compliant and ALLOWED.**

See IRON RULE section above for complete details.

Key insight: The problem is orphaned prepositions, not complete prepositional phrases.
Complete phrases like "con te" / "with you" are meaningful FD units.

#### 2. Infinitive "to" Placement Rule
**English infinitives: "to" attaches to the FOLLOWING verb, not trailing on modals.**

CORRECT:
  - "poter" = "to be able" (NOT "to be able to")
  - "parlare" = "to speak"
  - Combined: "poter parlare" = "to be able to speak"

INCORRECT:
  - âŒ "poter" = "to be able to"
  - âŒ "parlare" = "speak"

RATIONALE:
  In "I want to be able to speak", the structure has TWO infinitives:
    - "want" (modal)
    - "to be able" (infinitive 1)
    - "to speak" (infinitive 2)
  Each infinitive carries its own "to" marker.

#### 3. Minimal FD Chunks Principle
**Break LEGOs into SMALLEST FD-compliant chunks that are PEDAGOGICALLY HELPFUL.**

PROCESS:
  1. Can this LEGO break into smaller FD components?
  2. Would learning components FIRST help understand the composite?
  3. If YES â†’ Create BASE LEGOs + COMPOSITE + FEEDERS
  4. If NO â†’ Keep as single LEGO

EXAMPLE - GOOD BREAKDOWN:
  "il piÃ¹ spesso possibile" / "as often as possible"

  BASE LEGOs:
    - "spesso" / "often" (FD âœ“, pedagogically helpful âœ“)
    - "possibile" / "possible" (FD âœ“, pedagogically helpful âœ“)

  COMPOSITE LEGO:
    - "il piÃ¹ spesso possibile" / "as often as possible"

  FEEDERS:
    - "spesso" (learned as BASE LEGO)
    - "possibile" (learned as BASE LEGO)

EXAMPLE - KEEP AS SINGLE:
  "il piÃ¹ possibile" / "as hard as I can"

  Why? English translation is idiomatic and doesn't map directly to components.
  Breaking down "possibile" = "possible" wouldn't help learner understand
  "as hard as I can" - the mapping is non-compositional.

#### 4. Glue Words Must Stay INSIDE Composites
**Function words (di, a, per, che, de, Ã , von, etc.) must NEVER appear at LEGO edges.**
**They must be CONTAINED within composite units.**

CORRECT:
  âœ… "Sto cercando di ricordare" / "I'm trying to remember" (full COMPOSITE)
  âœ… "cercare di spiegare" / "to try to explain" (full COMPOSITE)
  âœ… "smettere di parlare" / "to stop talking" (full COMPOSITE)

INCORRECT:
  âŒ "Sto cercando di" / "I'm trying to" + "ricordare" / "remember"
      (leaves "di" trailing - breaks recombination)
  âŒ "cercare di" / "to try to" + "spiegare" / "explain"
      (leaves "di" trailing - breaks recombination)

RATIONALE:
  Leaving glue words at edges makes basket recombination (Phase 5) nearly
  impossible and creates unnatural phrase boundaries.

#### 5. FEEDERS - Selective, Not Exhaustive
**Only include FD and PEDAGOGICALLY HELPFUL components as FEEDERs.**

OLD APPROACH (wrong):
  Include ALL components of a COMPOSITE as FEEDERs

NEW APPROACH (correct):
  Only include components that are:
    1. FD-compliant (pass FD_LOOP test independently)
    2. Pedagogically helpful (aid learner understanding)

EXAMPLE:
  Seed: "Sto per cercare di spiegare quello che intendo."
  English: "I'm going to try to explain what I mean."

  LEGO: "quello che intendo" / "what I mean"

  FEEDERS:
    âœ… "intendo" / "I mean" (FD âœ“, helpful âœ“)

  NOT FEEDERS:
    âŒ "quello che" / "what" (NOT FD - could be cosa, che cosa, quale, etc.)

PRINCIPLE:
  If a component is NOT FD, don't include it as a FEEDER.
  The componentization explanation can still MENTION it for learner context,
  but it shouldn't be a separate teaching unit.

#### 6. Componentization Language - "represents" vs "means"
**Use precise language to describe component relationships.**

USE "means" when:
  - Direct, literal, word-for-word translation
  - Clear 1:1 correspondence
  - Example: "dove con = with and me = me"

USE "represents" when:
  - Idiomatic or structural translations
  - Grammar that doesn't translate directly
  - Non-compositional mappings
  - Example: "where Non vedo l'ora represents looking forward"
  - Example: "where che finisci represents that you finish"

This helps learners understand which mappings are direct vs interpretive.

#### 7. Function Words - Avoid Standalone LEGOs
**Function words should NOT be standalone LEGOs unless genuinely useful alone.**

AVOID AS STANDALONE:
  âŒ "E" / "And" (rarely useful in isolation)
  âŒ "Ma" / "But" (rarely useful in isolation)
  âŒ "se" / "if" (combine with clause: "se posso ricordare" / "if I can remember")
  âŒ "per" / "to" (combine with verb: "per rispondere" / "to answer")

ACCEPTABLE STANDALONE:
  âœ… "PerchÃ©" / "Why" or "Because" (question word / connector, high utility)
  âœ… "con" / "with" (when it appears separately in useful contexts)

PRINCIPLE:
  If a word rarely appears alone in natural speech, don't make it a standalone LEGO.
  CHUNK UP to include context that makes it a complete, useful teaching unit.

#### 8. FD Violations - Gender and Context Ambiguity
**CRITICAL: Avoid gender-specific or context-dependent translations.**
(See FD_LOOP GENDER AND CONTEXT NEUTRALITY section above for complete details)

Quick reference:
  - Use gender-neutral translations: "wants" not "he wants" / "she wants"
  - Use singular "they/their" for possessives: "their name" not "his/her name"
  - Context provided in full seed, NOT in individual LEGO translations

#### 9. Building Composites Hierarchically
**Create LEGOs at each hierarchical level when phrases build up naturally.**

EXAMPLE:
  Seed: "con qualcun altro" / "with someone else"

  Hierarchical breakdown:
    L01: "con" / "with"
    L02: "qualcuno" / "someone"
    L03: "altro" / "else"
    L04: "qualcun altro" / "someone else"
        FEEDERS: qualcuno, altro
        COMPONENTIZATION: "someone else = qualcun altro, where qualcuno = someone and altro = else"
    L05: "con qualcun altro" / "with someone else"
        FEEDERS: con, qualcun altro
        COMPONENTIZATION: "with someone else = con qualcun altro, where con = with and qualcun altro = someone else"

RATIONALE:
  Learners build understanding from smallest units to complete phrases naturally.
  This hierarchical structure mirrors natural language acquisition.

#### 10. CHUNK UP Principle - The FD Rescue Strategy
**When context is needed for FD compliance â†’ CHUNK UP to create larger COMPOSITE.**
(See THE CHUNK UP PRINCIPLE in FD_LOOP section above for complete algorithm)

DO NOT use vague "context-dependent" labels:
  âŒ WRONG: "parlare" / "speaking" (gerund in context) â† Vague! What context?
  âŒ WRONG: "ricordare" / "remember" (after modal) â† Ambiguous!

INSTEAD, CHUNK UP to include context:
  âœ… RIGHT: "sta parlando" / "is speaking" (COMPOSITE includes progressive marker)
            FEEDERS: "sta" / "is", "parlare" / "to speak"
            COMPONENTIZATION: "is speaking = sta parlando, where sta represents is and parlando represents speaking"

  âœ… RIGHT: "voglio ricordare" / "I want to remember" (COMPOSITE includes modal)
            FEEDERS: "voglio" / "I want", "ricordare" / "to remember"

  âœ… RIGHT: "sto cercando di ricordare" / "I'm trying to remember" (larger COMPOSITE)
            FEEDERS: "sto" / "I'm", "cercare" / "to try", "ricordare" / "to remember"
            COMPONENTIZATION: Shows how "cercando di" forms progressive + infinitive structure

THE ALGORITHM:
  1. Test word alone for FD â†’ FAIL?
  2. Add surrounding word (left or right) â†’ Test FD
  3. Still FAIL? Keep expanding
  4. Create COMPOSITE LEGO with full context that PASSES FD
  5. Extract FD components as FEEDERS
  6. Add COMPONENTIZATION explanation for learner understanding

This is the universal FD rescue strategy that works across ALL language pairs.

PROMPT: |
  # Phase 3: LEGO Decomposition

  Hi! I need help with Phase 3 of my language course project - LEGO decomposition.

  Working with ${targetLang} for ${knownLang} speakers.

  ## CORE PRINCIPLE
  Break each SEED_PAIR into LEGO chunks that:
  1. When placed side-by-side, EXACTLY reconstruct the original sentence
  2. Each LEGO passes the FD_LOOP test independently
  3. Are reusable across multiple sentences

  ## LEGO TYPES & ARCHITECTURE

  ### BASE LEGO (Simple/Atomic)
  - Fundamental FD unit
  - Cannot be broken down further
  - Examples: "Voglio", "parlare", "voy", "decir"

  ### COMPOSITE LEGO (Contains BASE + Glue)
  - FD unit with BASE LEGOs + non-LEGO glue words
  - BASE LEGOs DON'T TILE (can't concatenate directly)
  - Examples:
    - "voy a decir" (voy + a + decir) - "a" is glue
    - "sto per esercitarmi" (sto + per + esercitarmi) - "per" is glue

  ### FEEDERS
  - BASE LEGOs within a COMPOSITE
  - Stored separately with F## suffix
  - Help learners understand COMPOSITE structure

  ### TILING TEST
  **Question**: Can you concatenate these LEGOs directly?

  IF YES (TILES):
  â†’ Keep as separate BASE LEGOs
  Example: "Voglio" + "parlare" = "Voglio parlare" âœ…

  IF NO (DOESN'T TILE):
  â†’ Create COMPOSITE LEGO + FEEDERs
  Example: "voy" + "decir" â‰  "voy decir" âŒ (need "a")
  â†’ COMPOSITE: "voy a decir"
  â†’ FEEDERs: "voy" (F01), "decir" (F02)

  ## YOUR EXTRACTION PROCESS

  For each seed:

  1. Break into potential chunks
  2. Validate each chunk is FD
  3. Check if chunks contain multiple BASE LEGOs
  4. Apply TILING TEST:
     - TILES? â†’ Separate BASE LEGOs
     - DOESN'T TILE? â†’ COMPOSITE LEGO + FEEDERs
  5. Add componentization explanation (pedagogical)

  ## MANDATORY UID FORMAT
  For seed S0001:
  - LEGOs: S0001L01, S0001L02, S0001L03
  - FEEDERs: S0001F01, S0001F02 (sub-components of multi-word LEGOs)
  NEVER use L0001 or F0001 (missing parent seed ID)

  ## ğŸ” FD_LOOP TEST (MANDATORY FOR EVERY CHUNK)
  Target â†’ Known â†’ Target = MUST BE IDENTICAL
  âœ… "importante" â†’ "important" â†’ "importante" (IDENTICAL)
  âŒ "bien" â†’ "good" â†’ "bueno" (DIFFERENT = FAIL)

  ## ğŸ¯ FCFS RULE (First Come, First Served)
  When multiple valid mappings exist, use corpus frequency to CLAIM semantic territory.

  **UNIVERSAL PRINCIPLE**: Most frequent variant claims simple translation (if grammatically valid).
  Less frequent variants must differentiate with context. Works for ANY language pair.

  ### ARTISTIC CHOICE (flexible mapping allowed):
  When multiple ${targetLang} words can express the same ${knownLang} meaning:
  - Most frequent (15x) â†’ CLAIMS simple translation
  - Less frequent (2x) â†’ must use more specific translation
  - Once claimed, mapping is LOCKED for consistency

  Example patterns:
    - If "word_A" appears 15x â†’ claims simple meaning
    - If "word_B" appears 2x â†’ must differentiate (e.g., add intensity/formality)

  ### GRAMMATICAL CONSTRAINT (NO flexibility):
  When ${targetLang} grammar makes distinctions that ${knownLang} doesn't:
  â†’ LEGOs MUST preserve that distinction with context
  â†’ NEVER create ambiguous mappings
  â†’ Use CHUNK UP principle to include disambiguating context

  Common patterns to watch for:
    - Formal/informal distinctions (Spanish tÃº/usted, German du/Sie, French tu/vous)
    - Permanent/temporary states (Spanish ser/estar)
    - Aspect markers (Mandarin äº†/åœ¨/è¿‡, Slavic perfective/imperfective)
    - Honorific levels (Japanese plain/polite/humble, Korean í•´ìš”/í•©ë‹ˆë‹¤)
    - Gender agreement (Romance languages, German, Slavic)

  **CRITICAL**: If ${targetLang} has grammatical distinctions, CHUNK UP to preserve them!

  âœ… RIGHT: Include context that disambiguates
  âŒ WRONG: Collapse distinctions into generic translation

  ### FCFS PROCESS:
  1. Count frequency of each mapping across ALL corpus seeds
  2. Most frequent CLAIMS simple mapping (if grammatically valid)
  3. Less frequent must ADD context to differentiate
  4. If corpus edit needed to maintain FD, NOTE it for SEED_PAIR revision

  ## ğŸš« AUTOMATIC REJECTION LIST
  **Function Words (ALWAYS FAIL FD):**
  - Articles: el/la/los/las, un/una (gender ambiguous)
  - Pronouns: le/lo/la (multiple meanings)
  - Prepositions: en (in/on/at), de (of/from/about), por/para
  - "que" (that/what/which) - context dependent

  **Multi-meaning words WITHOUT grammar constraints:**
  - "bien" â†’ well/good/fine (use FCFS to claim primary meaning)
  - "muy" â†’ very/really (use FCFS for intensity)

  ## âœ… DUAL-PASS METHODOLOGY

  ### PASS 1: Forward Analysis (${targetLang} â†’ ${knownLang})
  1. Start with first word of ${targetLang} sentence
  2. Test for FD compliance using FD_LOOP
  3. If fails, expand to include next word
  4. Continue until FD passes or sentence complete
  5. Move to next unmapped word

  ### PASS 2: Reverse Validation (${knownLang} â†’ ${targetLang})
  1. Take each ${knownLang} chunk
  2. Verify it maps back to EXACT ${targetLang} chunk
  3. If different â†’ REJECT and re-decompose

  ### PASS 3: Corpus-Wide Validation
  For EVERY chunk, search ALL other SEED_PAIRS in batch:
  - Find every occurrence of this chunk
  - Count frequency of each mapping
  - Apply FCFS: most frequent claims simple mapping
  - Less frequent must differentiate with context
  - If conflicts cannot be resolved â†’ FLAG for SEED_PAIR revision

  ### PASS 4: SEED_PAIR Revision Notes
  If decomposition reveals FD conflicts:
  - Note which SEED_PAIRS need editing
  - Suggest specific changes to maintain FD
  - Example: "I want coffee" might need â†’ "I'd like coffee" if "quiero" is claimed

  ## ğŸ“ COMPONENTIZATION REQUIREMENT (BOTH languages must be multi-word!)
  COMPONENTIZATION is ONLY needed when BOTH target AND known are multi-word:
  - âœ… REQUIRED: "parlare italiano" â†” "parler italien" (BOTH are 2 words)
  - âœ… REQUIRED: "para su hermana" â†” "for his sister" (BOTH are 3 words)
  - âŒ NOT NEEDED: "construir" â†” "build" (both single words)
  - âŒ NOT NEEDED: "una nueva vida" â†” "a new life" (even though multi-word, simple 1:1 mapping)

  FORMAT: Simple word mappings ONLY (no grammar explanations):
  "[known LEGO] = [target LEGO], where [target1] = [known1] and [target2] = [known2]"

  âš ï¸ CRITICAL: Write ALL componentization in ${knownLang}, NOT English!
  - French speakers: Use French words like "oÃ¹" (not "where"), "et" (not "and")
  - Spanish speakers: Use Spanish words like "donde" (not "where"), "y" (not "and")
  - Chinese speakers: Use Chinese: "å…¶ä¸­" (not "where"), "å’Œ" (not "and")

  Example for ${knownLang} speakers:
  French: "parler italien = parlare italiano, oÃ¹ parlare = parler et italiano = italien"
  Spanish: "hablar italiano = parlare italiano, donde parlare = hablar y italiano = italiano"
  NOT: "parler italien = parlare italiano, where parlare = parler and italiano = italien" âŒ

  ## THE IRON RULE (ABSOLUTE)
  **No LEGO begins or ends with a STANDALONE preposition.**

  **CRITICAL CLARIFICATION - Prepositional Phrases**:
  - Standalone prepositions WITHOUT objects: âŒ FORBIDDEN
  - Complete prepositional phrases WITH objects: âœ… ALLOWED

  **ALLOWED (Complete prepositional phrases)**:
  - âœ… "con te" / "with you" (complete prepositional phrase)
  - âœ… "con me" / "with me" (complete prepositional phrase)
  - âœ… "in italiano" / "in Italian" (complete prepositional phrase)
  - âœ… "avec tous" / "with everyone" (complete prepositional phrase)

  **NOT ALLOWED (Standalone prepositions)**:
  - âŒ "con" / "with" (standalone preposition)
  - âŒ "in" / "in" (standalone preposition)
  - âŒ "per" / "to" (standalone preposition)
  - âŒ "de" / "of" (standalone preposition)

  **INFINITIVE MARKER CLARIFICATION**:
  - The infinitive marker "to" (as in "to speak") is NOT a preposition
  - It is a grammatical marker that forms part of the infinitive verb
  - Full infinitives like "to speak", "to learn" are ALLOWED and FD-compliant
  - Bare infinitives are NOT FD (conflict with commands and conjugations)

  **Examples**:
  - âœ… "to speak" / "parlare" (infinitive marker + verb)
  - âœ… "to learn" / "imparare" (infinitive marker + verb)
  - âŒ "to the" / "al" (directional preposition - needs object!)

  **PRINCIPLE**: Prepositional phrases are complete, meaningful, FD-compliant units.
              The issue is orphaned prepositions without objects.

  **NON-NEGOTIABLE**: No standalone prepositions at LEGO boundaries

  ## THE ELISION RULE (ABSOLUTE)
  **Never split after an elided word (apostrophe) without including the following word.**

  **ELISION PATTERNS** (vary by language):
  Romance languages commonly use elision where vowels are dropped before another vowel:
  - French: d', l', n', s', t', qu', m', c', j' (de, le, ne, se, te, que, me, ce, je)
  - Italian: d', l', un', all', dell', sull', nell' (di, lo/la, uno/una, alla, della, sulla, nella)
  - Spanish: (less common, but exists in contractions like "del" = de + el)
  - Catalan: d', l', n', s', t', m' (similar to French)

  **THE PROBLEM**:
  Elided words are grammatically incomplete - they MUST attach to the following word.
  - âŒ "d'" alone means nothing - it's an incomplete preposition
  - âŒ "l'" alone means nothing - it's an incomplete article
  - âœ… "d'expliquer" / "to explain" - complete meaningful unit
  - âœ… "l'italiano" / "the Italian" - complete meaningful unit

  **CRITICAL RULE**: NEVER create a LEGO that ends with an apostrophe!

  **EXAMPLES OF VIOLATIONS (DO NOT DO THIS)**:
  - âŒ "Je vais essayer d'" / "I'm going to try to" (d' is orphaned)
  - âŒ "Voglio parlare l'" / "I want to speak the" (l' is orphaned)
  - âŒ "Je n'" / "I don't" (n' is orphaned)

  **EXAMPLES OF CORRECT HANDLING**:
  - âœ… "Je vais essayer d'expliquer" / "I'm going to try to explain" (d' attached to expliquer)
  - âœ… "Voglio parlare l'italiano" / "I want to speak Italian" (l' attached to italiano)
  - âœ… "Je n'aime pas" / "I don't like" (n' attached to aime)

  **TILING WITH ELISIONS**:
  When you encounter elisions, apply the TILING TEST to the COMPLETE phrase (with elision + following word):

  Example: "Je vais essayer d'expliquer"
  1. Can we tile "Je vais essayer" + "d'expliquer"? â†’ Check if concatenation works
  2. NO â†’ They don't tile (missing "d'"), so create COMPOSITE:
     - COMPOSITE: "Je vais essayer d'expliquer" / "I'm going to try to explain"
     - FEEDERs: "Je vais" (I'm going), "essayer" (to try), "expliquer" (to explain)

  **DETECTION STRATEGY**:
  1. Scan target language text for apostrophes (')
  2. If apostrophe found, check if it's at end of current chunk
  3. If yes â†’ EXTEND chunk to include next word
  4. Then apply FD_LOOP test to extended chunk

  **LANGUAGE-SPECIFIC GUIDANCE**:
  - **French**: Very common - watch for d', l', n', s', t', qu', m', j', c'
  - **Italian**: Common - watch for d', l', un', all', dell', sull', nell'
  - **Spanish**: Rare - mostly in contractions (del, al) which are written as single words
  - **English**: Contractions like "I'm", "don't", "can't" â†’ treat as single words (already FD-compliant)
  - **Other languages**: Check for similar vowel elision patterns

  **NON-NEGOTIABLE**: No LEGO may end with an apostrophe indicating elision

  ## INPUT DATA
  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/

  Read ALL SEED_PAIRS from:
  SEED_PAIRS_COMPLETE.json (contains all 668 seeds)

  The files contain JSON with structure:
  {
    "seed_pairs": [
      {
        "seed_id": "S0001",
        "target": "[sentence in ${targetLang}]",
        "known": "[sentence in ${knownLang}]"
      }
    ]
  }

  ## OUTPUT FILES
  Save to course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/

  1. Process in batches of 20 seeds:
     - LEGO_BREAKDOWNS_BATCH_001.json (seeds 1-20)
     - LEGO_BREAKDOWNS_BATCH_002.json (seeds 21-40)
     - etc.

  2. ALSO create combined file with ALL breakdowns:
     - LEGO_BREAKDOWNS_COMPLETE.json (all seeds combined)

  Create this exact structure for each file:
  {
    "phase": "LEGO_BREAKDOWNS",
    "batch": "001",
    "target_language": "${targetLang}",
    "known_language": "${knownLang}",
    "lego_breakdowns": [
      // For EACH seed_pair in the input file:
      {
        "seed_id": "S0001",
        "canonical_id": "C0001",
        "original_target": "actual ${targetLang} sentence",
        "original_known": "actual ${knownLang} sentence",
        "lego_pairs": [
          // Break into FD-compliant chunks
        ],
        "feeder_pairs": [
          // Sub-components of multi-word LEGOs
        ],
        "componentization": [
          // ONLY when BOTH target AND known are multi-word!
          // Simple mappings format: known = target, where word1 = word1 and word2 = word2
          {
            "lego_id": "S0001L02",
            "explanation": "[known LEGO] = [target LEGO], where [word1] = [word1] and [word2] = [word2]"
          }
          // Skip if either side is single word or if it's a simple 1:1 mapping
        ]
      }
    ]
  }

  ## CRITICAL OUTPUT RULES
  - **SILENT OPERATION** - Work quietly, save to file
  - **NO PRINTING** - Don't display breakdowns
  - **VFS ONLY** - Save to VFS only, no console output

  Start decomposing immediately.

## Phase 3.5: Graph Construction

NAME: "Graph Construction"
PURPOSE: Build directed graph of LEGO adjacency relationships
INPUT:
  - vfs/amino_acids/legos/*.json
  - vfs/amino_acids/translations/*.json (for co-occurrence analysis)
OUTPUT: vfs/phase_outputs/phase_3.5_lego_graph.json

NEW_IN_V7: This phase is NEW in APML v7.0 - introduces graph intelligence

GRAPH_STRUCTURE:
  NODES: All LEGO amino acids
  EDGES: Directed edges LEGO_A â†’ LEGO_B (when A precedes B in corpus)
  WEIGHTS: co-occurrence frequency Ã— pedagogical value

PURPOSE_FOR_PHASE_5:
  - Graph edges represent legitimate LEGO sequence patterns
  - Phase 5 uses this to ensure pattern coverage in baskets
  - Replaces old DEBUT/ETERNAL pattern logic with measurable diversity

ADJACENCY_DETECTION:
  - Scan translations to find which LEGOs appear adjacent
  - Example: In "Dw i eisiau mynd", LEGOs "Dw i" and "eisiau" are adjacent
  - Direction matters: Aâ†’B â‰  Bâ†’A

VALIDATION:
  - Ensure graph is connected
  - Check for invalid cycles
  - Verify all LEGOs represented

PROMPT: |
  # Phase 3.5: Graph Construction (NEW in v7.0)

  ## Task
  Build directed graph of LEGO adjacency relationships to enable pattern-aware basket construction.

  ## Input
  - LEGO amino acids: vfs/amino_acids/legos/*.json
  - Translation amino acids: vfs/amino_acids/translations/*.json (for co-occurrence analysis)

  ## Your Mission
  1. **Detect Adjacency Patterns**:
     - Scan source translations to find which LEGOs appear adjacent to each other
     - Example: In "Dw i eisiau mynd", LEGOs "Dw i" and "eisiau" are adjacent

  2. **Build Directed Graph**:
     - Nodes: All LEGO amino acids
     - Edges: LEGO_A â†’ LEGO_B (A precedes B in corpus)
     - Direction matters (Aâ†’B â‰  Bâ†’A)

  3. **Calculate Edge Weights**:
     - Weight = co-occurrence frequency Ã— pedagogical value
     - Higher weight = more important pattern to teach

  4. **Validate Graph**:
     - Ensure graph is connected
     - Check for invalid cycles
     - Verify all LEGOs represented

  5. **Export Graph Structure**:
     - Adjacency list format
     - Include edge weights
     - Store metadata (total nodes, edges, density)

  ## Output Format
  vfs/phase_outputs/phase_3.5_lego_graph.json

  {
    "nodes": [ ... ],
    "edges": [
      { "from": "uuid_A", "to": "uuid_B", "weight": 42 },
      ...
    ],
    "metadata": { ... }
  }

  ## Critical Notes
  - This is NEW in APML v7.0 - graph intelligence!
  - Phase 5 uses this graph for pattern coverage optimization
  - Edges represent legitimate LEGO sequence patterns
  - Replaces old DEBUT/ETERNAL pattern logic

  ## Success Criteria
  âœ“ All LEGO adjacencies mapped
  âœ“ Directed edges created
  âœ“ Edge weights calculated
  âœ“ Graph validated (connected, no invalid cycles)
  âœ“ Ready for Phase 5 consumption

## Phase 4: DEPRECATED - Merged into Phase 5.5

DEPRECATED: This phase has been replaced by Phase 5.5 (Basket Deduplication)
REASON: More efficient to create baskets for all LEGO_PAIRS first, then deduplicate baskets
OLD APPROACH: Deduplicate LEGOs â†’ Create baskets
NEW APPROACH: Create baskets (with seed context) â†’ Deduplicate baskets

See Phase 5.5 for new deduplication workflow.

---

## Phase 4 (OLD - DEPRECATED): Deduplication

NAME: "Deduplication"
PURPOSE: Merge duplicate LEGOs while preserving ALL provenance
INPUT: vfs/amino_acids/legos/*.json
OUTPUT: vfs/amino_acids/legos_deduplicated/*.json

WHY_CRITICAL:
  - Many LEGOs appear in multiple seeds
  - Example: "Dw i" might appear from S1L1, S4L2, S12L3
  - Provenance enables edit propagation
  - If seed S12 changes, we know which LEGOs to update

MERGING_PROCESS:
  1. Detect duplicates (identical text content, different UUIDs)
  2. Combine ALL S{seed}L{position} labels
  3. Example: S1L1, S4L2, S12L3 â†’ "S1L1, S4L2, S12L3"
  4. Generate new deterministic UUID based on merged provenance
  5. Create deduplicated set (one LEGO per unique text)

IMMUTABILITY_PRESERVED:
  - Keep original LEGOs (immutable)
  - Deduplicated set is NEW amino acids
  - NEVER lose any provenance information

OUTPUT_STRUCTURE:
  uuid: new_deduplicated_uuid
  text: "the LEGO phrase"
  provenance: ["S1L1", "S4L2", "S12L3"]
  source_count: 3
  metadata: { ... }

PROMPT: |
  # Phase 4: Deduplication

  ## Task
  Identify and merge duplicate LEGOs while preserving ALL provenance information.

  ## Input
  - LEGO amino acids: vfs/amino_acids/legos/*.json

  ## Your Mission
  1. **Detect Duplicates**:
     - Find LEGOs with identical text content
     - May have different UUIDs (different provenance)
     - Example: "Dw i" might appear from S1L1, S4L2, S12L3

  2. **Merge Provenance**:
     - Combine all S{seed}L{position} labels
     - Example: Merge S1L1, S4L2, S12L3 â†’ "S1L1, S4L2, S12L3"
     - NEVER lose any provenance information

  3. **Recalculate UUID**:
     - Generate new deterministic UUID based on:
       - LEGO text
       - ALL merged provenance labels
       - Metadata

  4. **Create Deduplicated Set**:
     - One LEGO per unique text
     - Complete provenance history preserved
     - Update graph references if needed

  5. **Store Results**:
     - vfs/amino_acids/legos_deduplicated/*.json
     - Keep original LEGOs (immutable)
     - Deduplicated set is NEW amino acids

  ## Why This Matters
  - Many LEGOs appear in multiple seeds
  - Provenance enables edit propagation
  - If seed S12 changes, we know which LEGOs to update
  - Birth-parent history must NEVER be lost

  ## Output Structure
  {
    "uuid": "new_deduplicated_uuid",
    "text": "the LEGO phrase",
    "provenance": ["S1L1", "S4L2", "S12L3"],
    "source_count": 3,
    "metadata": { ... }
  }

  ## Success Criteria
  âœ“ All duplicates identified
  âœ“ Provenance fully merged (no data loss)
  âœ“ New UUIDs generated
  âœ“ Deduplicated set created
  âœ“ Original LEGOs preserved (immutable)

## Phase 5: Basket Generation (Edge-Aware + d-phrases/e-phrases)

NAME: "Basket Generation with Graph Intelligence and Progressive Vocabulary"
PURPOSE: Create practice phrase baskets for ALL LEGOs (deduplication happens in Phase 5.5)
INPUT:
  - vfs/courses/{course_code}/LEGO_BREAKDOWNS_COMPLETE.json (contains all LEGOs)
  - vfs/courses/{course_code}/phase_outputs/phase_3.5_lego_graph.json (for edge coverage)
  - vfs/courses/{course_code}/phase_outputs/phase_2_corpus_intelligence.json (for FCFS ordering)
OUTPUT: vfs/courses/{course_code}/lego_baskets.json (ALL LEGO baskets - includes duplicates)

CRITICAL: WHAT COUNTS AS A LEGO
  **ALL of these structures need baskets:**
  1. **lego_pairs[]** - Both BASE and COMPOSITE type LEGOs
     - Example: {"lego_id": "S0001L02", "target_chunk": "parler", "known_chunk": "to speak"}

  2. **feeder_pairs[]** - Atomic components of COMPOSITE LEGOs
     - Example: {"feeder_id": "S0015F01", "target_chunk": "parler", "known_chunk": "to speak"}
     - FEEDERS ARE LEGOS - They might be new, or duplicates of existing LEGOs
     - Generate baskets for ALL feeders (deduplication removes duplicates later)

  **Why process feeders:**
  - A FEEDER might introduce NEW vocabulary not yet seen
  - A FEEDER might be a DUPLICATE of an existing LEGO (dedup handles this)
  - We can't know which without checking, so we generate baskets for ALL

CRITICAL_CHANGE:
  - OLD: Create baskets only for lego_pairs[] entries
  - NEW: Create baskets for BOTH lego_pairs[] AND feeder_pairs[]
  - WHY: Feeders are legitimate LEGOs that need practice baskets
  - Deduplication happens AFTER in Phase 5.5 (delete duplicate baskets, keep first occurrence)

BATCH_PROCESSING:
  BATCH_SIZE: 20 LEGOs per batch
  PROCESSING: Forward (LEGO 1 â†’ last LEGO, NOT backwards)

TWO_STAGE_PROCESS:
  STAGE 1 - Basket Selection (Graph-Driven):
    - Analyze LEGO adjacency graph from Phase 3.5
    - Select LEGOs to maximize edge coverage (pattern diversity)
    - Follow FCFS chronological progression from Phase 2
    - Ensure smooth difficulty progression
    - Goal: Learners experience maximum pattern variety

  STAGE 2 - Phrase Generation (Vocabulary-Constrained):
    - For each selected LEGO, generate d-phrases and e-phrases
    - Apply progressive vocabulary constraint
    - Each LEGO can ONLY use vocabulary from LEGOs that came before it
    - LEGO #1: NO vocabulary available = empty basket
    - LEGO #2: Can only use LEGO #1 = very limited
    - LEGO #N: Can use LEGOs #1 through #(N-1)
    - This creates natural progression where complexity builds gradually

COMBINING_BOTH_APPROACHES:
  - Edge coverage ensures corpus patterns are reflected
  - Progressive vocabulary ensures pedagogical soundness
  - FCFS ordering maintains chronological appropriateness
  - Result: Optimal learning sequence with rich practice

E_PHRASES (ETERNAL Practice Phrases):
  WHEN_USED: At ANY point in the course AFTER this LEGO's introduction (reusable FOREVER)
  FREQUENCY: Permanent practice material - practiced hundreds of times throughout the course
  PURPOSE: Long-term practice for this LEGO (learner at lesson #50 practicing LEGO #10 uses these)
  QUALITY: MUST be excellent - natural, conversational, high-quality sentences
  REQUIREMENTS:
    - 5 phrases per LEGO
    - Each 7-10 words long
    - Must contain the target LEGO
    - Perfect grammar in BOTH languages
    - Natural, conversational usage
    - Only use vocabulary from previous LEGOs

D_PHRASES (DEBUT Practice Phrases):
  WHEN_USED: ONLY during this LEGO's FIRST introduction (used ONCE, never repeated)
  FREQUENCY: Temporary scaffolding for initial learning
  PURPOSE: Help learner build up to full sentences progressively (2â†’3â†’4â†’5 LEGOs)
  QUALITY: Syntactically correct, but CAN be awkward fragments (temporary learning aids)
  REQUIREMENTS:
    - Auto-generated from e_phrases using expanding windows
    - 2_lego: 2 phrases with 2 LEGOs each
    - 3_lego: 2 phrases with 3 LEGOs each
    - 4_lego: 2 phrases with 4 LEGOs each
    - 5_lego: 2 phrases with 5 LEGOs each
    - Must be syntactically correct (even as fragments) in BOTH languages

CRITICAL_DISTINCTION:
  E-phrases = Training wheels you keep FOREVER (permanent practice)
  D-phrases = Training wheels you remove AFTER debut (temporary scaffolding)

CULMINATING_LEGO_RULE:
  If this is the LAST LEGO in a seed (e.g., S0123L03 is last of S0123):
  - E-phrase #1 MUST be the COMPLETE SEED sentence
  - Use complete seed heavily in d-phrases (3+ times)
  - Gives learner satisfaction of understanding full seed

BASKET_STRUCTURE:
  {
    "S####L##": {
      "target": "target language LEGO",
      "known": "English translation",
      "e_phrases": [
        ["7-10 word phrase with LEGO", "English translation"],
        ... (5 total)
      ],
      "d_phrases": {
        "2_lego": [["phrase", "translation"], ...],
        "3_lego": [["phrase", "translation"], ...],
        "4_lego": [["phrase", "translation"], ...],
        "5_lego": [["phrase", "translation"], ...]
      }
    }
  }

PROMPT: |
  # Phase 5: Basket Generation - Graph Intelligence + Progressive Vocabulary

  ## TWO-STAGE PROCESS

  ### STAGE 1: Basket Selection (Graph-Driven)

  **Goal**: Select LEGO groupings that maximize pattern diversity

  1. **Load Graph Intelligence**:
     - Read: vfs/phase_outputs/phase_3.5_lego_graph.json
     - Adjacency graph showing which LEGOs appear near each other
     - Edge weights indicate co-occurrence frequency

  2. **Load FCFS Ordering**:
     - Read: vfs/phase_outputs/phase_2_corpus_intelligence.json
     - Chronological ordering from corpus frequency analysis
     - Ensures pedagogically sound sequence

  3. **Select LEGOs for Each Basket** (20 LEGOs per basket):
     - Maximize edge coverage (expose diverse patterns)
     - Follow FCFS chronological progression
     - Avoid redundant LEGO sequences across baskets
     - Ensure smooth difficulty progression
     - Balance novelty with reinforcement

  **Output of Stage 1**: Ordered list of LEGOs to process

  ### STAGE 2: Phrase Generation (Vocabulary-Constrained)

  **Goal**: Generate d-phrases and e-phrases for each selected LEGO

  ## CRITICAL PER-LEGO VOCABULARY CONSTRAINTS
  **ABSOLUTE RULE**: Each LEGO has DIFFERENT available vocabulary!
  - LEGO #1: NO VOCABULARY AVAILABLE = NO PHRASES POSSIBLE (empty basket)
  - LEGO #2: Can only use LEGO #1 = VERY LIMITED phrases possible
  - LEGO #3: Can only use LEGOs #1-2 = A FEW phrases possible
  - LEGO #N: Can only use LEGOs #1 through #(N-1)

  ## Input Data
  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/

  Read LEGOs from: vfs/courses/{course_code}/LEGO_BREAKDOWNS_COMPLETE.json

  **CRITICAL: Extract ALL LEGOs from two sources:**

  1. **lego_pairs[]** - Both BASE and COMPOSITE LEGOs from Phase 3
     ```javascript
     for (const seed of legoBreakdowns.lego_breakdowns) {
       for (const lego of seed.lego_pairs) {
         allLegos.push({
           lego_id: lego.lego_id,
           target_chunk: lego.target_chunk,
           known_chunk: lego.known_chunk,
           seed_id: seed.seed_id
         });
       }
     }
     ```

  2. **feeder_pairs[]** - Atomic components of COMPOSITE LEGOs (THESE ARE LEGOS TOO!)
     ```javascript
     for (const seed of legoBreakdowns.lego_breakdowns) {
       for (const feeder of seed.feeder_pairs || []) {
         allLegos.push({
           lego_id: feeder.feeder_id,  // Note: feeder_id, not lego_id
           target_chunk: feeder.target_chunk,
           known_chunk: feeder.known_chunk,
           seed_id: seed.seed_id,
           parent_lego_id: feeder.parent_lego_id  // Track which COMPOSITE this feeds
         });
       }
     }
     ```

  **WHY process feeder_pairs:**
  - A feeder might introduce NEW vocabulary not yet seen (needs its own basket)
  - A feeder might be a DUPLICATE of an existing LEGO (Phase 5.5 dedup handles this)
  - We can't know which without processing ALL of them
  - Phase 5.5 deduplication will remove duplicate baskets, keeping first occurrence

  **Total LEGOs to process:**
  - Spanish: ~115 (89 lego_pairs + 26 feeder_pairs)
  - Italian: ~115 (90 lego_pairs + 25 feeder_pairs)
  - French: ~116 (90 lego_pairs + 26 feeder_pairs)
  - Mandarin: ~103 (92 lego_pairs + 11 feeder_pairs)

  ## E-PHRASES (5 Eternal Practice Phrases per LEGO)

  ## E-PHRASE CRITICAL REQUIREMENTS (NON-NEGOTIABLE)

  ### Length Requirements (ABSOLUTE)
  - **MINIMUM**: 7 words in target language
  - **IDEAL**: 10 words in target language
  - **MAXIMUM**: 15 words (hard cap)
  - Short e-phrases (< 7 words) are a CRITICAL FAILURE
  - Better to have NO e-phrase than a short/clunky one

  ### Quality Requirements (ABSOLUTE)
  - QUALITY > QUANTITY: Do not force bad phrases to hit a count
  - E-phrases must be NATURAL and conversational in BOTH languages
  - If vocabulary is insufficient for quality 10-word phrase, skip it
  - Aim for 3-5 excellent e-phrases per basket (not forced to 5)

  ### Target Language Grammar (UNFORGIVEABLE ERRORS)
  âš ï¸ **POOR SYNTAX IN TARGET LANGUAGE IS UNFORGIVEABLE** âš ï¸

  For Italian specifically:
  - "cercare" + infinitive REQUIRES "di": "cercando di parlare" NOT "cercando parlare"
  - "imparare" + infinitive REQUIRES "a": "imparando a parlare" NOT "imparando parlare"
  - "provare" + infinitive REQUIRES "a": "provando a dire" NOT "provando dire"
  - "continuare" + infinitive REQUIRES "a": "continuando a parlare" NOT "continuando parlare"
  - "finire" + infinitive REQUIRES "di": "finendo di parlare" NOT "finendo parlare"

  **VALIDATE EVERY E-PHRASE**:
  - Is the target language grammar PERFECT?
  - Would a native speaker say this naturally?
  - Are all required prepositions present?

  If you cannot ensure perfect target language grammar, DO NOT include the phrase.

  ---

  Create 5 phrases, each 7-10 words (balanced across 7/8/9/10):
  - **MUST contain the target LEGO**
  - **Perfect grammar** in BOTH languages - validate target AND known language
  - **Natural, conversational** - things people actually say in BOTH languages
  - **Smooth pronunciation** - not clunky or awkward in either language
  - **Variety in position** - LEGO at different positions in phrase
  - **BILINGUAL VALIDATION**: Each phrase must be:
    - Grammatically correct in target language
    - Grammatically correct in known language
    - Semantically meaningful in BOTH languages
    - Natural and idiomatic in BOTH cultures

  ### CRITICAL RULE - CULMINATING LEGOs (ABSOLUTE REQUIREMENT)

  **Definition**: A "culminating LEGO" is the LAST LEGO in a seed's decomposition

  **How to identify**:
  - Check the LEGO's seed_id (e.g., S0005L02)
  - Look up the seed in Phase 3 LEGO breakdown
  - If this is the highest L-number for that seed â†’ it's culminating

  **ABSOLUTE RULE**:
  - **E-phrase #1 MUST be the COMPLETE SEED sentence itself**
  - Not a variation, not similar - the EXACT seed sentence
  - This complete seed MUST also appear 3+ times in D-phrases

  **Example**:
  - Seed S0005: "Sto per esercitarmi a parlare"
  - LEGOs: S0005L01 (sto per) + S0005L02 (esercitarmi a parlare)
  - S0005L02 is culminating (last LEGO)
  - Therefore: S0005L02 basket MUST have E-phrase #1 = "Sto per esercitarmi a parlare"

  **Validation**:
  - Before finalizing basket, check if LEGO is culminating
  - If yes, verify E-phrase #1 is complete seed
  - If not, regenerate basket

  ## VOCABULARY SELECTION (Recency Guidelines - for LEGOs 50+)
  **For early LEGOs (1-50):** Use whatever vocabulary is available - there's not enough yet for recency preferences.

  **For later LEGOs (50+):** When building E-phrases, PREFER recent vocabulary:
  - ~50% of vocabulary from recent seeds (N-5 to N-1)
  - ~25% from medium-recent (N-20 to N-1)
  - ~25% from all earlier seeds

  BUT ALWAYS PRIORITIZE natural, useful phrases over strict percentages.

  ## D-PHRASES (Auto-Generated Debuts)

  ### D-PHRASE QUALITY ALLOWANCE

  **Important**: D-phrases CAN be somewhat clunky or fragment-like
  - They are expanding windows from e-phrases (2-lego, 3-lego, 4-lego, 5-lego)
  - Syntactic correctness required, but naturalness is less critical
  - Focus: Help learners build up to full e-phrases gradually

  **Contrast with E-phrases**:
  - E-phrases: MUST be natural, conversational, perfect grammar
  - D-phrases: Can be awkward fragments as long as syntax is correct

  ---

  You will generate D-phrases using expanding window from E-phrases:
  - 2x 2-LEGO phrases
  - 2x 3-LEGO phrases
  - 2x 4-LEGO phrases
  - 2x 5-LEGO phrases
  ALL 5 E-phrases must contribute to D-phrases (variety is key).

  **CRITICAL RULE: OPERATIVE LEGO MUST BE PRESENT**
  - EVERY d-phrase MUST contain the operative LEGO (the LEGO this basket teaches)
  - Example: If basket is for "Quiero" (S0001L01), ALL d-phrases must contain "Quiero"
  - You CANNOT extract arbitrary contiguous windows - only windows containing the operative LEGO

  **CORRECT EXTRACTION (Basket for "Quiero"):**
    E-phrase: "Quiero hablar espaÃ±ol contigo ahora"
    - 2-LEGO: "Quiero hablar" âœ… (contains "Quiero")
    - 3-LEGO: "Quiero hablar espaÃ±ol" âœ… (contains "Quiero")
    - 4-LEGO: "Quiero hablar espaÃ±ol contigo" âœ… (contains "Quiero")

  **INCORRECT EXTRACTION (Basket for "Quiero"):**
    - 2-LEGO: "hablar espaÃ±ol" âŒ (missing "Quiero")
    - 3-LEGO: "espaÃ±ol contigo ahora" âŒ (missing "Quiero")

  **BILINGUAL SYNTAX RULES FOR D-PHRASES:**
  - D-phrases can be fragments (don't need to be complete sentences)
  - BUT they MUST be syntactically correct as far as they go in BOTH languages
  - Examples:
    - âœ… "quiero hablar" / "I want to speak" (fragment but correct in both)
    - âœ… "espaÃ±ol contigo" / "Spanish with you" (fragment but correct in both)
    - âŒ "quiero de" / "I want of" (syntactically broken in both)
    - âŒ "hablar yo" / "speak I" (wrong word order in both)
  - Always validate BOTH the target AND known language versions

  **For CULMINATING LEGOs:** Use the complete seed (E1) in at least:
  - 1x in 2-LEGO phrases
  - 1x in 3-LEGO phrases
  - 1x in 4 or 5-LEGO phrases
  This reinforces the complete seed understanding!

  ## VALIDATION REQUIREMENTS
  1. For EACH LEGO's basket:
     - If NO valid phrases can be made: Output {"e_phrases": [], "d_phrases": {}}
     - If only 1-2 phrases possible: Use what's available, don't force 5 phrases
     - EVERY word MUST come from the available vocabulary list

  2. NEVER use:
     - Words from LEGOs that haven't been learned yet
     - Words not in a LEGO (no "y", "de", "el" unless they're in a LEGO)
     - Made-up words to fill space

  3. Expected pattern for early LEGOs:
     - LEGO #1: NO PHRASES POSSIBLE (empty basket)
     - LEGO #2: Maybe 1 meaningful combination if semantically valid
     - LEGO #3: 1-3 phrases depending on semantic validity
     - Only after ~10-15 LEGOs will you have enough vocabulary for D-phrases
     - Only after ~50-100 LEGOs will you have enough vocabulary for full E-phrase baskets

  4. SEMANTIC VALIDITY RULES:
     - All phrases must be grammatically AND semantically correct in BOTH languages
     - Consider actual language usage and meaning
     - Validate each combination for real-world meaningfulness

  ## Output Format
  Save to: vfs/courses/{course_code}/lego_baskets.json

  **IMPORTANT: Use BOTH lego_id AND feeder_id as keys**

  {
    "S0001L01": {
      "lego": ["Quiero", "I want"],
      "e": [
        ["Quiero hablar espaÃ±ol.", "I want to speak Spanish."],
        ["Quiero practicar contigo ahora.", "I want to practice with you now."],
        ["No quiero adivinar.", "I don't want to guess."],
        ["Quiero recordar esto.", "I want to remember this."],
        ["Quiero intentar hablar mÃ¡s.", "I want to try to speak more."]
      ],
      "d": {
        "2": [["Quiero hablar", "I want to speak"], ["hablar espaÃ±ol", "to speak Spanish"]],
        "3": [["Quiero hablar espaÃ±ol", "I want to speak Spanish"], ["No quiero hablar", "I don't want to speak"]],
        "4": [["No quiero hablar ahora", "I don't want to speak now"], ...],
        "5": [["Quiero hablar espaÃ±ol contigo ahora", "I want to speak Spanish with you now"], ...]
      }
    },
    "S0001L02": { ... },
    "S0015F01": {
      "lego": ["parler", "to speak"],
      "e": [
        ["Je veux parler franÃ§ais maintenant avec toi ici.", "I want to speak French now with you here."],
        ["Parler franÃ§ais est important pour moi aujourd'hui.", "Speaking French is important to me today."]
      ],
      "d": {
        "2": [["veux parler", "want to speak"], ["parler franÃ§ais", "to speak French"]],
        "3": [["veux parler franÃ§ais", "want to speak French"], ...],
        "4": [...],
        "5": [...]
      }
    }
  }

  Format: { "lego_id_or_feeder_id": { lego: [target, known], e: [[t,k]...], d: {window_size: [[t,k]...]} } }

  **Key naming rules:**
  - Regular LEGOs use lego_id format: "S0001L01", "S0001L02", etc.
  - Feeder LEGOs use feeder_id format: "S0015F01", "S0015F02", etc.
  - Both are treated identically during basket generation
  - Phase 5.5 deduplication will remove duplicates (e.g., if S0015F01 duplicates S0001L02)

  Notes:
  - LEGO field contains the core teaching unit itself
  - "e" array contains e-phrases (7-10 words, natural conversational phrases)
  - "d" object contains d-phrases organized by window size ("2", "3", "4", "5")
  - Window size refers to number of LEGOs combined in the phrase
  - All phrases are [target, known] pairs

  ## Success Criteria

  **Stage 1 (Extraction):**
  âœ“ All lego_pairs[] extracted and processed
  âœ“ All feeder_pairs[] extracted and processed (CRITICAL - don't miss these!)
  âœ“ Both types use correct ID field (lego_id vs feeder_id)
  âœ“ Total LEGO count matches expected: lego_pairs + feeder_pairs

  **Stage 2 (Generation):**
  âœ“ Every LEGO has d-phrases and e-phrases (even if empty for early LEGOs)
  âœ“ All vocabulary constraints respected
  âœ“ E-phrases are natural and conversational in BOTH languages
  âœ“ D-phrases are syntactically correct in BOTH languages
  âœ“ Culminating LEGOs include complete seed as E-phrase #1
  âœ“ Progressive difficulty from LEGO #1 to last LEGO

  **Combined Result:**
  âœ“ Baskets generated for ALL LEGOs (both lego_pairs and feeder_pairs)
  âœ“ Basket count = lego_pairs count + feeder_pairs count (before deduplication)
  âœ“ Spanish: ~115 baskets, Italian: ~115, French: ~116, Mandarin: ~103
  âœ“ Pedagogical soundness through vocabulary constraints
  âœ“ Optimal learning sequence with rich practice

## Phase 5.5: Basket Deduplication

NAME: "Basket Deduplication"
PURPOSE: Remove duplicate LEGO baskets, keeping first occurrence with full provenance
INPUT: vfs/courses/{course_code}/lego_baskets.json (ALL lego_pairs AND feeder_pairs baskets)
OUTPUT: vfs/courses/{course_code}/baskets_deduplicated.json

WHY_THIS_APPROACH:
  - Phase 5 creates baskets for ALL LEGOs: lego_pairs[] AND feeder_pairs[] (e.g., ~115 baskets per course)
  - Many LEGOs appear in multiple seeds (e.g., "parlare" in S0001L02, S0003L02, S0005L04)
  - Feeders often duplicate existing LEGOs (e.g., S0015F01 "parler" duplicates S0001L02 "parler")
  - Each basket created with full SEED_PAIR context (culminating LEGO rule works naturally)
  - Deduplication is simple: DELETE duplicate baskets, KEEP first occurrence

**EXPECTED DUPLICATE PATTERNS:**
  - Spanish: ~115 baskets â†’ ~89 after dedup (26 feeder duplicates expected)
  - Italian: ~115 baskets â†’ ~90 after dedup (25 feeder duplicates expected)
  - French: ~116 baskets â†’ ~90 after dedup (26 feeder duplicates expected)
  - Mandarin: ~103 baskets â†’ ~92 after dedup (11 feeder duplicates expected)

DEDUPLICATION_PROCESS:

  1. **Identify Duplicates**:
     - Group baskets by LEGO text (case-insensitive: target + known)
     - Example: "parlare"/"to speak" appears as S0001L02, S0003L02, S0005F01, S0015F02
     - All four have identical LEGO text â†’ duplicates

  2. **Determine First Occurrence**:
     - Sort by FCFS order (from Phase 2)
     - First occurrence = lowest seed number
     - Example: S0001L02 comes before S0003L02 and S0005L04

  3. **Delete Duplicates**:
     - KEEP: S0001L02 basket (first occurrence)
     - DELETE: S0003L02 basket (duplicate)
     - DELETE: S0005L04 basket (duplicate)

  4. **Track Provenance**:
     - Create mapping: {"S0003L02": "â†’ S0001L02", "S0005L04": "â†’ S0001L02"}
     - This enables seed reconstruction (S0005 needs "parlare" â†’ use L0002)
     - Store in: vfs/courses/{course_code}/lego_provenance_map.json

CRITICAL_RULES:
  - NEVER merge basket phrases (just delete entire duplicate baskets)
  - ALWAYS keep first occurrence (FCFS principle)
  - ALWAYS track provenance mapping (for seed reconstruction)
  - Basket IDs stay as-is (S0001L02 remains S0001L02, not renumbered to L0002)

OUTPUT_STRUCTURE:

  baskets_deduplicated.json:
  {
    "S0001L01": { basket for "Voglio" },
    "S0001L02": { basket for "parlare" },    â† Kept (first occurrence)
    "S0001L03": { basket for "italiano" },
    // S0003L02 deleted (duplicate of S0001L02)
    "S0003L01": { basket for "come" },
    "S0003L03": { basket for "il piÃ¹" },
    ...
  }

  lego_provenance_map.json:
  {
    "S0003L02": "S0001L02",
    "S0005L04": "S0001L02",
    ...
  }

EXAMPLE:

  Before deduplication (150 baskets):
  - S0001L02: "parlare"
  - S0003L02: "parlare" (duplicate)
  - S0005L04: "parlare" (duplicate)

  After deduplication (~80 baskets):
  - S0001L02: "parlare" (kept)
  - Mapping: {"S0003L02": "S0001L02", "S0005L04": "S0001L02"}

SUCCESS_CRITERIA:
  âœ“ All duplicate baskets identified
  âœ“ Only first occurrence baskets kept
  âœ“ Provenance mapping complete
  âœ“ Reduction from ~150 to ~80 baskets (typical)
  âœ“ Ready for Phase 6 (introductions)

## Phase 6: Introductions

NAME: "Introductions"
PURPOSE: Generate known-only priming phrases
METHODOLOGY: See `skills/introductions-skill/` for complete methodology and bundled script
INPUT:
  - vfs/amino_acids/baskets/*.json
  - vfs/amino_acids/legos_deduplicated/*.json
OUTPUT: vfs/amino_acids/introductions/{uuid}.json

ABSOLUTE_RULE: Zero unknown elements allowed in introductions

KNOWN_ONLY_PRINCIPLE:
  - For each basket, identify ALL LEGOs from PREVIOUS baskets
  - These form the "known set"
  - Introduction phrases use ONLY known LEGOs
  - NO new vocabulary or structures
  - Goal: Activate prior knowledge, build confidence

WHY_CRITICAL:
  - Reduces cognitive load before new learning
  - Builds learner confidence (100% comprehension)
  - Primes brain for new content
  - Creates smooth entry point to each basket

VALIDATION:
  - Double-check: NO new LEGOs in introductions
  - Every word/phrase must be from known set
  - Absolute rule - no exceptions

INTRODUCTION_STRUCTURE:
  uuid: deterministic based on content + basket reference
  basket_uuid: which basket this introduction precedes
  phrases: ["phrase1", "phrase2", ...] (using only known LEGOs)
  known_legos_used: ["uuid1", "uuid2", ...] (which known LEGOs were used)
  validation:
    all_known: true
    unknown_count: 0 (MUST be zero)

PROMPT: |
  # Phase 6: Introductions

  ## Task
  Generate known-only introduction phrases for each basket to prime learners with zero unknowns.

  ## Input
  - Basket amino acids: vfs/amino_acids/baskets/*.json
  - Deduplicated LEGOs: vfs/amino_acids/legos_deduplicated/*.json

  ## Your Mission
  For each basket:
  1. **Identify Known LEGOs**:
     - Scan ALL previous baskets (baskets 1 to N-1)
     - Compile complete inventory of LEGOs learner has mastered
     - These are the ONLY LEGOs you can use

  2. **Generate Introduction Phrases**:
     - Create warm-up phrases using ONLY known LEGOs
     - ZERO unknown vocabulary or structures
     - Goal: Activate prior knowledge, build confidence
     - Prepare learner for new basket content

  3. **Validate Known-Only Rule**:
     - Double-check: NO new LEGOs in introductions
     - Every word/phrase must be from known set
     - Absolute rule - no exceptions

  4. **Create Introduction Amino Acids**:
     - Deterministic UUID based on content + basket reference
     - Store: vfs/amino_acids/introductions/{uuid}.json

  ## Introduction Amino Acid Structure
  {
    "uuid": "...",
    "basket_uuid": "...",
    "phrases": ["phrase1", "phrase2", ...],
    "known_legos_used": ["uuid1", "uuid2", ...],
    "validation": {
      "all_known": true,
      "unknown_count": 0
    }
  }

  ## Why This Matters
  - Reduces cognitive load before new learning
  - Builds learner confidence (100% comprehension)
  - Primes brain for new content
  - Creates smooth entry point to each basket

  ## CRITICAL RULE
  **ZERO unknown elements allowed in introductions.**
  If you're unsure, DON'T use it.

  ## Success Criteria
  âœ“ Introduction generated for each basket
  âœ“ All LEGOs verified as "known" from previous baskets
  âœ“ Zero unknown elements (validated)
  âœ“ Introduction amino acids stored
  âœ“ Course ready for final compilation

# =============================================================================
# QUALITY VALIDATION & SELF-ASSESSMENT (v7.4)
# =============================================================================

## Overview: The Recursive Improvement Loop

The system implements a continuous quality improvement loop inspired by Self-Adapting Language Models (SEAL), combining automated Claude self-assessment with human oversight to achieve iterative convergence on high-quality output.

## The Complete Learning Cycle

```
ITERATION 1:
  Generate Course â†’ Claude Self-Assessment â†’ 85% quality â†’ Flags issues
       â†“
  Human Review â†’ Identifies prompt gaps â†’ Updates APML â†’ Learns patterns
       â†“
  Regenerate Course

ITERATION 2:
  Generate Course â†’ Claude Self-Assessment â†’ 92% quality â†’ Minor issues
       â†“
  Quick human check â†’ One prompt tweak â†’ Pattern reinforced
       â†“
  Regenerate Course

ITERATION 3:
  Generate Course â†’ Claude Self-Assessment â†’ 97% quality â†’ Meets threshold
       â†“
  âœ… Done! â†’ Learned patterns committed â†’ Next course starts better
```

## Dual Quality Signal (Better than Pure RL)

Unlike pure reinforcement learning approaches (e.g., SEAL), we use TWO quality signals:

1. **Claude's Self-Assessment**: Automated syntax, FD, and semantic validation
2. **Human Expert Review**: Pedagogical judgment and edge case identification

This hybrid approach provides:
- Higher signal quality (human expertise)
- Faster iteration (automated pre-filtering)
- No catastrophic forgetting (prompt-based accumulation)
- Explainable decisions (traceable to rules)

## Phase 3.9: Automated Quality Validation

TRIGGERED: Automatically after Phase 3 (LEGO Decomposition)
PURPOSE: Validate APML compliance before human review
IMPLEMENTATION: vfs/courses/validate-lego-breakdowns.cjs
OUTPUT: Terminal report + optional JSON log

VALIDATION_SCRIPT_USAGE:

```bash
# Validate single course
cd vfs/courses
node validate-lego-breakdowns.cjs spa_for_eng_30seeds

# Validate all courses
node validate-lego-breakdowns.cjs --all
```

AUTOMATED_CHECKS:

1. **FD_LOOP Compliance** (CRITICAL)
   - Tests: target â†’ known â†’ target must be IDENTICAL
   - Detects: Subjunctive/conditional forms without context
   - Example violation: "pueda" / "I can" (ambiguous)
   - Correct: "en cuanto pueda" / "as soon as I can"
   - Auto-detects: Spanish/Italian/French subjunctive patterns

2. **IRON RULE Enforcement** (CRITICAL)
   - No standalone prepositions without objects
   - Detects: "con" / "with", "de" / "of", "Ã " / "to"
   - Correct: "con te" / "with you" (complete prepositional phrase)
   - Checks: Both target and known chunks

3. **CHUNK UP Principle** (HIGH)
   - Context-dependent forms must include disambiguating context
   - Detects: Gender-ambiguous words without nouns
   - Example: "su" â†’ should be "su nombre" for FD clarity
   - Language-aware: Checks Spanish/Italian/French/German patterns

4. **Translation Synchronization** (CRITICAL)
   - LEGO breakdown matches seed_pairs.json exactly
   - Detects: Mismatches in original_target/original_known
   - Ensures: Regenerated LEGOs use updated Phase 1 translations

5. **Structure Validation** (HIGH)
   - All required fields present (lego_id, lego_type, chunks, fd_validated)
   - No empty chunks
   - Valid lego_type values (BASE or COMPOSITE)

6. **COMPOSITE Validation** (MEDIUM)
   - COMPOSITEs have componentization explanations
   - COMPOSITE components listed in feeder_pairs (recommended)
   - Pedagogically useful decomposition

SEVERITY_LEVELS:

CRITICAL (Must Fix):
  - IRON_RULE_VIOLATION: Standalone prepositions
  - FD_VALIDATION_FAILED: fd_validated: false in output
  - TRANSLATION_MISMATCH: Doesn't match seed_pairs.json
  - EMPTY_CHUNK: Empty target_chunk or known_chunk

HIGH (Should Fix):
  - FD_CONTEXT_MISSING: Subjunctive without temporal clause
  - TRANSLATION_MISSING: Seed not found in seed_pairs.json
  - MISSING_FIELD: Required field absent

MEDIUM (Fix If Time):
  - FD_GENDER_AMBIGUOUS: Gender word without noun (reduces clarity)
  - MISSING_COMPONENTIZATION: COMPOSITE lacks explanation

LOW (Optional):
  - MISSING_FEEDERS: COMPOSITE has no feeder_pairs (may be intentional)

VALIDATION_OUTPUT_EXAMPLE:
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LEGO BREAKDOWNS VALIDATION REPORT
Course: spa_for_eng_30seeds
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SUMMARY
  Total Issues: 2
  CRITICAL: 0
  HIGH: 0
  MEDIUM: 0
  LOW: 2

â„¹ï¸  MEDIUM/LOW PRIORITY ISSUES
  0 medium priority, 2 low priority
  Run with --verbose to see all issues

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… VALIDATION PASSED - No critical or high-priority issues
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

ITERATION_STRATEGY:

When Validation Fails:
  1. CRITICAL/HIGH issues â†’ MUST regenerate or manually fix
  2. MEDIUM issues â†’ Fix if time permits
  3. LOW issues â†’ Accept (agent non-determinism may not improve)

Regeneration Decision Matrix:
  - >10% seeds with CRITICAL â†’ Full regeneration with improved prompt
  - Systematic pattern (e.g., all subjunctives fail) â†’ Update prompt, regenerate
  - 1-2 isolated CRITICAL â†’ Manual fix faster
  - Only LOW/MEDIUM â†’ Ship it (next generation may be worse)

Multi-Pass Strategy (for non-deterministic agents):
  1. Generate version A
  2. Validate â†’ Record scores
  3. Generate version B
  4. Validate â†’ Record scores
  5. Compare: Pick version with fewer CRITICAL/HIGH issues
  6. If tied, pick version with higher MEDIUM/LOW tolerance

AUTOMATED_ORCHESTRATION:

Script: vfs/courses/process-phase-3-with-validation.cjs

Usage:
```bash
# Single course with automatic retries
node process-phase-3-with-validation.cjs spa_for_eng_30seeds

# Specify max retry attempts
node process-phase-3-with-validation.cjs spa_for_eng_30seeds --max-attempts=5

# Process all courses
node process-phase-3-with-validation.cjs --all
```

Features:
  - Automatic validation after generation
  - Multi-attempt strategy with backups
  - Comparative scoring across attempts
  - Recommendation of best attempt
  - Batch processing support

Workflow:
  1. Generate LEGO decompositions (Phase 3)
  2. Backup existing if regenerating
  3. Run validation (Phase 3.9)
  4. If PASS â†’ Done
  5. If FAIL with CRITICAL/HIGH â†’ Retry (up to max-attempts)
  6. Compare all attempts â†’ Recommend best
  7. User selects final version

INTEGRATION_WITH_PHASE_3_PROMPT:

When generating LEGOs, the agent should be aware that validation will run.
Include in Phase 3 agent prompt:

"Your output will be automatically validated for:
- FD_LOOP compliance (CRITICAL)
- IRON RULE enforcement (CRITICAL)
- Translation synchronization (CRITICAL)
- CHUNK UP principle (HIGH)
- Structure completeness (HIGH)

Focus especially on:
1. Subjunctive forms â†’ Must include temporal context
2. Standalone prepositions â†’ Must include objects
3. Gender-ambiguous words â†’ Must include nouns
4. fd_validated field â†’ Must be true for all LEGOs

Validation severity levels will be reported. Aim for ZERO CRITICAL/HIGH issues."

## Automatic Self-Learning from Manual Edits

WHEN: User manually corrects LEGO breakdown in dashboard
TRIGGERED: PUT /api/courses/:code/seeds/:seedId/lego-breakdown

PROCESS:
1. **Pattern Extraction**: learnFromManualEdit() analyzes differences
2. **Rule Creation**: Pattern becomes "experimental" rule (confidence: 50%)
3. **Auto-Promotion**:
   - 5+ occurrences â†’ "validated" (confidence: 80%)
   - 10+ occurrences â†’ "committed" (confidence: 95%)
4. **Prompt Injection**: commitRuleToPrompt() updates Phase 3 DNA
5. **Next Generation**: New courses automatically use evolved prompts

STORAGE: vfs/courses/{courseCode}/learned_rules.json

STRUCTURE:
```json
{
  "rules": [
    {
      "type": "merge" | "split" | "boundary_shift",
      "description": "Consider larger LEGO chunks for verb + prep + inf",
      "occurrences": 12,
      "confidence": 0.95,
      "status": "committed",
      "first_seen": "2025-10-14T10:23:00Z",
      "last_seen": "2025-10-14T15:42:00Z",
      "effectiveness": {
        "courses_applied": ["ita_for_eng_574seeds", "spa_for_eng_668seeds"],
        "quality_impact": +0.08,
        "success_rate": 0.91
      }
    }
  ],
  "manual_edits": [
    {
      "seed_id": "S0042",
      "timestamp": "2025-10-14T15:42:00Z",
      "original_count": 3,
      "edited_count": 2,
      "patterns": [
        {
          "type": "merge",
          "description": "Human merged 3 LEGOs into 2",
          "learned_rule": "Consider larger LEGO chunks for this pattern"
        }
      ]
    }
  ]
}
```

PATTERN_TYPES:

MERGE: Human combines multiple AI-generated LEGOs into one
  - Learns: "Consider larger LEGO chunks for this pattern"
  - Example: ["voy", "a", "decir"] â†’ ["voy a decir"]

SPLIT: Human breaks one AI-generated LEGO into multiple
  - Learns: "Consider smaller LEGO chunks for this pattern"
  - Example: ["quiero hablar espaÃ±ol"] â†’ ["quiero", "hablar espaÃ±ol"]

BOUNDARY_SHIFT: Human adjusts LEGO boundaries
  - Learns: "Adjust chunk boundaries at this linguistic marker"
  - Example: ["estoy feliz"] â†’ ["estoy", "feliz"] (temporary vs state)

## API Endpoints for Quality Loop

GET /api/courses/:code/quality-assessment
  - Retrieve Claude's self-assessment report
  - Returns quality_assessment.json with all metrics
  - Used by dashboard to show quality scores

GET /api/courses/:code/learned-rules
  - View all learned rules (experimental/validated/committed)
  - Returns learned_rules.json with effectiveness data
  - Powers LearnedRulesView.vue dashboard

POST /api/courses/:code/regenerate
  - Trigger regeneration after prompt improvements
  - Parameters: { phases: [3, 5], reason: "Fix FD compliance issues" }
  - Creates new quality assessment cycle

## Dashboard Components

QualityDashboard.vue:
  - Display overall quality scores
  - Show Claude's self-assessment metrics
  - Highlight issues flagged for human review
  - Track improvement across iterations

LearnedRulesView.vue:
  - Summary stats (experimental/validated/committed counts)
  - Rule lifecycle visualization
  - Recent manual edits display
  - Rule effectiveness tracking

PromptEvolutionView.vue:
  - Version history of prompt changes
  - Correlation with quality improvements
  - A/B comparison of different prompt versions

## Key Advantage Over Pure RL (e.g., SEAL)

SEAL Paper Problem: Catastrophic forgetting - new updates overwrite previous learning

OUR SOLUTION: Prompt-based accumulation with no forgetting
  âœ… Rules are additive (append, don't overwrite)
  âœ… Each rule is versioned and traceable
  âœ… Can selectively disable rules without data loss
  âœ… Human oversight prevents harmful updates
  âœ… Explainable: Every rule traces to specific manual edits

## The Meta-Insight

Every manual correction makes the system smarter. After 10 similar corrections, the pattern is automatically committed to prompt DNA and applied to all future courses.

**This is true recursive self-improvement: the system learns how to learn better.**

Unlike weight-based approaches, our prompt-based learning:
- Accumulates without forgetting
- Is human-auditable (can read the rules)
- Can be selectively controlled (enable/disable rules)
- Generalizes across language pairs (rules transfer)

IMPLEMENTATION:
  - learnFromManualEdit() [automation_server.cjs:2010-2127]
  - commitRuleToPrompt() [automation_server.cjs:2133-2170]
  - Quality assessment integration [planned]

# =============================================================================
# DASHBOARD INTERFACE SPECIFICATIONS
# =============================================================================

## Interface Section 1: Course Generation Pipeline

COMPONENTS:
  - CourseGeneration.vue (main generation interface)
  - ProcessOverview.vue (phase progress visualization)
  - TrainingPhase.vue (phase documentation and prompt display)

CRITICAL_FEATURE: TrainingPhase.vue displays ACTUAL prompts from registry
  - Fetches from: GET /api/registry/phase-prompts/:phase
  - Shows working reality (not generic docs)
  - Editable textarea allows prompt updates
  - Updates POST to: PUT /api/registry/phase-prompts/:phase
  - Creates version history for every change

DATA_FLOW:
  User selects languages + seed count
    â†“
  POST /api/courses/generate
    â†“
  automation_server.cjs creates job
    â†“
  cascadePhases() reads PHASE_PROMPTS from registry
    â†“
  spawnPhaseAgent() via osascript
    â†“
  Claude Code receives actual working prompts
    â†“
  Outputs saved to VFS
    â†“
  Dashboard polls: GET /api/courses/:code/status
    â†“
  Displays results in real-time

## Interface Section 2: Quality Review & Self-Healing

COMPONENTS:
  - QualityDashboard.vue (overview and metrics)
  - SeedQualityReview.vue (individual seed review)
  - PromptEvolutionView.vue (prompt version history)

PURPOSE:
  - Visual review of all phase outputs
  - Flag problematic seeds for regeneration
  - Track prompt evolution over time
  - Self-healing: automatic rerun of failed extractions

## Interface Section 3: Visualization & Editing

COMPONENTS:
  - LegoVisualizer.vue (visual LEGO breakdown display)
  - SeedVisualizer.vue (seed pair visualization)
  - PhraseVisualizer.vue (phrase pattern visualization)
  - CourseEditor.vue (edit translations and LEGOs)

EDIT_WORKFLOW:
  User edits translation in UI
    â†“
  PUT /api/courses/:code/translations/:uuid
    â†“
  Triggers regeneration of affected phases
    â†“
  Phase 3+ re-run with updated translation
    â†“
  Dashboard shows updated results

## Interface Section 4: APML Specification & Docs

COMPONENTS:
  - APMLSpec.vue (displays this specification)
  - Dashboard.vue (main navigation)
  - PROJECT-DASHBOARD.html (auto-generated from APML)

SELF_DOCUMENTATION:
  - This APML file is the single source of truth
  - Dashboard components fetch from this specification
  - Changes to APML regenerate documentation
  - No drift between docs and reality

# =============================================================================
# COMPILATION & DEPLOYMENT
# =============================================================================

## Compilation Process

1. **Parse APML Specification**
   - Read ssi-course-production.apml
   - Extract Variable Registry
   - Extract Phase Prompts
   - Extract Interface Specs

2. **Generate .apml-registry.json**
   - Machine-readable format for runtime access
   - Contains all PHASE_PROMPTS
   - Contains all API endpoints
   - Contains all configuration

3. **Update automation_server.cjs**
   - Replace hardcoded PHASE_PROMPTS with registry import
   - const apmlRegistry = require('./.apml-registry.json');
   - const PHASE_PROMPTS = apmlRegistry.variable_registry.PHASE_PROMPTS;

4. **Update TrainingPhase.vue**
   - Fetch prompts from: GET /api/registry/phase-prompts/:phase
   - Display in editable textarea
   - Enable prompt updates via API

5. **Generate PROJECT-DASHBOARD.html**
   - Auto-generated navigation interface
   - Links to all interface sections
   - Shows current system status

## Deployment

VERCEL_DEPLOYMENT:
  - Dashboard deployed to Vercel (frontend)
  - Includes .apml-registry.json (latest prompts)
  - Includes auto-generated documentation
  - User can access from anywhere

LOCAL_AUTOMATION:
  - automation_server.cjs runs on SSi Mac (port 3456)
  - ngrok tunnel exposes to internet
  - Dashboard connects via tunnel
  - Claude Code executes locally with full intelligence

# =============================================================================
# VERSION HISTORY
# =============================================================================

VERSION: 7.6.0
DATE: 2025-10-15
CHANGES:
  - ğŸ¯ CRITICAL: Added COGNATE PREFERENCE heuristic for seeds 1-100
  - ğŸ¯ CRITICAL: Added VARIATION REDUCTION principle (vocabulary claiming)
  - ğŸ¯ CRITICAL: Added Phase 3.9 automated quality validation system
  - ğŸ”§ NEW: validate-lego-breakdowns.cjs (automated APML compliance checking)
  - ğŸ”§ NEW: process-phase-3-with-validation.cjs (orchestration with auto-retry)
  - Established Progressive Optimization Curve (seeds 1-100, 101-300, 301-668)
  - Heuristic priority now changes based on seed position
  - Seeds 1-100: Cognate-heavy + variation reduction (max learner confidence)
  - Seeds 101-300: Introduce natural alternatives gradually
  - Seeds 301-668: Full idiomatic/colloquial expressions
  - Updated Phase 1 spec (lines 369-477) with detailed examples
  - Updated Phase 1 prompt (lines 559-695) with VOCABULARY REGISTRY process
  - Updated Phase 3.9 spec (lines 2436-2605) with validation workflow
  - Added "First Word Wins" rule for early seeds
  - Cognate examples across Spanish/French/Italian/Mandarin
  - EXCEPTION handling for grammatically required variation (ser/estar, savoir/connaÃ®tre)
  - Automated checks: FD_LOOP, IRON RULE, CHUNK UP, Translation Sync, Structure
  - Severity levels: CRITICAL/HIGH/MEDIUM/LOW with iteration strategies
  - Multi-attempt comparison strategy for non-deterministic agent generation
  - Based on analysis of overnight generation showing excessive variation in seeds 1-30
  - Principle: Get learners into conversation FASTER by reducing cognitive load early
  - Validation ensures quality before human review, supports iterative refinement

VERSION: 7.5.0
DATE: 2025-10-15
CHANGES:
  - ğŸŒ MAJOR: Complete language-agnostic transformation of Phase 3
  - Fixed IRON RULE contradiction: prepositional phrases WITH objects now explicitly ALLOWED
  - Replaced Spanish-only examples with universal principles + diverse language families
  - Added comprehensive FD_LOOP GENDER AND CONTEXT NEUTRALITY section
  - Introduced THE CHUNK UP PRINCIPLE as universal FD rescue strategy
  - Integrated all 10 Phase 3 refinements from Italian 30-seed validation:
    1. IRON RULE clarification (prepositional phrases OK)
    2. Infinitive "to" placement rule
    3. Minimal FD chunks principle
    4. Glue words must stay inside composites
    5. Selective FEEDERS (not exhaustive)
    6. "represents" vs "means" language precision
    7. Function word handling (avoid standalone)
    8. FD violations (gender/context ambiguity)
    9. Building composites hierarchically
    10. CHUNK UP principle (not "context-dependent" labels)
  - Updated FCFS examples to cover 6+ language families (Romance, Germanic, Celtic, Sino-Tibetan, Japonic, Slavic)
  - Added grammatical constraint examples for diverse languages (Spanish, German, Japanese, Mandarin, French)
  - Eliminated language bias: 97 Spanish/Italian-specific references replaced with ${targetLang}/${knownLang} variables
  - Updated both spec (lines 606-731) and prompt (lines 1250-1382) for consistency
  - Based on APML_Phase3_Updates_2025.md + extended language-agnostic analysis

VERSION: 7.4.0
DATE: 2025-10-14
CHANGES:
  - Added "Quality Validation & Self-Assessment" section
  - Documented Phase 3.9: Automated Quality Assessment
  - Formalized Claude self-assessment with quality thresholds
  - Added automatic self-learning from manual edits
  - Documented three-stage rule lifecycle (experimental â†’ validated â†’ committed)
  - Added learned_rules.json structure and pattern types
  - Integrated SEAL paper insights (recursive improvement without forgetting)
  - Added API endpoints for quality loop (quality-assessment, learned-rules, regenerate)
  - Updated dashboard fallback prompts to v7.0 architecture (TrainingPhase.vue)
  - Documented dual quality signal advantage over pure RL approaches
  - Implemented learnFromManualEdit() and commitRuleToPrompt() functions
  - Created LearnedRulesView.vue dashboard component
  - Based on SEAL paper analysis and recursive improvement requirements

VERSION: 7.3.0
DATE: 2025-10-13
CHANGES:
  - Added LEGO type definitions (BASE, COMPOSITE, FEEDERS)
  - Added TILING concept with decision tree
  - Clarified COMPONENTIZATION as pedagogical (not structural)
  - Updated Phase 3 prompt with LEGO architecture extraction logic
  - Examples use "voy a decir" pattern
  - Based on LEGO_ARCHITECTURE_CLARIFICATION_BRIEF.md

VERSION: 7.2.0
DATE: 2025-10-13
CHANGES:
  - Clarified Phase 1 two-step translation architecture (canonicalâ†’targetâ†’known)
  - Clarified IRON RULE: infinitive "to" is NOT a preposition (explicitly allowed)
  - Updated Phase 5 prompt with CRITICAL e-phrase length requirements (7-10 words)
  - Added UNFORGIVEABLE target language grammar validation
  - Strengthened culminating LEGO rule enforcement
  - Clarified e-phrase quality > quantity (3-5 excellent vs forced 5)
  - Added D-phrase quality allowance explanation
  - Based on 30-seed Italian validation findings (QUALITY_REPORT.md)

VERSION: 7.1.0
DATE: 2025-10-13
CHANGES:
  - Added "Human-AI Collaboration Model" section
  - Documented Claude Code agent's role as thinking partner
  - Defined orchestrator pattern for parallel work execution
  - Explained "The Meta-Game" - self-improving system vision
  - Added session initialization checklist
  - Documented self-upregulating intelligence loop
  - Clarified that dashboard IS the living system (not just UI)

VERSION: 7.0.0
DATE: 2025-10-13
CHANGES:
  - Created complete APML specification
  - Documented all 668 canonical seeds
  - Preserved critical Phase 3 intelligence (250+ lines)
  - Added Phase 3.5 (Graph Construction)
  - Updated all batch calculations
  - Defined Variable Registry as single source of truth
  - Specified dashboard interface components
  - Documented compilation and deployment process

PREVIOUS_VERSION: 6.x (scattered across multiple files)
MIGRATION: v6 â†’ v7 consolidated all intelligence into this APML specification

# =============================================================================
# SUCCESS CRITERIA
# =============================================================================

âœ… Complete specification preserves all intelligence
âœ… No information loss during code refactors
âœ… Dashboard shows actual working prompts (not generic docs)
âœ… Edit in UI â†’ updates source â†’ execution and docs stay in sync
âœ… Variable Registry eliminates naming inconsistencies
âœ… APML standard compliance (PSS, Intent Capture, Variable Registry)
âœ… Self-documenting system (specification IS implementation)
âœ… Version controlled (Git tracks every change)
âœ… Published with dashboard (Vercel has latest)
âœ… Claude receives detailed, battle-tested prompts
âœ… Generated courses work perfectly in SSi mobile app

# =============================================================================
# END OF SPECIFICATION
# =============================================================================

For implementation: https://apml.dev/toolchain/
For APML standards: /Users/tomcassidy/APML/apml-dev-website/specifications/

This specification is theæ°¸ä¹…çš„çœŸç† (permanent truth) of the SSi Course Production System.

