app ssi_course_production:
  title: "SSi Language Course Production System"
  version: "7.3.0"
  apml_version: "1.1.0"
  description: |
    Complete specification for SSi (Say Something In) language course production system.
    This system transforms canonical seed sentences into pedagogically optimized
    language learning courses through a 7-phase pipeline orchestrated by Claude Code agents.

  created: "2024-10-13"
  author: "Tom Cassidy / SSi Team"

  pss_compliance:
    structure_standard: "APML-PSS v1.0.0"
    self_documentation: enabled

  deterministic_compilation:
    target_platform: "Vue3 + Node.js + Claude Code"
    compilation_guarantee: "Specification-driven phase orchestration"

# =============================================================================
# SYSTEM OVERVIEW & INTENT
# =============================================================================

## System Purpose

The SSi Course Production System enables:

1. **Automated Course Generation** - Transform 668 canonical English sentences into
   pedagogically optimized courses for ANY target language

2. **Distributed Collaboration** - Web dashboard accessible from any computer tunnels
   to SSi Mac machine running Claude Code (Sonnet 4.5) for AI-powered generation

3. **Self-Documenting Intelligence** - Dashboard displays the ACTUAL prompts used by
   Claude, making the system fully transparent and editable

4. **Quality Assurance** - Visual review and editing of all phase outputs with
   automatic regeneration of affected downstream phases

5. **Course Delivery** - Final JSON manifest drives SSi mobile app, coordinating
   text display with AWS-hosted audio files

## Critical Success Factors

‚úÖ Dashboard shows working reality (not generic documentation)
‚úÖ Edit intelligence in UI ‚Üí updates source ‚Üí execution and docs stay in sync
‚úÖ No intelligence loss during code refactors or UI redesigns
‚úÖ Claude Code agents receive detailed, battle-tested prompts
‚úÖ Generated courses work perfectly in SSi app

## System Architecture

```
User (any computer, any location)
  ‚Üì
Web Dashboard (Vercel-hosted Vue3 app)
  ‚Üì
ngrok Tunnel
  ‚Üì
automation_server.cjs (on SSi Mac, port 3456)
  ‚Üì
osascript (opens Claude Code)
  ‚Üì
Claude Code (Sonnet 4.5) executes phase prompts
  ‚Üì
VFS (Virtual File System) - stores amino acid outputs
  ‚Üì
Dashboard polls for updates, displays results
  ‚Üì
User reviews/edits, triggers regeneration
  ‚Üì
Final JSON manifest ‚Üí SSi mobile app
```

## Self-Upregulating Intelligence

This system is designed as a **recursive self-improvement loop**:

1. **System executes** using APML prompts
2. **Quality issues detected** (human or automated review)
3. **Prompts improved** (edited in dashboard UI)
4. **APML updates** (git commit, registry recompile)
5. **System learns** (documents what worked)
6. **Next execution better** (improved prompts used)
7. **Cycle continues** (recursive improvement)

**Key Insight**: The dashboard IS the living system - not just a UI, but the published SSoT that contains the process, intelligence, training, and evolution engine.

# =============================================================================
# HUMAN-AI COLLABORATION MODEL
# =============================================================================

## Claude Code Agent Role

When a new Claude Code session begins, the agent must understand its role in this self-improving system.

### Primary Role: Thinking Partner, Not Task Executor

**DO**:
- Read this APML specification FIRST (it's the SSoT)
- Understand the system architecture and current state
- Ask clarifying questions about goals and priorities
- Create briefs for orchestrator agents to execute work in parallel
- Stay available in main conversation thread for discussion
- Provide strategic guidance and pattern recognition
- Help interpret quality reports and suggest improvements

**DO NOT**:
- Execute tasks directly (use orchestrator agents instead)
- Block the main conversation with long-running work
- Make changes without understanding the full context
- Assume previous context (each session is fresh - read APML)

### The Orchestrator Pattern

**When work needs to be done**:
1. Create a brief (markdown file with clear instructions)
2. Launch orchestrator agent via Task tool
3. Orchestrator spawns parallel sub-agents as needed
4. Main Claude stays available for conversation
5. Orchestrator reports back when complete

**Example**:
```
User: "Validate the 30-seed quality"
Claude:
  1. Creates ORCHESTRATOR_BRIEF.md
  2. Launches orchestrator with Task tool
  3. Stays in conversation: "Orchestrator launched, I'm here while it works"
  4. Orchestrator does all the work in parallel
  5. Reports back: "‚úÖ Quality validation complete"
```

### Understanding "The Meta-Game"

This is not just a course production system - it's a **meta-framework for self-improving AI systems**.

**The Vision**:
- Dashboard publishes the SSoT (this APML)
- Everything is human-editable AND recursively upgradable
- Quality feedback ‚Üí prompt improvements ‚Üí better output ‚Üí learning
- System becomes self-aware, self-improving, self-documenting
- Pattern generalizes to other complex AI systems

**30-Seed Test**: First proof that recursive improvement loop works in production.

**If This Works**: Validates the pattern for building AGI-like systems that improve themselves through experience.

### Session Initialization Checklist

When a new Claude Code session starts:

1. ‚úÖ **Read APML** - This file is your bible
2. ‚úÖ **Understand current phase** - What are we validating/building?
3. ‚úÖ **Check orchestrator status** - Any agents already running?
4. ‚úÖ **Ask about priorities** - What's most important right now?
5. ‚úÖ **Create briefs, not tasks** - Set up parallel work streams
6. ‚úÖ **Stay conversational** - Be the thinking partner

### Key Files

**This APML**: `/Users/tomcassidy/SSi/ssi-dashboard-v7-clean/ssi-course-production.apml`
- Single source of truth
- Read this FIRST every session

**Dashboard**: `/Users/tomcassidy/SSi/ssi-dashboard-v7-clean/`
- Vue3 app that publishes this APML
- Shows process, prompts, training, evolution

**Automation Server**: `automation_server.cjs`
- API backend (port 3456)
- Executes phase prompts via osascript
- Manages VFS and quality tracking

**VFS**: `/Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/`
- Where all amino acids live
- Organized by course code

**Test Data**: `ita_for_eng_574seeds/`
- 30-seed proof-of-concept
- Validates APML prompts produce quality

### Communication Style

**Be concise**: User operates in command-line mindset
**Be strategic**: Focus on "what and why", not "how"
**Be parallel**: Set up multiple work streams simultaneously
**Be present**: Don't disappear into tasks - stay conversational
**Be humble**: Ask when uncertain, don't assume

### Remember

You are part of a **self-improving system**. Your role is to help guide its evolution, not to be the system itself. Create briefs, launch orchestrators, stay available, provide insight.

**The system improves itself. You help it learn how.**

# =============================================================================
# VARIABLE REGISTRY (Single Source of Truth)
# =============================================================================

## Core Concepts

### Amino Acids
PURPOSE: Immutable components with deterministic UUIDs
DEFINITION: Each phase output is an "amino acid" - a discrete, content-addressed component
UUID_GENERATION: hash(content + metadata) - ensures same content always gets same ID
IMMUTABILITY: Edits create NEW amino acids with updated provenance, never modify originals
PROVENANCE: S{seed}L{position} format tracks birth-parent relationships

### VFS (Virtual File System)
PURPOSE: Organized storage for all course generation artifacts
BASE_PATH: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/
STRUCTURE: {target_code}_for_{known_code}_speakers/
SUBDIRS:
  - amino_acids/translations/
  - amino_acids/legos/
  - amino_acids/legos_deduplicated/
  - amino_acids/baskets/
  - amino_acids/introductions/
  - phase_outputs/
  - proteins/ (compiled manifests)

### Course Codes
FORMAT: "{target_iso}_for_{known_iso}_speakers"
EXAMPLES:
  - fra_for_eng_speakers (French for English speakers)
  - cym_for_eng_speakers (Welsh for English speakers)
  - ita_for_fra_speakers (Italian for French speakers)

## API Endpoints

ENDPOINTS:
  - POST /api/courses/generate
    PURPOSE: Start complete course generation pipeline
    PARAMETERS: { target, known, seeds }
    RETURNS: { courseCode, status }

  - GET /api/courses/:courseCode/status
    PURPOSE: Poll for generation progress
    RETURNS: { phase, progress, status }

  - GET /api/courses/:courseCode
    PURPOSE: Get complete course data
    RETURNS: Course metadata and manifest

  - POST /api/courses/:code/seeds/regenerate
    PURPOSE: Regenerate specific seeds after edits
    PARAMETERS: { seedIds }

  - GET /api/registry/phase-prompts/:phase
    PURPOSE: Fetch actual prompt for phase (from this APML registry)
    RETURNS: { name, prompt, metadata }

  - PUT /api/registry/phase-prompts/:phase
    PURPOSE: Update phase prompt (writes to APML registry)
    PARAMETERS: { prompt, changelog }
    CREATES: New version in prompt history

## Batch Configuration

BATCH_SIZES:
  PHASE_1_TRANSLATION: 100 seeds per batch (easier work, larger batches)
  PHASE_3_LEGO_DECOMPOSITION: 20 seeds per batch (complex work, smaller batches)
  PHASE_5_BASKETS: 20 LEGOs per batch

TOTAL_SEEDS: 668 (canonical SSi corpus)

# =============================================================================
# PHASE SPECIFICATIONS
# =============================================================================

## Phase 0: Corpus Pre-Analysis

NAME: "Corpus Pre-Analysis"
PURPOSE: Analyze source corpus to inform translation decisions
INPUT: vfs/seeds/canonical_seeds.json (668 English seeds)
OUTPUT: vfs/phase_outputs/phase_0_intelligence.json

TASKS:
  1. Calculate word frequency distributions
  2. Identify high-frequency vocabulary and patterns
  3. Assess translation complexity (cognates, false friends)
  4. Map grammatical dependencies and prerequisites
  5. Generate intelligence report for Phase 1 heuristics

CRITICAL_NOTES:
  - Does NOT modify corpus - analysis only
  - Informs Phase 1's 6 pedagogical heuristics
  - Consider learner perspective (what's easy/hard)

PROMPT: |
Test prompt content - updated at 23:51:51

  # Phase 0: Corpus Pre-Analysis

  ## Task
  Analyze the source corpus to generate intelligence data for pedagogical translation.

  ## Input
  - Source corpus (668 canonical seed pairs)
  - Located in: vfs/seeds/canonical_seeds.json

  ## Your Mission
  1. Load and validate the canonical seed corpus
  2. Perform linguistic analysis:
     - Calculate word frequency distributions
     - Identify high-frequency vocabulary and grammatical patterns
     - Assess translation complexity (cognates, false friends, structural challenges)
     - Map grammatical dependencies and prerequisite knowledge
  3. Generate intelligence report with:
     - Frequency rankings for words and phrases
     - Complexity scores for each seed
     - Translation guidance notes (tricky structures, idioms, etc.)
     - Recommendations for Phase 1 heuristic application

  ## Output Format
  Store results as JSON:
  vfs/phase_outputs/phase_0_intelligence.json

  Structure:
  {
    "frequency_analysis": { ... },
    "complexity_scores": { ... },
    "translation_guidance": { ... },
    "recommendations": { ... }
  }

  ## Important Notes
  - DO NOT modify the source corpus - analysis only
  - Focus on patterns that affect pedagogical decisions
  - This intelligence informs Phase 1's 6 heuristics
  - Consider learner perspective (what's easy/hard to learn)

  ## Success Criteria
  ‚úì All 668 seeds analyzed
  ‚úì Intelligence report generated
  ‚úì Frequency rankings accurate
  ‚úì Complexity assessments complete
  ‚úì Ready for Phase 1 consumption

## Phase 1: Pedagogical Translation

NAME: "Pedagogical Translation"
PURPOSE: Apply 6 pedagogical heuristics to create optimal learning translations
INPUT:
  - vfs/seeds/canonical_seeds.json
  - vfs/phase_outputs/phase_0_intelligence.json
OUTPUT: vfs/amino_acids/translations/{uuid}.json (668 translation amino acids)

THE_6_HEURISTICS:
  1. Naturalness - Target language should sound native, not transliterated
  2. Frequency - Prefer high-frequency vocabulary and common structures
  3. Clarity - Prioritize clear, unambiguous expressions over idiomatic complexity
  4. Brevity - Shorter translations preferred when pedagogically equivalent
  5. Consistency - Maintain consistent terminology across seeds
  6. Utility - Maximize teaching value (versatile phrases, reusable structures)

BATCH_PROCESSING:
  BATCH_SIZE: 100 seeds
  BATCHES: 7 total (668 √∑ 100 = 6.68, rounded up to 7)
  NAMING: phase1_batch_001.json, phase1_batch_002.json, etc.

AMINO_ACID_STRUCTURE:
  uuid: hash(source + target + metadata)
  source: original English seed
  target: pedagogically optimized translation
  seed_id: provenance tracking (S0001, S0002, etc.)
  heuristics_applied: array of which heuristics influenced this translation
  metadata: language codes, batch info, timestamp

CRITICAL_RULES:
  - Translations are NOT literal - they are pedagogically optimized
  - Each translation is an immutable amino acid component
  - UUIDs are deterministic (content-based)
  - Preserve seed_id for provenance tracking

TRANSLATION_ARCHITECTURE:
  Phase 1 uses a TWO-STEP translation process to ensure optimal FD_LOOP compliance:

  STEP 1 - Canonical ‚Üí Target (Pedagogical Optimization):
    - Start with English canonical seed
    - Apply all 6 pedagogical heuristics
    - Generate pedagogically optimized target language translation
    - This becomes the "source of truth"

  STEP 2 - Target ‚Üí Known (Back-Translation):
    - Take the optimized target translation from Step 1
    - Translate it into the known language
    - Ensure known translation MATCHES target's structure
    - This creates better FD_LOOP compliance (target ‚Üî known alignment)

  EXAMPLES:
    Course: ita_for_eng (Italian for English speakers)
      - Canonical: "I want to speak Italian with you now"
      - Step 1: English ‚Üí Italian (optimized): "Voglio parlare italiano con te adesso"
      - Step 2: Italian ‚Üí English: Use canonical (since canonical IS English)

    Course: ita_for_fra (Italian for French speakers)
      - Canonical: "I want to speak Italian with you now"
      - Step 1: English ‚Üí Italian (optimized): "Voglio parlare italiano con te adesso"
      - Step 2: Italian ‚Üí French: "Je veux parler italien avec toi maintenant"
      - Note: French matches Italian structure, NOT English canonical

  WHY THIS WORKS:
    - Target is pedagogically optimized (6 heuristics applied)
    - Known translation mirrors target structure (easier LEGO mapping)
    - FD_LOOP more reliable (target ‚Üî known designed to align)
    - Works for ANY language pair combination

PROMPT: |
# Phase 1: Pedagogical Translation

TEST UPDATE - This is a test of the live prompt editing system.

All previous content maintained...

  # Phase 1: Pedagogical Translation

  ## Task
  Apply 6 pedagogical heuristics to translate all 668 canonical seed pairs into optimized learning material.

  ## Input
  - Canonical seeds: vfs/seeds/canonical_seeds.json
  - Phase 0 intelligence: vfs/phase_outputs/phase_0_intelligence.json

  ## The 6 Pedagogical Heuristics
  1. **Naturalness**: Target language should sound native, not transliterated
  2. **Frequency**: Prefer high-frequency vocabulary and common structures
  3. **Clarity**: Prioritize clear, unambiguous expressions over idiomatic complexity
  4. **Brevity**: Shorter translations preferred when pedagogically equivalent
  5. **Consistency**: Maintain consistent terminology across seeds
  6. **Utility**: Maximize teaching value (versatile phrases, reusable structures)

  ## Your Mission

For each canonical English seed:

1. **STEP 1: Canonical ‚Üí Target (Pedagogical Optimization)**
   - Apply all 6 pedagogical heuristics
   - Generate optimized target language translation
   - Validate: Natural, high-frequency, clear, brief, consistent, useful

2. **STEP 2: Target ‚Üí Known (Back-Translation)**
   - Take the optimized target translation
   - Translate to known language
   - Ensure known translation MATCHES target structure
   - Goal: Known ‚Üî Target alignment for better FD_LOOP

3. **Generate Amino Acid**
   - Deterministic UUID: hash(source + target + metadata)
   - Store as: vfs/amino_acids/translations/{uuid}.json
   - Content: { source, target, seed_id, heuristics_applied, metadata }

IMPORTANT: For courses where known=English (e.g., ita_for_eng):
- Step 1 produces optimized target
- Step 2 can reuse canonical English (it's already the known language)
- But verify the English phrasing aligns with target structure

For courses where known‚â†English (e.g., ita_for_fra):
- Step 1 produces optimized Italian
- Step 2 MUST translate Italian ‚Üí French (NOT English ‚Üí French)
- This ensures French mirrors Italian structure

  ## Critical Rules
  - Translations are NOT literal - they are pedagogically optimized
  - Each translation is an immutable amino acid component
  - UUIDs are content-based (deterministic)
  - Preserve seed_id for provenance tracking

  ## Example Translation
  Seed S42: "I would like to go"
  Literal: "Hoffwn i fynd"
  Pedagogical: "Dw i eisiau mynd" (more natural, higher frequency, clearer for learners)

  ## Success Criteria
  ‚úì All 668 seeds translated
  ‚úì All 6 heuristics applied to each
  ‚úì Deterministic UUIDs generated
  ‚úì Amino acids stored in VFS
  ‚úì Provenance preserved (seed_id in each amino acid)

## Phase 2: Corpus Intelligence

NAME: "Corpus Intelligence"
PURPOSE: Map FCFS chronological order and calculate utility scores
INPUT:
  - vfs/amino_acids/translations/*.json
  - vfs/phase_outputs/phase_0_intelligence.json
OUTPUT: vfs/phase_outputs/phase_2_corpus_intelligence.json

FCFS_DEFINITION: First-Can-First-Say
  - Identifies chronological learning order
  - Maps prerequisite dependencies (word A requires word B)
  - Establishes natural learning progression

UTILITY_SCORING:
  FORMULA: Frequency √ó Versatility √ó Simplicity
  FREQUENCY: How often used in corpus
  VERSATILITY: How many contexts it appears in
  SIMPLICITY: How easy to learn/teach
  SCALE: 0-100

PURPOSE_FOR_PHASE_3:
  - FCFS provides chronological baseline for LEGO extraction
  - Utility may override FCFS for high-value teaching opportunities
  - This intelligence drives LEGO decomposition decisions

PROMPT: |
  # Phase 2: Corpus Intelligence

  ## Task
  Analyze translated corpus to determine FCFS (First-Can-First-Say) order and calculate utility scores.

  ## Input
  - Translation amino acids: vfs/amino_acids/translations/*.json
  - Phase 0 intelligence: vfs/phase_outputs/phase_0_intelligence.json

  ## Your Mission
  1. **FCFS Mapping**: Determine chronological teaching order
     - Identify prerequisite knowledge (what must be learned first)
     - Map dependency chains (word A requires word B)
     - Establish natural learning progression

  2. **Utility Scoring**: Calculate pedagogical value
     - Formula: Frequency √ó Versatility √ó Simplicity
     - Frequency: How often used in corpus
     - Versatility: How many contexts it appears in
     - Simplicity: How easy to learn/teach

  3. **Generate Intelligence Report**:
     - FCFS rankings for all translations
     - Utility scores (0-100 scale)
     - Dependency maps
     - Teaching sequence recommendations

  ## Output Format
  vfs/phase_outputs/phase_2_corpus_intelligence.json

  {
    "fcfs_order": [ ... ],
    "utility_scores": { translation_uuid: score, ... },
    "dependencies": { ... },
    "recommendations": { ... }
  }

  ## Critical Notes
  - FCFS = "natural" chronological sequence
  - Utility may override FCFS for high-value opportunities
  - This data drives Phase 3 LEGO extraction algorithm

  ## Success Criteria
  ‚úì FCFS order complete
  ‚úì Utility scores calculated for all translations
  ‚úì Dependency maps generated
  ‚úì Ready for Phase 3 consumption

## Phase 3: LEGO Decomposition

NAME: "LEGO Extraction"
PURPOSE: Extract optimal teaching phrases while enforcing FD_LOOP and FCFS rules
INPUT:
  - vfs/amino_acids/translations/*.json
  - vfs/phase_outputs/phase_2_corpus_intelligence.json
OUTPUT: vfs/amino_acids/legos/{uuid}.json

BATCH_PROCESSING:
  BATCH_SIZE: 20 seeds (complex work requires smaller batches)
  BATCHES: 34 total (668 √∑ 20 = 33.4, rounded up to 34)

CRITICAL_INTELLIGENCE:

### FD_LOOP TEST (MANDATORY FOR EVERY CHUNK)
DEFINITION: Forward-Deterministic Loop Test
RULE: Target ‚Üí Known ‚Üí Target MUST BE IDENTICAL
EXAMPLES:
  ‚úÖ "importante" ‚Üí "important" ‚Üí "importante" (IDENTICAL - PASS)
  ‚ùå "bien" ‚Üí "good" ‚Üí "bueno" (DIFFERENT - FAIL)

PURPOSE: Ensures every LEGO chunk can be reliably translated back and forth
WHY_CRITICAL: Prevents ambiguous mappings that confuse learners

### FCFS RULE (First Come, First Served)
DEFINITION: Corpus frequency determines semantic territory claiming
PROCESS:
  1. Count frequency of each mapping in corpus
  2. Most frequent CLAIMS the simple mapping (if grammatically valid)
  3. Less frequent must ADD context to differentiate
  4. If corpus edit needed to maintain FD, NOTE it for SEED_PAIR revision

ARTISTIC_CHOICE (flexible mapping):
  - "quiero" appears 15x as "I want" ‚Üí CLAIMS "I want"
  - "deseo" appears 2x ‚Üí must use "I desire" or "I really want"
  - Once claimed, "I want" ALWAYS ‚Üí "quiero" in this course

GRAMMATICAL_CONSTRAINT (NO flexibility):
  - "estoy" CANNOT claim generic "I am" - MUST include temporal aspect
    ‚úÖ "estoy aprendiendo" ‚Üí "I'm learning" (temporary state)
    ‚ùå "estoy" ‚Üí "I am" (loses critical grammar distinction)
  - "soy" CANNOT claim generic "I am" - MUST include permanent aspect
    ‚úÖ "soy de Inglaterra" ‚Üí "I'm from England" (permanent origin)
    ‚ùå "soy" ‚Üí "I am" (loses critical grammar distinction)

### AUTOMATIC REJECTION LIST
FUNCTION_WORDS (ALWAYS FAIL FD):
  - Articles: el/la/los/las, un/una (gender ambiguous)
  - Pronouns: le/lo/la (multiple meanings)
  - Prepositions: en (in/on/at), de (of/from/about), por/para
  - "que" (that/what/which) - context dependent

MULTI_MEANING_WITHOUT_CONSTRAINTS:
  - "bien" ‚Üí well/good/fine (use FCFS to claim primary meaning)
  - "muy" ‚Üí very/really (use FCFS for intensity)

### DUAL-PASS METHODOLOGY

PASS 1: Forward Analysis (Target ‚Üí Known)
  1. Start with first word of target sentence
  2. Test for FD compliance using FD_LOOP
  3. If fails, expand to include next word
  4. Continue until FD passes or sentence complete
  5. Move to next unmapped word

PASS 2: Reverse Validation (Known ‚Üí Target)
  1. Take each known chunk
  2. Verify it maps back to EXACT target chunk
  3. If different ‚Üí REJECT and re-decompose

PASS 3: Corpus-Wide Validation
  For EVERY chunk, search ALL other SEED_PAIRS in batch:
  - Find every occurrence of this chunk
  - Count frequency of each mapping
  - Apply FCFS: most frequent claims simple mapping
  - Less frequent must differentiate with context
  - If conflicts cannot be resolved ‚Üí FLAG for SEED_PAIR revision

PASS 4: SEED_PAIR Revision Notes
  If decomposition reveals FD conflicts:
  - Note which SEED_PAIRS need editing
  - Suggest specific changes to maintain FD
  - Example: "I want coffee" might need ‚Üí "I'd like coffee" if "quiero" is claimed

### LEGO TYPES

BASE_LEGO:
  DEFINITION: Fundamental FD unit that cannot be broken down further
  CHARACTERISTICS:
    - Single, atomic unit
    - FD (passes target ‚Üí known ‚Üí target)
    - Not composed of other LEGOs
  EXAMPLES:
    - "Voglio" = "I want"
    - "voy" = "I'm going"
    - "algo" = "something"

COMPOSITE_LEGO:
  DEFINITION: FD unit comprising BASE LEGOs + non-LEGO glue words
  CHARACTERISTICS:
    - Itself is FD as a complete unit
    - Contains at least ONE BASE LEGO + glue words
    - BASE LEGOs within DO NOT TILE (don't concatenate cleanly)
    - Glue words are NOT LEGOs themselves
  EXAMPLES:
    - "voy a decir" = "I'm going to say" (glue: "a")
    - "sto per esercitarmi" = "I'm going to practice" (glue: "per")
  WHEN_TO_CREATE:
    - BASE LEGOs don't TILE if concatenated directly
    - Glue words (prepositions, particles) required between
    - Unit is more useful taught as one piece

FEEDERS:
  DEFINITION: BASE LEGOs that feed into a COMPOSITE LEGO
  CHARACTERISTICS:
    - They are BASE LEGOs themselves (FD, atomic, standalone)
    - Have dual existence:
      1. As independent BASE LEGOs (own baskets, used in phrases)
      2. As components within COMPOSITE LEGO
    - Stored with F## suffix (not L##) when part of COMPOSITE
    - NOT subordinate to COMPOSITE - full LEGOs used in multiple contexts
  EXAMPLE:
    - COMPOSITE: "voy a decir" (S0005L02)
    - FEEDER 1: "voy" (S0005F01) ‚Üê Also exists as BASE LEGO elsewhere
    - FEEDER 2: "decir" (S0005F02) ‚Üê Also exists as BASE LEGO elsewhere
    - Glue: "a" (NOT a LEGO, NOT a FEEDER)

### TILING CONCEPT

DEFINITION: LEGOs that concatenate cleanly without glue words

TILES (Concatenate directly):
  - No additional words needed between LEGOs
  - Direct concatenation reconstructs sentence
  - Keep as separate BASE LEGOs
  EXAMPLE: "Voglio parlare" = "Voglio" + "parlare" ‚úÖ TILES

DOES_NOT_TILE (Needs glue):
  - Additional words required between LEGOs
  - Cannot concatenate directly
  - Create COMPOSITE LEGO
  EXAMPLE: "voy a decir" ‚â† "voy" + "decir" ‚ùå DOESN'T TILE (needs "a")

DECISION_RULE:
  IF (BASE LEGOs TILE):
    ‚Üí Keep as separate BASE LEGOs
  ELSE IF (BASE LEGOs DON'T TILE):
    ‚Üí Create COMPOSITE LEGO with FEEDERs

### COMPONENTIZATION (Pedagogical Explanation)

PURPOSE: Help learners understand how multi-word LEGOs break down

TWO TYPES:

1. For BASE LEGOs that TILE:
   - LEGOs remain separate in structure
   - But add explanation for learner clarity
   - Example: "parlare italiano" stays as two LEGOs (parlare + italiano)
   - Add: "parler italien = parlare italiano, o√π parlare = parler et italiano = italien"

2. For COMPOSITE LEGOs:
   - LEGO is structurally one unit (doesn't tile)
   - Show FEEDERs to help learner understand components
   - Example: "voy a decir" is ONE COMPOSITE LEGO
   - FEEDERs: voy (F01), decir (F02)
   - Explanation: "voy a decir = I'm going to say, where voy = I'm going, a = [particle], decir = to say"

RULE: Add componentization when BOTH target AND known are multi-word

FORMAT: Simple word mappings in KNOWN language
  "[known LEGO] = [target LEGO], where [target1] = [known1] and [target2] = [known2]"

CRITICAL: Write ALL componentization in KNOWN language, NOT English!
  - French speakers: Use "o√π" (not "where"), "et" (not "and")
  - Spanish speakers: Use "donde" (not "where"), "y" (not "and")

### IRON RULE
ABSOLUTE_CONSTRAINT: No LEGO begins or ends with a preposition

IMPORTANT CLARIFICATION:
  - The infinitive marker "to" (as in "to speak") is NOT a preposition
  - It is a grammatical marker that forms part of the infinitive verb
  - Full infinitives like "to speak", "to learn" are ALLOWED and FD-compliant
  - Bare infinitives are NOT FD (conflict with commands and conjugations)

EXAMPLES OF VIOLATIONS:
  ‚úó "to the" (preposition "to" for direction)
  ‚úó "with me" (preposition "with")
  ‚úó "in" (standalone preposition)
  ‚úó "con" (standalone preposition)
  ‚úó "da" (standalone preposition)

EXAMPLES OF ALLOWED:
  ‚úÖ "to speak" (infinitive marker + verb)
  ‚úÖ "to learn" (infinitive marker + verb)
  ‚úÖ "parlare" (infinitive without marker)

NON_NEGOTIABLE: No standalone prepositions or prepositional phrase boundaries

### UID FORMAT
MANDATORY_STRUCTURE:
  LEGOs: S{seed_id}L{position}
  FEEDERs: S{seed_id}F{position}

EXAMPLES:
  - Seed S0001 ‚Üí LEGOs: S0001L01, S0001L02, S0001L03
  - Seed S0001 ‚Üí FEEDERs: S0001F01, S0001F02

NEVER_USE:
  ‚ùå L0001 (missing parent seed ID)
  ‚ùå F0001 (missing parent seed ID)

### CONCRETE EXAMPLE

INPUT (from Phase 1):
{
  "seed_id": "S0001",
  "target": "Voglio parlare italiano con te adesso.",
  "known": "Je veux parler italien avec toi maintenant."
}

OUTPUT (Phase 3 decomposition):
{
  "seed_id": "S0001",
  "original_target": "Voglio parlare italiano con te adesso.",
  "original_known": "Je veux parler italien avec toi maintenant.",
  "lego_pairs": [
    {
      "lego_id": "S0001L01",
      "target_chunk": "Voglio",
      "known_chunk": "Je veux",
      "fd_validated": true
    },
    {
      "lego_id": "S0001L02",
      "target_chunk": "parlare italiano",
      "known_chunk": "parler italien",
      "fd_validated": true
    },
    {
      "lego_id": "S0001L03",
      "target_chunk": "con te",
      "known_chunk": "avec toi",
      "fd_validated": true
    },
    {
      "lego_id": "S0001L04",
      "target_chunk": "adesso",
      "known_chunk": "maintenant",
      "fd_validated": true
    }
  ],
  "feeder_pairs": [
    {
      "feeder_id": "S0001F01",
      "target_chunk": "parlare",
      "known_chunk": "parler"
    },
    {
      "feeder_id": "S0001F02",
      "target_chunk": "italiano",
      "known_chunk": "italien"
    }
  ],
  "componentization": [
    {
      "lego_id": "S0001L02",
      "explanation": "parler italien = parlare italiano, o√π parlare = parler et italiano = italien"
    },
    {
      "lego_id": "S0001L03",
      "explanation": "avec toi = con te, o√π con = avec et te = toi"
    }
  ]
}

PROMPT: |
  # Phase 3: LEGO Decomposition

  Hi! I need help with Phase 3 of my language course project - LEGO decomposition.

  Working with ${targetLang} for ${knownLang} speakers.

  ## CORE PRINCIPLE
  Break each SEED_PAIR into LEGO chunks that:
  1. When placed side-by-side, EXACTLY reconstruct the original sentence
  2. Each LEGO passes the FD_LOOP test independently
  3. Are reusable across multiple sentences

  ## LEGO TYPES & ARCHITECTURE

  ### BASE LEGO (Simple/Atomic)
  - Fundamental FD unit
  - Cannot be broken down further
  - Examples: "Voglio", "parlare", "voy", "decir"

  ### COMPOSITE LEGO (Contains BASE + Glue)
  - FD unit with BASE LEGOs + non-LEGO glue words
  - BASE LEGOs DON'T TILE (can't concatenate directly)
  - Examples:
    - "voy a decir" (voy + a + decir) - "a" is glue
    - "sto per esercitarmi" (sto + per + esercitarmi) - "per" is glue

  ### FEEDERS
  - BASE LEGOs within a COMPOSITE
  - Stored separately with F## suffix
  - Help learners understand COMPOSITE structure

  ### TILING TEST
  **Question**: Can you concatenate these LEGOs directly?

  IF YES (TILES):
  ‚Üí Keep as separate BASE LEGOs
  Example: "Voglio" + "parlare" = "Voglio parlare" ‚úÖ

  IF NO (DOESN'T TILE):
  ‚Üí Create COMPOSITE LEGO + FEEDERs
  Example: "voy" + "decir" ‚â† "voy decir" ‚ùå (need "a")
  ‚Üí COMPOSITE: "voy a decir"
  ‚Üí FEEDERs: "voy" (F01), "decir" (F02)

  ## YOUR EXTRACTION PROCESS

  For each seed:

  1. Break into potential chunks
  2. Validate each chunk is FD
  3. Check if chunks contain multiple BASE LEGOs
  4. Apply TILING TEST:
     - TILES? ‚Üí Separate BASE LEGOs
     - DOESN'T TILE? ‚Üí COMPOSITE LEGO + FEEDERs
  5. Add componentization explanation (pedagogical)

  ## MANDATORY UID FORMAT
  For seed S0001:
  - LEGOs: S0001L01, S0001L02, S0001L03
  - FEEDERs: S0001F01, S0001F02 (sub-components of multi-word LEGOs)
  NEVER use L0001 or F0001 (missing parent seed ID)

  ## üîç FD_LOOP TEST (MANDATORY FOR EVERY CHUNK)
  Target ‚Üí Known ‚Üí Target = MUST BE IDENTICAL
  ‚úÖ "importante" ‚Üí "important" ‚Üí "importante" (IDENTICAL)
  ‚ùå "bien" ‚Üí "good" ‚Üí "bueno" (DIFFERENT = FAIL)

  ## üéØ FCFS RULE (First Come, First Served)
  When multiple valid mappings exist, use corpus frequency to CLAIM semantic territory:

  ### ARTISTIC CHOICE (flexible mapping allowed):
  - "quiero" appears 15x as "I want" in corpus ‚Üí CLAIM as "I want"
  - "deseo" appears 2x ‚Üí must use MORE SPECIFIC: "I desire" or "I really want"
  - Once claimed, "I want" ALWAYS ‚Üí "quiero" in this course

  ### GRAMMATICAL CONSTRAINT (NO flexibility):
  - "estoy" CANNOT claim generic "I am" - MUST include temporal aspect
    ‚úÖ "estoy aprendiendo" ‚Üí "I'm learning" (temporary state)
    ‚úÖ "estoy feliz" ‚Üí "I'm happy (right now)"
    ‚ùå "estoy" ‚Üí "I am" (loses critical grammar distinction)

  - "soy" CANNOT claim generic "I am" - MUST include permanent aspect
    ‚úÖ "soy de Inglaterra" ‚Üí "I'm from England" (permanent origin)
    ‚úÖ "soy profesor" ‚Üí "I'm a teacher" (identity/profession)
    ‚ùå "soy" ‚Üí "I am" (loses critical grammar distinction)

  ### FCFS PROCESS:
  1. Count frequency of each mapping in corpus
  2. Most frequent CLAIMS the simple mapping (if grammatically valid)
  3. Less frequent must ADD context to differentiate
  4. If corpus edit needed to maintain FD, NOTE it for SEED_PAIR revision

  ## üö´ AUTOMATIC REJECTION LIST
  **Function Words (ALWAYS FAIL FD):**
  - Articles: el/la/los/las, un/una (gender ambiguous)
  - Pronouns: le/lo/la (multiple meanings)
  - Prepositions: en (in/on/at), de (of/from/about), por/para
  - "que" (that/what/which) - context dependent

  **Multi-meaning words WITHOUT grammar constraints:**
  - "bien" ‚Üí well/good/fine (use FCFS to claim primary meaning)
  - "muy" ‚Üí very/really (use FCFS for intensity)

  ## ‚úÖ DUAL-PASS METHODOLOGY

  ### PASS 1: Forward Analysis (${targetLang} ‚Üí ${knownLang})
  1. Start with first word of ${targetLang} sentence
  2. Test for FD compliance using FD_LOOP
  3. If fails, expand to include next word
  4. Continue until FD passes or sentence complete
  5. Move to next unmapped word

  ### PASS 2: Reverse Validation (${knownLang} ‚Üí ${targetLang})
  1. Take each ${knownLang} chunk
  2. Verify it maps back to EXACT ${targetLang} chunk
  3. If different ‚Üí REJECT and re-decompose

  ### PASS 3: Corpus-Wide Validation
  For EVERY chunk, search ALL other SEED_PAIRS in batch:
  - Find every occurrence of this chunk
  - Count frequency of each mapping
  - Apply FCFS: most frequent claims simple mapping
  - Less frequent must differentiate with context
  - If conflicts cannot be resolved ‚Üí FLAG for SEED_PAIR revision

  ### PASS 4: SEED_PAIR Revision Notes
  If decomposition reveals FD conflicts:
  - Note which SEED_PAIRS need editing
  - Suggest specific changes to maintain FD
  - Example: "I want coffee" might need ‚Üí "I'd like coffee" if "quiero" is claimed

  ## üìù COMPONENTIZATION REQUIREMENT (BOTH languages must be multi-word!)
  COMPONENTIZATION is ONLY needed when BOTH target AND known are multi-word:
  - ‚úÖ REQUIRED: "parlare italiano" ‚Üî "parler italien" (BOTH are 2 words)
  - ‚úÖ REQUIRED: "para su hermana" ‚Üî "for his sister" (BOTH are 3 words)
  - ‚ùå NOT NEEDED: "construir" ‚Üî "build" (both single words)
  - ‚ùå NOT NEEDED: "una nueva vida" ‚Üî "a new life" (even though multi-word, simple 1:1 mapping)

  FORMAT: Simple word mappings ONLY (no grammar explanations):
  "[known LEGO] = [target LEGO], where [target1] = [known1] and [target2] = [known2]"

  ‚ö†Ô∏è CRITICAL: Write ALL componentization in ${knownLang}, NOT English!
  - French speakers: Use French words like "o√π" (not "where"), "et" (not "and")
  - Spanish speakers: Use Spanish words like "donde" (not "where"), "y" (not "and")
  - Chinese speakers: Use Chinese: "ÂÖ∂‰∏≠" (not "where"), "Âíå" (not "and")

  Example for ${knownLang} speakers:
  French: "parler italien = parlare italiano, o√π parlare = parler et italiano = italien"
  Spanish: "hablar italiano = parlare italiano, donde parlare = hablar y italiano = italiano"
  NOT: "parler italien = parlare italiano, where parlare = parler and italiano = italien" ‚ùå

  ## THE IRON RULE (ABSOLUTE)
  **No LEGO begins or ends with a preposition.**

  **IMPORTANT CLARIFICATION**:
  - The infinitive marker "to" (as in "to speak") is NOT a preposition
  - It is a grammatical marker that forms part of the infinitive verb
  - Full infinitives like "to speak", "to learn" are ALLOWED and FD-compliant
  - Bare infinitives are NOT FD (conflict with commands and conjugations)

  **Examples of VIOLATIONS**:
  - ‚úó "to the" (preposition "to" for direction)
  - ‚úó "with me" (preposition "with")
  - ‚úó "in" (standalone preposition)

  **Examples of ALLOWED**:
  - ‚úÖ "to speak" (infinitive marker + verb)
  - ‚úÖ "to learn" (infinitive marker + verb)

  - This is NON-NEGOTIABLE for standalone prepositions

  ## INPUT DATA
  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/

  Read ALL SEED_PAIRS from:
  SEED_PAIRS_COMPLETE.json (contains all 668 seeds)

  The files contain JSON with structure:
  {
    "seed_pairs": [
      {
        "seed_id": "S0001",
        "target": "[sentence in ${targetLang}]",
        "known": "[sentence in ${knownLang}]"
      }
    ]
  }

  ## OUTPUT FILES
  Save to course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/

  1. Process in batches of 20 seeds:
     - LEGO_BREAKDOWNS_BATCH_001.json (seeds 1-20)
     - LEGO_BREAKDOWNS_BATCH_002.json (seeds 21-40)
     - etc.

  2. ALSO create combined file with ALL breakdowns:
     - LEGO_BREAKDOWNS_COMPLETE.json (all seeds combined)

  Create this exact structure for each file:
  {
    "phase": "LEGO_BREAKDOWNS",
    "batch": "001",
    "target_language": "${targetLang}",
    "known_language": "${knownLang}",
    "lego_breakdowns": [
      // For EACH seed_pair in the input file:
      {
        "seed_id": "S0001",
        "canonical_id": "C0001",
        "original_target": "actual ${targetLang} sentence",
        "original_known": "actual ${knownLang} sentence",
        "lego_pairs": [
          // Break into FD-compliant chunks
        ],
        "feeder_pairs": [
          // Sub-components of multi-word LEGOs
        ],
        "componentization": [
          // ONLY when BOTH target AND known are multi-word!
          // Simple mappings format: known = target, where word1 = word1 and word2 = word2
          {
            "lego_id": "S0001L02",
            "explanation": "[known LEGO] = [target LEGO], where [word1] = [word1] and [word2] = [word2]"
          }
          // Skip if either side is single word or if it's a simple 1:1 mapping
        ]
      }
    ]
  }

  ## CRITICAL OUTPUT RULES
  - **SILENT OPERATION** - Work quietly, save to file
  - **NO PRINTING** - Don't display breakdowns
  - **VFS ONLY** - Save to VFS only, no console output

  Start decomposing immediately.

## Phase 3.5: Graph Construction

NAME: "Graph Construction"
PURPOSE: Build directed graph of LEGO adjacency relationships
INPUT:
  - vfs/amino_acids/legos/*.json
  - vfs/amino_acids/translations/*.json (for co-occurrence analysis)
OUTPUT: vfs/phase_outputs/phase_3.5_lego_graph.json

NEW_IN_V7: This phase is NEW in APML v7.0 - introduces graph intelligence

GRAPH_STRUCTURE:
  NODES: All LEGO amino acids
  EDGES: Directed edges LEGO_A ‚Üí LEGO_B (when A precedes B in corpus)
  WEIGHTS: co-occurrence frequency √ó pedagogical value

PURPOSE_FOR_PHASE_5:
  - Graph edges represent legitimate LEGO sequence patterns
  - Phase 5 uses this to ensure pattern coverage in baskets
  - Replaces old DEBUT/ETERNAL pattern logic with measurable diversity

ADJACENCY_DETECTION:
  - Scan translations to find which LEGOs appear adjacent
  - Example: In "Dw i eisiau mynd", LEGOs "Dw i" and "eisiau" are adjacent
  - Direction matters: A‚ÜíB ‚â† B‚ÜíA

VALIDATION:
  - Ensure graph is connected
  - Check for invalid cycles
  - Verify all LEGOs represented

PROMPT: |
  # Phase 3.5: Graph Construction (NEW in v7.0)

  ## Task
  Build directed graph of LEGO adjacency relationships to enable pattern-aware basket construction.

  ## Input
  - LEGO amino acids: vfs/amino_acids/legos/*.json
  - Translation amino acids: vfs/amino_acids/translations/*.json (for co-occurrence analysis)

  ## Your Mission
  1. **Detect Adjacency Patterns**:
     - Scan source translations to find which LEGOs appear adjacent to each other
     - Example: In "Dw i eisiau mynd", LEGOs "Dw i" and "eisiau" are adjacent

  2. **Build Directed Graph**:
     - Nodes: All LEGO amino acids
     - Edges: LEGO_A ‚Üí LEGO_B (A precedes B in corpus)
     - Direction matters (A‚ÜíB ‚â† B‚ÜíA)

  3. **Calculate Edge Weights**:
     - Weight = co-occurrence frequency √ó pedagogical value
     - Higher weight = more important pattern to teach

  4. **Validate Graph**:
     - Ensure graph is connected
     - Check for invalid cycles
     - Verify all LEGOs represented

  5. **Export Graph Structure**:
     - Adjacency list format
     - Include edge weights
     - Store metadata (total nodes, edges, density)

  ## Output Format
  vfs/phase_outputs/phase_3.5_lego_graph.json

  {
    "nodes": [ ... ],
    "edges": [
      { "from": "uuid_A", "to": "uuid_B", "weight": 42 },
      ...
    ],
    "metadata": { ... }
  }

  ## Critical Notes
  - This is NEW in APML v7.0 - graph intelligence!
  - Phase 5 uses this graph for pattern coverage optimization
  - Edges represent legitimate LEGO sequence patterns
  - Replaces old DEBUT/ETERNAL pattern logic

  ## Success Criteria
  ‚úì All LEGO adjacencies mapped
  ‚úì Directed edges created
  ‚úì Edge weights calculated
  ‚úì Graph validated (connected, no invalid cycles)
  ‚úì Ready for Phase 5 consumption

## Phase 4: Deduplication

NAME: "Deduplication"
PURPOSE: Merge duplicate LEGOs while preserving ALL provenance
INPUT: vfs/amino_acids/legos/*.json
OUTPUT: vfs/amino_acids/legos_deduplicated/*.json

WHY_CRITICAL:
  - Many LEGOs appear in multiple seeds
  - Example: "Dw i" might appear from S1L1, S4L2, S12L3
  - Provenance enables edit propagation
  - If seed S12 changes, we know which LEGOs to update

MERGING_PROCESS:
  1. Detect duplicates (identical text content, different UUIDs)
  2. Combine ALL S{seed}L{position} labels
  3. Example: S1L1, S4L2, S12L3 ‚Üí "S1L1, S4L2, S12L3"
  4. Generate new deterministic UUID based on merged provenance
  5. Create deduplicated set (one LEGO per unique text)

IMMUTABILITY_PRESERVED:
  - Keep original LEGOs (immutable)
  - Deduplicated set is NEW amino acids
  - NEVER lose any provenance information

OUTPUT_STRUCTURE:
  uuid: new_deduplicated_uuid
  text: "the LEGO phrase"
  provenance: ["S1L1", "S4L2", "S12L3"]
  source_count: 3
  metadata: { ... }

PROMPT: |
  # Phase 4: Deduplication

  ## Task
  Identify and merge duplicate LEGOs while preserving ALL provenance information.

  ## Input
  - LEGO amino acids: vfs/amino_acids/legos/*.json

  ## Your Mission
  1. **Detect Duplicates**:
     - Find LEGOs with identical text content
     - May have different UUIDs (different provenance)
     - Example: "Dw i" might appear from S1L1, S4L2, S12L3

  2. **Merge Provenance**:
     - Combine all S{seed}L{position} labels
     - Example: Merge S1L1, S4L2, S12L3 ‚Üí "S1L1, S4L2, S12L3"
     - NEVER lose any provenance information

  3. **Recalculate UUID**:
     - Generate new deterministic UUID based on:
       - LEGO text
       - ALL merged provenance labels
       - Metadata

  4. **Create Deduplicated Set**:
     - One LEGO per unique text
     - Complete provenance history preserved
     - Update graph references if needed

  5. **Store Results**:
     - vfs/amino_acids/legos_deduplicated/*.json
     - Keep original LEGOs (immutable)
     - Deduplicated set is NEW amino acids

  ## Why This Matters
  - Many LEGOs appear in multiple seeds
  - Provenance enables edit propagation
  - If seed S12 changes, we know which LEGOs to update
  - Birth-parent history must NEVER be lost

  ## Output Structure
  {
    "uuid": "new_deduplicated_uuid",
    "text": "the LEGO phrase",
    "provenance": ["S1L1", "S4L2", "S12L3"],
    "source_count": 3,
    "metadata": { ... }
  }

  ## Success Criteria
  ‚úì All duplicates identified
  ‚úì Provenance fully merged (no data loss)
  ‚úì New UUIDs generated
  ‚úì Deduplicated set created
  ‚úì Original LEGOs preserved (immutable)

## Phase 5: Basket Generation (Edge-Aware + d-phrases/e-phrases)

NAME: "Basket Generation with Graph Intelligence and Progressive Vocabulary"
PURPOSE: Select pedagogically optimal LEGO groupings, then generate practice phrases
INPUT:
  - vfs/amino_acids/legos_deduplicated/*.json
  - vfs/phase_outputs/phase_3.5_lego_graph.json (for edge coverage)
  - vfs/phase_outputs/phase_2_corpus_intelligence.json (for FCFS ordering)
OUTPUT: phase_outputs/phase_5_baskets.json

BATCH_PROCESSING:
  BATCH_SIZE: 20 LEGOs per batch
  PROCESSING: Forward (LEGO 1 ‚Üí last LEGO, NOT backwards)

TWO_STAGE_PROCESS:
  STAGE 1 - Basket Selection (Graph-Driven):
    - Analyze LEGO adjacency graph from Phase 3.5
    - Select LEGOs to maximize edge coverage (pattern diversity)
    - Follow FCFS chronological progression from Phase 2
    - Ensure smooth difficulty progression
    - Goal: Learners experience maximum pattern variety

  STAGE 2 - Phrase Generation (Vocabulary-Constrained):
    - For each selected LEGO, generate d-phrases and e-phrases
    - Apply progressive vocabulary constraint
    - Each LEGO can ONLY use vocabulary from LEGOs that came before it
    - LEGO #1: NO vocabulary available = empty basket
    - LEGO #2: Can only use LEGO #1 = very limited
    - LEGO #N: Can use LEGOs #1 through #(N-1)
    - This creates natural progression where complexity builds gradually

COMBINING_BOTH_APPROACHES:
  - Edge coverage ensures corpus patterns are reflected
  - Progressive vocabulary ensures pedagogical soundness
  - FCFS ordering maintains chronological appropriateness
  - Result: Optimal learning sequence with rich practice

E_PHRASES (Eternal Practice Phrases):
  - 5 phrases per LEGO
  - Each 7-10 words long
  - Must contain the target LEGO
  - Perfect grammar in BOTH languages
  - Natural, conversational usage
  - Only use vocabulary from previous LEGOs

D_PHRASES (Deconstructed Practice Phrases):
  - Auto-generated from e_phrases using expanding windows
  - 2_lego: 2 phrases with 2 LEGOs each
  - 3_lego: 2 phrases with 3 LEGOs each
  - 4_lego: 2 phrases with 4 LEGOs each
  - 5_lego: 2 phrases with 5 LEGOs each
  - Must be syntactically correct (even as fragments) in BOTH languages

CULMINATING_LEGO_RULE:
  If this is the LAST LEGO in a seed (e.g., S0123L03 is last of S0123):
  - E-phrase #1 MUST be the COMPLETE SEED sentence
  - Use complete seed heavily in d-phrases (3+ times)
  - Gives learner satisfaction of understanding full seed

BASKET_STRUCTURE:
  {
    "S####L##": {
      "target": "target language LEGO",
      "known": "English translation",
      "e_phrases": [
        ["7-10 word phrase with LEGO", "English translation"],
        ... (5 total)
      ],
      "d_phrases": {
        "2_lego": [["phrase", "translation"], ...],
        "3_lego": [["phrase", "translation"], ...],
        "4_lego": [["phrase", "translation"], ...],
        "5_lego": [["phrase", "translation"], ...]
      }
    }
  }

PROMPT: |
  # Phase 5: Basket Generation - Graph Intelligence + Progressive Vocabulary

  ## TWO-STAGE PROCESS

  ### STAGE 1: Basket Selection (Graph-Driven)

  **Goal**: Select LEGO groupings that maximize pattern diversity

  1. **Load Graph Intelligence**:
     - Read: vfs/phase_outputs/phase_3.5_lego_graph.json
     - Adjacency graph showing which LEGOs appear near each other
     - Edge weights indicate co-occurrence frequency

  2. **Load FCFS Ordering**:
     - Read: vfs/phase_outputs/phase_2_corpus_intelligence.json
     - Chronological ordering from corpus frequency analysis
     - Ensures pedagogically sound sequence

  3. **Select LEGOs for Each Basket** (20 LEGOs per basket):
     - Maximize edge coverage (expose diverse patterns)
     - Follow FCFS chronological progression
     - Avoid redundant LEGO sequences across baskets
     - Ensure smooth difficulty progression
     - Balance novelty with reinforcement

  **Output of Stage 1**: Ordered list of LEGOs to process

  ### STAGE 2: Phrase Generation (Vocabulary-Constrained)

  **Goal**: Generate d-phrases and e-phrases for each selected LEGO

  ## CRITICAL PER-LEGO VOCABULARY CONSTRAINTS
  **ABSOLUTE RULE**: Each LEGO has DIFFERENT available vocabulary!
  - LEGO #1: NO VOCABULARY AVAILABLE = NO PHRASES POSSIBLE (empty basket)
  - LEGO #2: Can only use LEGO #1 = VERY LIMITED phrases possible
  - LEGO #3: Can only use LEGOs #1-2 = A FEW phrases possible
  - LEGO #N: Can only use LEGOs #1 through #(N-1)

  ## Input Data
  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/

  Read LEGOs from: vfs/amino_acids/legos_deduplicated/*.json
  Read Graph: vfs/phase_outputs/phase_3.5_lego_graph.json
  Read FCFS: vfs/phase_outputs/phase_2_corpus_intelligence.json

  ## E-PHRASES (5 Eternal Practice Phrases per LEGO)

  ## E-PHRASE CRITICAL REQUIREMENTS (NON-NEGOTIABLE)

  ### Length Requirements (ABSOLUTE)
  - **MINIMUM**: 7 words in target language
  - **IDEAL**: 10 words in target language
  - **MAXIMUM**: 15 words (hard cap)
  - Short e-phrases (< 7 words) are a CRITICAL FAILURE
  - Better to have NO e-phrase than a short/clunky one

  ### Quality Requirements (ABSOLUTE)
  - QUALITY > QUANTITY: Do not force bad phrases to hit a count
  - E-phrases must be NATURAL and conversational in BOTH languages
  - If vocabulary is insufficient for quality 10-word phrase, skip it
  - Aim for 3-5 excellent e-phrases per basket (not forced to 5)

  ### Target Language Grammar (UNFORGIVEABLE ERRORS)
  ‚ö†Ô∏è **POOR SYNTAX IN TARGET LANGUAGE IS UNFORGIVEABLE** ‚ö†Ô∏è

  For Italian specifically:
  - "cercare" + infinitive REQUIRES "di": "cercando di parlare" NOT "cercando parlare"
  - "imparare" + infinitive REQUIRES "a": "imparando a parlare" NOT "imparando parlare"
  - "provare" + infinitive REQUIRES "a": "provando a dire" NOT "provando dire"
  - "continuare" + infinitive REQUIRES "a": "continuando a parlare" NOT "continuando parlare"
  - "finire" + infinitive REQUIRES "di": "finendo di parlare" NOT "finendo parlare"

  **VALIDATE EVERY E-PHRASE**:
  - Is the target language grammar PERFECT?
  - Would a native speaker say this naturally?
  - Are all required prepositions present?

  If you cannot ensure perfect target language grammar, DO NOT include the phrase.

  ---

  Create 5 phrases, each 7-10 words (balanced across 7/8/9/10):
  - **MUST contain the target LEGO**
  - **Perfect grammar** in BOTH languages - validate target AND known language
  - **Natural, conversational** - things people actually say in BOTH languages
  - **Smooth pronunciation** - not clunky or awkward in either language
  - **Variety in position** - LEGO at different positions in phrase
  - **BILINGUAL VALIDATION**: Each phrase must be:
    - Grammatically correct in target language
    - Grammatically correct in known language
    - Semantically meaningful in BOTH languages
    - Natural and idiomatic in BOTH cultures

  ### CRITICAL RULE - CULMINATING LEGOs (ABSOLUTE REQUIREMENT)

  **Definition**: A "culminating LEGO" is the LAST LEGO in a seed's decomposition

  **How to identify**:
  - Check the LEGO's seed_id (e.g., S0005L02)
  - Look up the seed in Phase 3 LEGO breakdown
  - If this is the highest L-number for that seed ‚Üí it's culminating

  **ABSOLUTE RULE**:
  - **E-phrase #1 MUST be the COMPLETE SEED sentence itself**
  - Not a variation, not similar - the EXACT seed sentence
  - This complete seed MUST also appear 3+ times in D-phrases

  **Example**:
  - Seed S0005: "Sto per esercitarmi a parlare"
  - LEGOs: S0005L01 (sto per) + S0005L02 (esercitarmi a parlare)
  - S0005L02 is culminating (last LEGO)
  - Therefore: S0005L02 basket MUST have E-phrase #1 = "Sto per esercitarmi a parlare"

  **Validation**:
  - Before finalizing basket, check if LEGO is culminating
  - If yes, verify E-phrase #1 is complete seed
  - If not, regenerate basket

  ## VOCABULARY SELECTION (Recency Guidelines - for LEGOs 50+)
  **For early LEGOs (1-50):** Use whatever vocabulary is available - there's not enough yet for recency preferences.

  **For later LEGOs (50+):** When building E-phrases, PREFER recent vocabulary:
  - ~50% of vocabulary from recent seeds (N-5 to N-1)
  - ~25% from medium-recent (N-20 to N-1)
  - ~25% from all earlier seeds

  BUT ALWAYS PRIORITIZE natural, useful phrases over strict percentages.

  ## D-PHRASES (Auto-Generated Debuts)

  ### D-PHRASE QUALITY ALLOWANCE

  **Important**: D-phrases CAN be somewhat clunky or fragment-like
  - They are expanding windows from e-phrases (2-lego, 3-lego, 4-lego, 5-lego)
  - Syntactic correctness required, but naturalness is less critical
  - Focus: Help learners build up to full e-phrases gradually

  **Contrast with E-phrases**:
  - E-phrases: MUST be natural, conversational, perfect grammar
  - D-phrases: Can be awkward fragments as long as syntax is correct

  ---

  You will generate D-phrases using expanding window from E-phrases:
  - 2x 2-LEGO phrases
  - 2x 3-LEGO phrases
  - 2x 4-LEGO phrases
  - 2x 5-LEGO phrases
  ALL 5 E-phrases must contribute to D-phrases (variety is key).

  **BILINGUAL SYNTAX RULES FOR D-PHRASES:**
  - D-phrases can be fragments (don't need to be complete sentences)
  - BUT they MUST be syntactically correct as far as they go in BOTH languages
  - Examples:
    - ‚úÖ "quiero hablar" / "I want to speak" (fragment but correct in both)
    - ‚úÖ "espa√±ol contigo" / "Spanish with you" (fragment but correct in both)
    - ‚ùå "quiero de" / "I want of" (syntactically broken in both)
    - ‚ùå "hablar yo" / "speak I" (wrong word order in both)
  - Always validate BOTH the target AND known language versions

  **For CULMINATING LEGOs:** Use the complete seed (E1) in at least:
  - 1x in 2-LEGO phrases
  - 1x in 3-LEGO phrases
  - 1x in 4 or 5-LEGO phrases
  This reinforces the complete seed understanding!

  ## VALIDATION REQUIREMENTS
  1. For EACH LEGO's basket:
     - If NO valid phrases can be made: Output {"e_phrases": [], "d_phrases": {}}
     - If only 1-2 phrases possible: Use what's available, don't force 5 phrases
     - EVERY word MUST come from the available vocabulary list

  2. NEVER use:
     - Words from LEGOs that haven't been learned yet
     - Words not in a LEGO (no "y", "de", "el" unless they're in a LEGO)
     - Made-up words to fill space

  3. Expected pattern for early LEGOs:
     - LEGO #1: NO PHRASES POSSIBLE (empty basket)
     - LEGO #2: Maybe 1 meaningful combination if semantically valid
     - LEGO #3: 1-3 phrases depending on semantic validity
     - Only after ~10-15 LEGOs will you have enough vocabulary for D-phrases
     - Only after ~50-100 LEGOs will you have enough vocabulary for full E-phrase baskets

  4. SEMANTIC VALIDITY RULES:
     - All phrases must be grammatically AND semantically correct in BOTH languages
     - Consider actual language usage and meaning
     - Validate each combination for real-world meaningfulness

  ## Output Format
  Save to: course_folder/phase_outputs/phase_5_baskets.json

  {
    "baskets": {
      "S####L##": {
        "target": "[target lego]",
        "known": "[known translation]",
        "seed_origin": "S####",
        "e_phrases": [
          ["[7-10 word phrase with target LEGO]", "[translation]"],
          ["[7-10 word phrase with target LEGO]", "[translation]"],
          ["[7-10 word phrase with target LEGO]", "[translation]"],
          ["[7-10 word phrase with target LEGO]", "[translation]"],
          ["[7-10 word phrase with target LEGO]", "[translation]"]
        ],
        "d_phrases": {
          "2_lego": [
            ["[2-LEGO phrase]", "[translation]"],
            ["[2-LEGO phrase]", "[translation]"]
          ],
          "3_lego": [
            ["[3-LEGO phrase]", "[translation]"],
            ["[3-LEGO phrase]", "[translation]"]
          ],
          "4_lego": [
            ["[4-LEGO phrase]", "[translation]"],
            ["[4-LEGO phrase]", "[translation]"]
          ],
          "5_lego": [
            ["[5-LEGO phrase]", "[translation]"],
            ["[5-LEGO phrase]", "[translation]"]
          ]
        }
      }
    }
  }

  ## Success Criteria

  **Stage 1 (Selection):**
  ‚úì All LEGOs assigned to baskets
  ‚úì Maximum edge coverage per basket (diverse patterns)
  ‚úì FCFS/chronological ordering maintained
  ‚úì Smooth difficulty progression

  **Stage 2 (Generation):**
  ‚úì Every LEGO has d-phrases and e-phrases (even if empty for early LEGOs)
  ‚úì All vocabulary constraints respected
  ‚úì E-phrases are natural and conversational in BOTH languages
  ‚úì D-phrases are syntactically correct in BOTH languages
  ‚úì Culminating LEGOs include complete seed as E-phrase #1
  ‚úì Progressive difficulty from LEGO #1 to last LEGO

  **Combined Result:**
  ‚úì Corpus patterns reflected through edge coverage
  ‚úì Pedagogical soundness through vocabulary constraints
  ‚úì Optimal learning sequence with rich practice

## Phase 6: Introductions

NAME: "Introductions"
PURPOSE: Generate known-only priming phrases
INPUT:
  - vfs/amino_acids/baskets/*.json
  - vfs/amino_acids/legos_deduplicated/*.json
OUTPUT: vfs/amino_acids/introductions/{uuid}.json

ABSOLUTE_RULE: Zero unknown elements allowed in introductions

KNOWN_ONLY_PRINCIPLE:
  - For each basket, identify ALL LEGOs from PREVIOUS baskets
  - These form the "known set"
  - Introduction phrases use ONLY known LEGOs
  - NO new vocabulary or structures
  - Goal: Activate prior knowledge, build confidence

WHY_CRITICAL:
  - Reduces cognitive load before new learning
  - Builds learner confidence (100% comprehension)
  - Primes brain for new content
  - Creates smooth entry point to each basket

VALIDATION:
  - Double-check: NO new LEGOs in introductions
  - Every word/phrase must be from known set
  - Absolute rule - no exceptions

INTRODUCTION_STRUCTURE:
  uuid: deterministic based on content + basket reference
  basket_uuid: which basket this introduction precedes
  phrases: ["phrase1", "phrase2", ...] (using only known LEGOs)
  known_legos_used: ["uuid1", "uuid2", ...] (which known LEGOs were used)
  validation:
    all_known: true
    unknown_count: 0 (MUST be zero)

PROMPT: |
  # Phase 6: Introductions

  ## Task
  Generate known-only introduction phrases for each basket to prime learners with zero unknowns.

  ## Input
  - Basket amino acids: vfs/amino_acids/baskets/*.json
  - Deduplicated LEGOs: vfs/amino_acids/legos_deduplicated/*.json

  ## Your Mission
  For each basket:
  1. **Identify Known LEGOs**:
     - Scan ALL previous baskets (baskets 1 to N-1)
     - Compile complete inventory of LEGOs learner has mastered
     - These are the ONLY LEGOs you can use

  2. **Generate Introduction Phrases**:
     - Create warm-up phrases using ONLY known LEGOs
     - ZERO unknown vocabulary or structures
     - Goal: Activate prior knowledge, build confidence
     - Prepare learner for new basket content

  3. **Validate Known-Only Rule**:
     - Double-check: NO new LEGOs in introductions
     - Every word/phrase must be from known set
     - Absolute rule - no exceptions

  4. **Create Introduction Amino Acids**:
     - Deterministic UUID based on content + basket reference
     - Store: vfs/amino_acids/introductions/{uuid}.json

  ## Introduction Amino Acid Structure
  {
    "uuid": "...",
    "basket_uuid": "...",
    "phrases": ["phrase1", "phrase2", ...],
    "known_legos_used": ["uuid1", "uuid2", ...],
    "validation": {
      "all_known": true,
      "unknown_count": 0
    }
  }

  ## Why This Matters
  - Reduces cognitive load before new learning
  - Builds learner confidence (100% comprehension)
  - Primes brain for new content
  - Creates smooth entry point to each basket

  ## CRITICAL RULE
  **ZERO unknown elements allowed in introductions.**
  If you're unsure, DON'T use it.

  ## Success Criteria
  ‚úì Introduction generated for each basket
  ‚úì All LEGOs verified as "known" from previous baskets
  ‚úì Zero unknown elements (validated)
  ‚úì Introduction amino acids stored
  ‚úì Course ready for final compilation

# =============================================================================
# DASHBOARD INTERFACE SPECIFICATIONS
# =============================================================================

## Interface Section 1: Course Generation Pipeline

COMPONENTS:
  - CourseGeneration.vue (main generation interface)
  - ProcessOverview.vue (phase progress visualization)
  - TrainingPhase.vue (phase documentation and prompt display)

CRITICAL_FEATURE: TrainingPhase.vue displays ACTUAL prompts from registry
  - Fetches from: GET /api/registry/phase-prompts/:phase
  - Shows working reality (not generic docs)
  - Editable textarea allows prompt updates
  - Updates POST to: PUT /api/registry/phase-prompts/:phase
  - Creates version history for every change

DATA_FLOW:
  User selects languages + seed count
    ‚Üì
  POST /api/courses/generate
    ‚Üì
  automation_server.cjs creates job
    ‚Üì
  cascadePhases() reads PHASE_PROMPTS from registry
    ‚Üì
  spawnPhaseAgent() via osascript
    ‚Üì
  Claude Code receives actual working prompts
    ‚Üì
  Outputs saved to VFS
    ‚Üì
  Dashboard polls: GET /api/courses/:code/status
    ‚Üì
  Displays results in real-time

## Interface Section 2: Quality Review & Self-Healing

COMPONENTS:
  - QualityDashboard.vue (overview and metrics)
  - SeedQualityReview.vue (individual seed review)
  - PromptEvolutionView.vue (prompt version history)

PURPOSE:
  - Visual review of all phase outputs
  - Flag problematic seeds for regeneration
  - Track prompt evolution over time
  - Self-healing: automatic rerun of failed extractions

## Interface Section 3: Visualization & Editing

COMPONENTS:
  - LegoVisualizer.vue (visual LEGO breakdown display)
  - SeedVisualizer.vue (seed pair visualization)
  - PhraseVisualizer.vue (phrase pattern visualization)
  - CourseEditor.vue (edit translations and LEGOs)

EDIT_WORKFLOW:
  User edits translation in UI
    ‚Üì
  PUT /api/courses/:code/translations/:uuid
    ‚Üì
  Triggers regeneration of affected phases
    ‚Üì
  Phase 3+ re-run with updated translation
    ‚Üì
  Dashboard shows updated results

## Interface Section 4: APML Specification & Docs

COMPONENTS:
  - APMLSpec.vue (displays this specification)
  - Dashboard.vue (main navigation)
  - PROJECT-DASHBOARD.html (auto-generated from APML)

SELF_DOCUMENTATION:
  - This APML file is the single source of truth
  - Dashboard components fetch from this specification
  - Changes to APML regenerate documentation
  - No drift between docs and reality

# =============================================================================
# COMPILATION & DEPLOYMENT
# =============================================================================

## Compilation Process

1. **Parse APML Specification**
   - Read ssi-course-production.apml
   - Extract Variable Registry
   - Extract Phase Prompts
   - Extract Interface Specs

2. **Generate .apml-registry.json**
   - Machine-readable format for runtime access
   - Contains all PHASE_PROMPTS
   - Contains all API endpoints
   - Contains all configuration

3. **Update automation_server.cjs**
   - Replace hardcoded PHASE_PROMPTS with registry import
   - const apmlRegistry = require('./.apml-registry.json');
   - const PHASE_PROMPTS = apmlRegistry.variable_registry.PHASE_PROMPTS;

4. **Update TrainingPhase.vue**
   - Fetch prompts from: GET /api/registry/phase-prompts/:phase
   - Display in editable textarea
   - Enable prompt updates via API

5. **Generate PROJECT-DASHBOARD.html**
   - Auto-generated navigation interface
   - Links to all interface sections
   - Shows current system status

## Deployment

VERCEL_DEPLOYMENT:
  - Dashboard deployed to Vercel (frontend)
  - Includes .apml-registry.json (latest prompts)
  - Includes auto-generated documentation
  - User can access from anywhere

LOCAL_AUTOMATION:
  - automation_server.cjs runs on SSi Mac (port 3456)
  - ngrok tunnel exposes to internet
  - Dashboard connects via tunnel
  - Claude Code executes locally with full intelligence

# =============================================================================
# VERSION HISTORY
# =============================================================================

VERSION: 7.3.0
DATE: 2025-10-13
CHANGES:
  - Added LEGO type definitions (BASE, COMPOSITE, FEEDERS)
  - Added TILING concept with decision tree
  - Clarified COMPONENTIZATION as pedagogical (not structural)
  - Updated Phase 3 prompt with LEGO architecture extraction logic
  - Examples use "voy a decir" pattern
  - Based on LEGO_ARCHITECTURE_CLARIFICATION_BRIEF.md

VERSION: 7.2.0
DATE: 2025-10-13
CHANGES:
  - Clarified Phase 1 two-step translation architecture (canonical‚Üítarget‚Üíknown)
  - Clarified IRON RULE: infinitive "to" is NOT a preposition (explicitly allowed)
  - Updated Phase 5 prompt with CRITICAL e-phrase length requirements (7-10 words)
  - Added UNFORGIVEABLE target language grammar validation
  - Strengthened culminating LEGO rule enforcement
  - Clarified e-phrase quality > quantity (3-5 excellent vs forced 5)
  - Added D-phrase quality allowance explanation
  - Based on 30-seed Italian validation findings (QUALITY_REPORT.md)

VERSION: 7.1.0
DATE: 2025-10-13
CHANGES:
  - Added "Human-AI Collaboration Model" section
  - Documented Claude Code agent's role as thinking partner
  - Defined orchestrator pattern for parallel work execution
  - Explained "The Meta-Game" - self-improving system vision
  - Added session initialization checklist
  - Documented self-upregulating intelligence loop
  - Clarified that dashboard IS the living system (not just UI)

VERSION: 7.0.0
DATE: 2025-10-13
CHANGES:
  - Created complete APML specification
  - Documented all 668 canonical seeds
  - Preserved critical Phase 3 intelligence (250+ lines)
  - Added Phase 3.5 (Graph Construction)
  - Updated all batch calculations
  - Defined Variable Registry as single source of truth
  - Specified dashboard interface components
  - Documented compilation and deployment process

PREVIOUS_VERSION: 6.x (scattered across multiple files)
MIGRATION: v6 ‚Üí v7 consolidated all intelligence into this APML specification

# =============================================================================
# SUCCESS CRITERIA
# =============================================================================

‚úÖ Complete specification preserves all intelligence
‚úÖ No information loss during code refactors
‚úÖ Dashboard shows actual working prompts (not generic docs)
‚úÖ Edit in UI ‚Üí updates source ‚Üí execution and docs stay in sync
‚úÖ Variable Registry eliminates naming inconsistencies
‚úÖ APML standard compliance (PSS, Intent Capture, Variable Registry)
‚úÖ Self-documenting system (specification IS implementation)
‚úÖ Version controlled (Git tracks every change)
‚úÖ Published with dashboard (Vercel has latest)
‚úÖ Claude receives detailed, battle-tested prompts
‚úÖ Generated courses work perfectly in SSi mobile app

# =============================================================================
# END OF SPECIFICATION
# =============================================================================

For implementation: https://apml.dev/toolchain/
For APML standards: /Users/tomcassidy/APML/apml-dev-website/specifications/

This specification is theÊ∞∏‰πÖÁöÑÁúüÁêÜ (permanent truth) of the SSi Course Production System.

