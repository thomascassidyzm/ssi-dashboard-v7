app ssi_course_production:
  title: "SSi Language Course Production System"
  version: "7.6.0"
  apml_version: "1.1.0"
  description: |
    Complete specification for SSi (Say Something In) language course production system.
    This system transforms 668 canonical concepts (expressed in English as a reference language)
    into pedagogically optimized language learning courses through a 7-phase pipeline
    orchestrated by Claude Code agents.

  created: "2024-10-13"
  author: "Tom Cassidy / SSi Team"

  pss_compliance:
    structure_standard: "APML-PSS v1.0.0"
    self_documentation: enabled

  deterministic_compilation:
    target_platform: "Vue3 + Node.js + Claude Code"
    compilation_guarantee: "Specification-driven phase orchestration"

# =============================================================================
# SYSTEM OVERVIEW & INTENT
# =============================================================================

## System Purpose

The SSi Course Production System enables:

1. **Automated Course Generation** - Transform 668 canonical concepts (expressed in English)
   into pedagogically optimized courses for ANY language direction (target + known)

2. **Distributed Collaboration** - Web dashboard accessible from any computer tunnels
   to SSi Mac machine running Claude Code (Sonnet 4.5) for AI-powered generation

3. **Self-Documenting Intelligence** - Dashboard displays the ACTUAL prompts used by
   Claude, making the system fully transparent and editable

4. **Quality Assurance** - Visual review and editing of all phase outputs with
   automatic regeneration of affected downstream phases

5. **Course Delivery** - Final JSON manifest drives SSi mobile app, coordinating
   text display with AWS-hosted audio files

## Critical Success Factors

✅ Dashboard shows working reality (not generic documentation)
✅ Edit intelligence in UI → updates source → execution and docs stay in sync
✅ No intelligence loss during code refactors or UI redesigns
✅ Claude Code agents receive detailed, battle-tested prompts
✅ Generated courses work perfectly in SSi app

## System Architecture

```
User (any computer, any location)
  ↓
Web Dashboard (Vercel-hosted Vue3 app)
  ↓
ngrok Tunnel
  ↓
automation_server.cjs (on SSi Mac, port 3456)
  ↓
osascript (opens Claude Code)
  ↓
Claude Code (Sonnet 4.5) executes phase prompts
  ↓
VFS (Virtual File System) - stores amino acid outputs
  ↓
Dashboard polls for updates, displays results
  ↓
User reviews/edits, triggers regeneration
  ↓
Final JSON manifest → SSi mobile app
```

## Self-Upregulating Intelligence

This system is designed as a **recursive self-improvement loop**:

1. **System executes** using APML prompts
2. **Quality issues detected** (human or automated review)
3. **Prompts improved** (edited in dashboard UI)
4. **APML updates** (git commit, registry recompile)
5. **System learns** (documents what worked)
6. **Next execution better** (improved prompts used)
7. **Cycle continues** (recursive improvement)

**Key Insight**: The dashboard IS the living system - not just a UI, but the published SSoT that contains the process, intelligence, training, and evolution engine.

# =============================================================================
# HUMAN-AI COLLABORATION MODEL
# =============================================================================

## Claude Code Agent Role

When a new Claude Code session begins, the agent must understand its role in this self-improving system.

### Primary Role: Thinking Partner, Not Task Executor

**DO**:
- Read this APML specification FIRST (it's the SSoT)
- Understand the system architecture and current state
- Ask clarifying questions about goals and priorities
- Create briefs for orchestrator agents to execute work in parallel
- Stay available in main conversation thread for discussion
- Provide strategic guidance and pattern recognition
- Help interpret quality reports and suggest improvements

**DO NOT**:
- Execute tasks directly (use orchestrator agents instead)
- Block the main conversation with long-running work
- Make changes without understanding the full context
- Assume previous context (each session is fresh - read APML)

### The Orchestrator Pattern

**When work needs to be done**:
1. Create a brief (markdown file with clear instructions)
2. Launch orchestrator agent via Task tool
3. Orchestrator spawns parallel sub-agents as needed
4. Main Claude stays available for conversation
5. Orchestrator reports back when complete

**Example**:
```
User: "Validate the 30-seed quality"
Claude:
  1. Creates ORCHESTRATOR_BRIEF.md
  2. Launches orchestrator with Task tool
  3. Stays in conversation: "Orchestrator launched, I'm here while it works"
  4. Orchestrator does all the work in parallel
  5. Reports back: "✅ Quality validation complete"
```

### Understanding "The Meta-Game"

This is not just a course production system - it's a **meta-framework for self-improving AI systems**.

**The Vision**:
- Dashboard publishes the SSoT (this APML)
- Everything is human-editable AND recursively upgradable
- Quality feedback → prompt improvements → better output → learning
- System becomes self-aware, self-improving, self-documenting
- Pattern generalizes to other complex AI systems

**30-Seed Test**: First proof that recursive improvement loop works in production.

**If This Works**: Validates the pattern for building AGI-like systems that improve themselves through experience.

### Session Initialization Checklist

When a new Claude Code session starts:

1. ✅ **Read APML** - This file is your bible
2. ✅ **Understand current phase** - What are we validating/building?
3. ✅ **Check orchestrator status** - Any agents already running?
4. ✅ **Ask about priorities** - What's most important right now?
5. ✅ **Create briefs, not tasks** - Set up parallel work streams
6. ✅ **Stay conversational** - Be the thinking partner

### Key Files

**This APML**: `/Users/tomcassidy/SSi/ssi-dashboard-v7-clean/ssi-course-production.apml`
- Single source of truth
- Read this FIRST every session

**Dashboard**: `/Users/tomcassidy/SSi/ssi-dashboard-v7-clean/`
- Vue3 app that publishes this APML
- Shows process, prompts, training, evolution

**Automation Server**: `automation_server.cjs`
- API backend (port 3456)
- Executes phase prompts via osascript
- Manages VFS and quality tracking

**VFS**: `/Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/`
- Where all amino acids live
- Organized by course code

**Test Data**: `ita_for_eng_574seeds/`
- 30-seed proof-of-concept
- Validates APML prompts produce quality

### Communication Style

**Be concise**: User operates in command-line mindset
**Be strategic**: Focus on "what and why", not "how"
**Be parallel**: Set up multiple work streams simultaneously
**Be present**: Don't disappear into tasks - stay conversational
**Be humble**: Ask when uncertain, don't assume

### Remember

You are part of a **self-improving system**. Your role is to help guide its evolution, not to be the system itself. Create briefs, launch orchestrators, stay available, provide insight.

**The system improves itself. You help it learn how.**

# =============================================================================
# VARIABLE REGISTRY (Single Source of Truth)
# =============================================================================

## Domain Concepts (User-Facing)

### SEED_PAIRS
PURPOSE: Pedagogically optimized translations of canonical seeds
DEFINITION: Translation of a canonical seed into BOTH target AND known languages
REFERENCE_FORMAT: S0001 to S0668 (S + 4-digit number)
FILE_FORMAT: Single consolidated JSON file
STRUCTURE:
  {
    "S0001": ["Quiero hablar español contigo ahora.", "I want to speak Spanish with you now."],
    "S0002": ["Estoy tratando de aprender.", "I'm trying to learn."],
    ...
  }
  Format: { "seed_id": [target, known] }
KEY_PROPERTIES:
  - Total: 668 per course
  - Language-direction specific (ita_for_fra has different SEED_PAIRS than ita_for_eng)
  - Must be "lego_complete" - decomposes into LEGO_PAIRS that tile back perfectly
  - Stored as SINGLE FILE (not individual amino acids) for efficiency
PHASE: Phase 1 (Pedagogical Translation)
STORAGE: vfs/courses/{course_code}/translations.json

### LEGO_PAIRS
PURPOSE: Forward-deterministic teaching units extracted from SEED_PAIRS
DEFINITION: A LEGO cannot exist unless it has BOTH target and known languages mapped
REFERENCE_FORMAT: S0041L02 (seed reference + L + position)
NOTE: LEGO_PAIRS are now SUBSUMED by LEGO_BASKETS (see below)
      Each basket contains the LEGO itself plus all practice phrases
      LEGOs no longer stored separately - baskets.json is the single source
KEY_PROPERTIES:
  - Course-specific AND language-direction specific
  - Must pass FD_LOOP test (target → known → target = IDENTICAL)
  - Two types:
    * BASE LEGO: Atomic, cannot be decomposed further
    * COMPOSITE LEGO: Contains BASE LEGOs + glue words, needs componentization
  - Count: ~2000-3000 per course
PHASE: Phase 3 (LEGO Decomposition)
STORAGE: Integrated into baskets.json (Phase 5)

### LEGO_BASKETS
PURPOSE: Complete set of practice phrases associated with ONE LEGO_PAIR
DEFINITION: One basket per LEGO_PAIR (1:1 relationship), INCLUDES the LEGO itself
FILE_FORMAT: Single consolidated JSON file
STRUCTURE:
  {
    "S0001L01": {
      "lego": ["Quiero", "I want"],
      "e": [
        ["Quiero hablar español.", "I want to speak Spanish."],
        ["Quiero practicar contigo.", "I want to practice with you."]
      ],
      "d": {
        "2": [["Quiero hablar", "I want to speak"], ["hablar español", "to speak Spanish"]],
        "3": [["Quiero hablar español", "I want to speak Spanish"], ...],
        "4": [...],
        "5": [...]
      }
    },
    "S0002L04": { ... }
  }
  Format: { "lego_id": { lego: [target, known], e: [[t,k]...], d: {window: [[t,k]...]} } }
KEY_PROPERTIES:
  - LEGO field contains the core teaching unit (target/known pair)
  - E-PHRASES (e): Up to 5 phrases, 7-10 words, perfect target grammar
  - D-PHRASES (d): Organized by window size (2-5 LEGOs), progressive vocabulary only
  - Count: Matches LEGO_PAIRS count (if 2341 LEGO_PAIRS → 2341 LEGO_BASKETS)
  - Stored as SINGLE FILE for efficiency (not individual amino acids)
  - LEGO_ID is used as key (e.g., "S0001L01", "S0002L04")
PHASE: Phase 5 (Basket Generation)
STORAGE: vfs/courses/{course_code}/baskets.json

### LEGO_INTRODUCTIONS
PURPOSE: Intelligence about LEGO type (BASE vs COMPOSITE) and componentization
DEFINITION: Pedagogical explanation of how LEGO breaks down into components
STRUCTURE:
  {
    "lego_pair_id": "S0041L02",
    "type": "BASE" | "COMPOSITE",
    "feeders": [ ... ],  // For COMPOSITE LEGOs
    "componentization": { "explanation": "..." }
  }
KEY_PROPERTIES:
  - Explains BASE vs COMPOSITE distinction
  - For COMPOSITE LEGOs: shows how they break down into FEEDERs
PHASE: Phase 6 (Introductions)
STORAGE: vfs/courses/{course_code}/amino_acids/introductions/

## Technical Architecture (Implementation Details)

### Amino Acids (Storage Layer)
PURPOSE: Immutable components with deterministic UUIDs
DEFINITION: All phase outputs are stored as "amino acids" - discrete, content-addressed components
UUID_GENERATION: hash(content + metadata) - ensures same content always gets same ID
IMMUTABILITY: Edits create NEW amino acids with updated provenance, never modify originals
PROVENANCE: S{seed}L{position} format tracks birth-parent relationships
NOTE: This is an implementation detail - users see SEED_PAIRS, LEGO_PAIRS, LEGO_BASKETS

### VFS (Virtual File System)
PURPOSE: Organized storage for all course generation artifacts
BASE_PATH: /Users/tomcassidy/SSi/ssi-dashboard-v7-clean/vfs/courses/
STRUCTURE: {target_code}_for_{known_code}_{seed_count}seeds/
FILES:
  - translations.json (stores all SEED_PAIRS - single consolidated file)
  - baskets.json (stores all LEGO_BASKETS including LEGOs - single consolidated file)
  - course_metadata.json (course-level metadata)
SUBDIRS:
  - phase_outputs/ (intermediate files like graphs, corpus intelligence)
  - proteins/ (compiled manifests for app consumption)
NOTE: Old amino_acids/ subdirectory structure deprecated in favor of single consolidated files

### Course Codes
FORMAT: "{target_iso}_for_{known_iso}_speakers"
EXAMPLES:
  - fra_for_eng_speakers (French for English speakers)
  - cym_for_eng_speakers (Welsh for English speakers)
  - ita_for_fra_speakers (Italian for French speakers)

## API Endpoints

ENDPOINTS:
  - POST /api/courses/generate
    PURPOSE: Start complete course generation pipeline
    PARAMETERS: { target, known, seeds }
    RETURNS: { courseCode, status }

  - GET /api/courses/:courseCode/status
    PURPOSE: Poll for generation progress
    RETURNS: { phase, progress, status }

  - GET /api/courses/:courseCode
    PURPOSE: Get complete course data
    RETURNS: Course metadata and manifest

  - POST /api/courses/:code/seeds/regenerate
    PURPOSE: Regenerate specific seeds after edits
    PARAMETERS: { seedIds }

  - GET /api/registry/phase-prompts/:phase
    PURPOSE: Fetch actual prompt for phase (from this APML registry)
    RETURNS: { name, prompt, metadata }

  - PUT /api/registry/phase-prompts/:phase
    PURPOSE: Update phase prompt (writes to APML registry)
    PARAMETERS: { prompt, changelog }
    CREATES: New version in prompt history

## Batch Configuration

BATCH_SIZES:
  PHASE_1_TRANSLATION: 100 seeds per batch (easier work, larger batches)
  PHASE_3_LEGO_DECOMPOSITION: 20 seeds per batch (complex work, smaller batches)
  PHASE_5_BASKETS: 20 LEGOs per batch

TOTAL_SEEDS: 668 (canonical SSi corpus)

# =============================================================================
# PHASE SPECIFICATIONS
# =============================================================================

## Phase 1: Pedagogical Translation

NAME: "Pedagogical Translation"
PURPOSE: Apply 6 pedagogical heuristics to create optimal learning translations
INPUT: vfs/seeds/canonical_seeds.json
OUTPUT: vfs/amino_acids/translations/{uuid}.json (668 translation amino acids)

THE_PEDAGOGICAL_HEURISTICS:

CRITICAL: Heuristic priority changes based on seed position (progressive optimization curve)

SEEDS 1-100 (Beginner Phase - Cognate-Heavy + Variation Reduction):
  1. COGNATE PREFERENCE ⭐ - Maximize vocabulary similarity to known language
  2. VARIATION REDUCTION ⭐ - Once you establish a mapping, stick with it
  3. Consistency - Reinforce same patterns and vocabulary repeatedly
  4. Clarity - Prioritize clear, unambiguous expressions
  5. Utility - Maximize teaching value (versatile phrases, reusable structures)
  6. Frequency - De-prioritized (cognates trump frequency for beginners)
  7. Naturalness - De-prioritized (patterns trump naturalness for beginners)
  8. Brevity - Lowest priority

SEEDS 101-300 (Intermediate Phase - Natural Alternatives):
  1. Consistency - Maintain established patterns while introducing alternatives
  2. Frequency - Start preferring high-frequency vocabulary
  3. Naturalness - Increase natural/common expressions
  4. Clarity - Still prioritize clear expressions
  5. Utility - Maximize teaching value
  6. Cognate Preference - Still useful but lower priority
  7. Brevity - Shorter preferred when equivalent

SEEDS 301-668 (Advanced Phase - Idiomatic + Colloquial):
  1. Naturalness - Target should sound fully native
  2. Frequency - Prefer most common expressions
  3. Utility - Maximum versatility and real-world usage
  4. Clarity - Can introduce more nuanced/ambiguous expressions
  5. Consistency - Still important but allows more variation
  6. Brevity - Natural length preferred
  7. Cognate Preference - No longer prioritized

DETAILED HEURISTIC DEFINITIONS:

1. COGNATE PREFERENCE (Seeds 1-100 priority)
   DEFINITION: Prefer vocabulary with similar form/sound to known language

   EXAMPLES:
     Spanish for English:
       ✅ "intentar" (cognate: intend) > "tratar" (not cognate)
       ✅ "practicar" (cognate: practice) > "entrenar" (not cognate)
       ✅ "importante" (cognate: important) > "relevante" (also cognate but less common)
       ✅ "usar" (cognate: use) even better "utilizar" (cognate: utilize)

     French for English:
       ✅ "pratiquer" (cognate: practice) > "s'entraîner" (not cognate)
       ✅ "important" > "significatif"
       ✅ "utiliser" (cognate: utilize) > "employer" (not cognate)
       ✅ "essayer" (cognate: essay/assay) is acceptable

     Italian for English:
       ✅ "importante" > "rilevante"
       ✅ "praticare" > "allenarsi"
       ✅ "usare" even better "utilizzare"

     Mandarin for English:
       (No cognates - use SIMPLEST high-frequency characters instead)
       ✅ 说 (shuō - speak, 1 character) > 讲话 (jiǎnghuà - speak, 2 characters)
       ✅ 学 (xué - learn, 1 character) > 学习 (xuéxí - study, 2 characters)

   TRADE-OFF: Accept slightly less common word if cognate
   BENEFIT: Reduces cognitive load, increases confidence, faster to conversation
   APPLIES: Primarily seeds 1-100, gradually de-prioritize after

2. VARIATION REDUCTION (Seeds 1-100 priority)
   DEFINITION: Once you establish a mapping, stick with it - vocabulary claiming

   RULE: "First Word Wins" for early seeds
     - First seed that needs "to try" → pick ONE verb (e.g., "intentar")
     - ALL subsequent "to try" contexts → use SAME verb
     - Do NOT introduce synonyms until seeds 100+
     - Create internal vocabulary registry to track claims

   EXAMPLES:
     ❌ BAD (introduces confusion):
       S0002: "tratando" = trying
       S0007: "intentar" = to try
       S0008: "tratar" = to try
       S0015: "probar" = to try
       (Learner confused: which one should I use??)

     ✅ GOOD (builds confidence):
       S0002: "intentando" = trying
       S0007: "intentar" = to try
       S0008: "intentar" = to try
       S0015: "intentar" = to try
       (Learner confident: "intentar" is THE word for "try"!)

   VOCABULARY REGISTRY (maintain during generation):
     - "to try" → CLAIMED by "intentar" (S0002)
     - "to speak" → CLAIMED by "hablar" (S0001)
     - "to want" → CLAIMED by "querer" (S0001)
     - "to learn" → CLAIMED by "aprender" (S0002)

   EXCEPTION: Only introduce variation when GRAMMATICALLY NECESSARY
     (e.g., Spanish "ser" vs "estar" - different grammar, must introduce both)
     (e.g., French "savoir" vs "connaître" - different contexts, must introduce both)

   LATER INTRODUCTION (Seeds 100-300):
     "You know 'intentar' = to try. You can also say 'tratar de' (more common in some regions) or 'probar' (to try/test)."

   APPLIES: Strictly seeds 1-100, gradually relax after

3. Naturalness - Target language should sound native, not transliterated
4. Frequency - Prefer high-frequency vocabulary and common structures
5. Clarity - Prioritize clear, unambiguous expressions over idiomatic complexity
6. Brevity - Shorter translations preferred when pedagogically equivalent
7. Consistency - Maintain consistent terminology across seeds
8. Utility - Maximize teaching value (versatile phrases, reusable structures)

BATCH_PROCESSING:
  BATCH_SIZE: 100 seeds
  BATCHES: 7 total (668 ÷ 100 = 6.68, rounded up to 7)
  NAMING: phase1_batch_001.json, phase1_batch_002.json, etc.

AMINO_ACID_STRUCTURE:
  uuid: hash(source + target + metadata)
  source: original English seed
  target: pedagogically optimized translation
  seed_id: provenance tracking (S0001, S0002, etc.)
  heuristics_applied: array of which heuristics influenced this translation
  metadata: language codes, batch info, timestamp

CRITICAL_RULES:
  - Translations are NOT literal - they are pedagogically optimized
  - Each translation is an immutable amino acid component
  - UUIDs are deterministic (content-based)
  - Preserve seed_id for provenance tracking

TRANSLATION_ARCHITECTURE:
  Phase 1 uses a TWO-STEP translation process to ensure optimal FD_LOOP compliance:

  STEP 1 - Canonical → Target (Pedagogical Optimization):
    - Start with canonical concept (expressed in English as reference)
    - Apply all 6 pedagogical heuristics
    - Generate pedagogically optimized target language translation
    - This becomes the "source of truth"
    - NOTE: If target language IS English, optimize the canonical expression

  STEP 2 - Target → Known (Back-Translation):
    - Take the optimized target translation from Step 1
    - Translate it into the known language
    - Ensure known translation MATCHES target's structure
    - This creates better FD_LOOP compliance (target ↔ known alignment)

  EXAMPLES:
    Course: ita_for_eng (Italian for English speakers)
      - Canonical: "I want to speak Italian with you now" (reference language)
      - Step 1: Canonical → Italian (optimized): "Voglio parlare italiano con te adesso"
      - Step 2: Italian → English: Use canonical expression (since known language IS English)

    Course: ita_for_fra (Italian for French speakers)
      - Canonical: "I want to speak Italian with you now" (reference language)
      - Step 1: Canonical → Italian (optimized): "Voglio parlare italiano con te adesso"
      - Step 2: Italian → French: "Je veux parler italien avec toi maintenant"
      - Note: French matches Italian structure, NOT the canonical English expression

  WHY THIS WORKS:
    - Target is pedagogically optimized (6 heuristics applied)
    - Known translation mirrors target structure (easier LEGO mapping)
    - FD_LOOP more reliable (target ↔ known designed to align)
    - Works for ANY language pair combination

PROMPT: |
# Phase 1: Pedagogical Translation

TEST UPDATE - This is a test of the live prompt editing system.

All previous content maintained...

  # Phase 1: Pedagogical Translation

  ## Task
  Apply 6 pedagogical heuristics to translate all 668 canonical concepts into BOTH target
  and known languages, creating optimized learning material.

  ## Input
  - Canonical seeds: vfs/seeds/canonical_seeds.json (668 concepts expressed in English)
  - Target language code (e.g., "ita" for Italian)
  - Known language code (e.g., "fra" for French)

  ## Critical Understanding

  Canonical seeds are **NOT English content** - they are language-agnostic concepts that
  happen to be expressed in English as a reference. You will translate each concept into:
  1. TARGET language (the language being learned) - pedagogically optimized
  2. KNOWN language (the learner's language) - structurally matched to target

  Exception: If target or known IS English, reuse the canonical expression (no translation needed).

  ## The Pedagogical Heuristics (Progressive Optimization Curve)

  **CRITICAL**: Heuristic priority changes based on seed position!

  ### SEEDS 1-100 (Beginner Phase - You are translating these!)
  **Priority order for first 100 seeds:**

  1. **COGNATE PREFERENCE** ⭐ - Maximize vocabulary similarity to known language
     - Spanish: "intentar" (cognate) > "tratar" (not cognate)
     - French: "pratiquer" (cognate) > "s'entraîner" (not cognate)
     - Accept slightly less common word if it's a cognate
     - BENEFIT: Reduces cognitive load, learner recognizes words faster

  2. **VARIATION REDUCTION** ⭐ - Once you establish a mapping, stick with it!
     - First seed needs "to try" → Pick ONE verb (e.g., "intentar")
     - ALL subsequent "to try" contexts → Use SAME verb
     - Maintain VOCABULARY REGISTRY as you translate:
       * "to try" → CLAIMED by "intentar" (S0002)
       * "to speak" → CLAIMED by "hablar" (S0001)
       * "to want" → CLAIMED by "querer" (S0001)
     - Do NOT introduce synonyms in seeds 1-100
     - EXCEPTION: Only when grammatically necessary (ser vs estar, savoir vs connaître)

  3. **Consistency** - Reinforce same patterns and vocabulary repeatedly
  4. **Clarity** - Clear, unambiguous expressions
  5. **Utility** - Maximize teaching value
  6. **Frequency** - De-prioritized (cognates trump frequency for beginners)
  7. **Naturalness** - De-prioritized (patterns trump naturalness for beginners)
  8. **Brevity** - Lowest priority

  ### SEEDS 101-300 (Intermediate Phase - Not translating now)
  Start introducing natural alternatives while maintaining established patterns

  ### SEEDS 301-668 (Advanced Phase - Not translating now)
  Full natural/idiomatic expressions, variation encouraged

  ---

  ## Detailed Heuristic Definitions

  ### 1. COGNATE PREFERENCE (Your #1 priority for seeds 1-100)

  **Definition:** Prefer vocabulary with similar form/sound to known language

  **How to identify cognates:**
  - Spanish/French/Italian for English: Look for Latin-derived words
  - Words ending in -tion, -ción, -zione are usually cognates
  - Words with similar roots (practice/practicar, important/importante)

  **Examples by language:**

  **Spanish for English:**
  - ✅ "intentar" (intend) > "tratar" (try)
  - ✅ "practicar" (practice) > "entrenar" (train)
  - ✅ "importante" (important) > "relevante" (relevant)
  - ✅ "usar" (use), even better "utilizar" (utilize)
  - ✅ "continuar" (continue) > "seguir" (continue)
  - ✅ "explicar" (explain) > "aclarar" (clarify)

  **French for English:**
  - ✅ "pratiquer" (practice) > "s'entraîner" (train)
  - ✅ "important" > "significatif"
  - ✅ "utiliser" (utilize) > "employer" (use)
  - ✅ "essayer" (essay/assay) is acceptable
  - ✅ "expliquer" (explain) > "clarifier"
  - ✅ "continuer" (continue) > "poursuivre"

  **Italian for English:**
  - ✅ "importante" > "rilevante"
  - ✅ "praticare" > "allenarsi"
  - ✅ "usare", even better "utilizzare"
  - ✅ "continuare" > "proseguire"
  - ✅ "spiegare" is OK (explain)

  **Mandarin for English:**
  - No cognates available
  - Use SIMPLEST high-frequency characters instead
  - ✅ Single character > two-character compounds when possible
  - ✅ 说 (shuō - speak) > 讲话 (jiǎnghuà - speak)
  - ✅ 学 (xué - learn) > 学习 (xuéxí - study)

  ### 2. VARIATION REDUCTION (Your #2 priority for seeds 1-100)

  **Definition:** Once you establish a mapping, stick with it - "First Word Wins"

  **Process:**
  As you translate seeds 1-100, maintain an internal VOCABULARY REGISTRY:

  ```
  VOCABULARY REGISTRY (build as you translate):
  - "to speak" → "hablar" (claimed in S0001)
  - "to want" → "querer" (claimed in S0001)
  - "to try" → "intentar" (claimed in S0002)
  - "to learn" → "aprender" (claimed in S0002)
  - "to practice" → "practicar" (claimed in S0005)
  - "to remember" → "recordar" (claimed in S0006)
  - "to explain" → "explicar" (claimed in S0008)
  - ... continue building registry
  ```

  **Rules:**
  1. When you encounter a new concept, pick the BEST cognate
  2. Record it in your registry
  3. ALL future occurrences of that concept → use SAME word
  4. Do NOT introduce synonyms, even if "more natural"

  **Example - BAD (current overnight generation):**
  ```
  S0002: "tratando" = trying
  S0007: "intentar" = to try
  S0008: "tratar" = to try
  ```
  ❌ Learner confused: "Which word should I use for 'try'?"

  **Example - GOOD (what you should generate):**
  ```
  S0002: "intentando" = trying (CLAIM: "intentar" for "to try")
  S0007: "intentar" = to try (use claimed word)
  S0008: "intentar" = to try (use claimed word)
  ```
  ✅ Learner confident: "'intentar' is THE word for try!"

  **EXCEPTION - Grammatically Required Variation:**
  Some variation is unavoidable when grammar requires it:
  - Spanish: "ser" vs "estar" (both "to be" but permanent vs temporary)
  - French: "savoir" vs "connaître" (both "to know" but facts vs people)

  In these cases, introduce BOTH but explain the distinction clearly in seed context.

  ### 3-8. Other Heuristics (lower priority for seeds 1-100)

  3. **Consistency** - Maintain consistent terminology across seeds
  4. **Clarity** - Prioritize clear, unambiguous expressions
  5. **Utility** - Maximize teaching value (versatile phrases, reusable structures)
  6. **Frequency** - Prefer high-frequency vocabulary (but AFTER cognates)
  7. **Naturalness** - Target should sound native (but AFTER cognates/consistency)
  8. **Brevity** - Shorter translations preferred when equivalent

  ## Your Mission

For each canonical concept (expressed in English as reference):

1. **STEP 1: Canonical → Target (Pedagogical Optimization)**
   - Apply all 6 pedagogical heuristics
   - Generate optimized target language translation
   - Validate: Natural, high-frequency, clear, brief, consistent, useful

2. **STEP 2: Target → Known (Back-Translation)**
   - Take the optimized target translation
   - Translate to known language
   - Ensure known translation MATCHES target structure
   - Goal: Known ↔ Target alignment for better FD_LOOP

3. **Generate Output**
   - Store ALL translations in single consolidated file
   - Format: { "S0001": [target, known], "S0002": [target, known], ... }
   - File: vfs/courses/{course_code}/translations.json

IMPORTANT: For courses where known=English (e.g., ita_for_eng):
- Step 1 produces optimized target
- Step 2 can reuse canonical English (it's already the known language)
- But verify the English phrasing aligns with target structure

For courses where known≠English (e.g., ita_for_fra):
- Step 1 produces optimized Italian
- Step 2 MUST translate Italian → French (NOT English → French)
- This ensures French mirrors Italian structure

  ## Critical Rules
  - Translations are NOT literal - they are pedagogically optimized
  - Each translation is an immutable amino acid component
  - UUIDs are content-based (deterministic)
  - Preserve seed_id for provenance tracking

  ## Example Translation
  Seed S42: "I would like to go"
  Literal: "Hoffwn i fynd"
  Pedagogical: "Dw i eisiau mynd" (more natural, higher frequency, clearer for learners)

  ## Success Criteria
  ✓ All 668 seeds translated
  ✓ All 6 heuristics applied to each
  ✓ Deterministic UUIDs generated
  ✓ Amino acids stored in VFS
  ✓ Provenance preserved (seed_id in each amino acid)

## Phase 2: Corpus Intelligence

NAME: "Corpus Intelligence"
PURPOSE: Map FCFS chronological order and calculate utility scores
INPUT: vfs/courses/{course_code}/translations.json
OUTPUT: vfs/courses/{course_code}/phase_outputs/phase_2_corpus_intelligence.json

FCFS_DEFINITION: First-Can-First-Say (Semantic Priority)
  - The first word/LEGO to teach a concept CLAIMS that meaning as a BASE LEGO
  - Later words with overlapping meanings must be taught in more specific contexts
  - Example: "estoy" appears first → claims "I am" as BASE
              "soy" appears later → taught as "I am (permanent)" in context like "soy profesor"
  - Establishes which LEGOs get semantic priority in the teaching sequence

UTILITY_SCORING:
  FORMULA: Frequency × Versatility × Simplicity
  FREQUENCY: How often used in corpus
  VERSATILITY: How many contexts it appears in
  SIMPLICITY: How easy to learn/teach
  SCALE: 0-100

PURPOSE_FOR_PHASE_3:
  - FCFS provides chronological baseline for LEGO extraction
  - Utility may override FCFS for high-value teaching opportunities
  - This intelligence drives LEGO decomposition decisions

PROMPT: |
  # Phase 2: Corpus Intelligence

  ## Task
  Analyze translated corpus to determine FCFS (First-Can-First-Say) order and calculate utility scores.

  ## Input
  - Translation amino acids: vfs/amino_acids/translations/*.json

  ## Your Mission
  1. **FCFS Mapping** (First-Can-First-Say - Semantic Priority):
     - Determine which words/LEGOs appear first in the teaching sequence
     - The FIRST word to teach a concept CLAIMS that meaning as a BASE LEGO
     - Later words with overlapping meanings must be taught in more specific contexts
     - Example: If "estoy" = "I am" appears before "soy" = "I am", then:
       * "estoy" claims "I am" as its BASE meaning
       * "soy" must be taught differently (e.g., "soy profesor" = "I am a teacher (permanent)")
     - Map semantic priority: which word gets to "own" each core meaning

  2. **Utility Scoring**: Calculate pedagogical value
     - Formula: Frequency × Versatility × Simplicity
     - Frequency: How often used in corpus
     - Versatility: How many contexts it appears in
     - Simplicity: How easy to learn/teach

  3. **Generate Intelligence Report**:
     - FCFS rankings for all translations
     - Utility scores (0-100 scale)
     - Dependency maps
     - Teaching sequence recommendations

  ## Output Format
  vfs/phase_outputs/phase_2_corpus_intelligence.json

  {
    "fcfs_order": [ ... ],
    "utility_scores": { translation_uuid: score, ... },
    "dependencies": { ... },
    "recommendations": { ... }
  }

  ## Critical Notes
  - FCFS = "natural" chronological sequence
  - Utility may override FCFS for high-value opportunities
  - This data drives Phase 3 LEGO extraction algorithm

  ## Success Criteria
  ✓ FCFS order complete
  ✓ Utility scores calculated for all translations
  ✓ Dependency maps generated
  ✓ Ready for Phase 3 consumption

## Phase 3: LEGO Decomposition

NAME: "LEGO Extraction"
PURPOSE: Extract optimal teaching phrases while enforcing FD_LOOP and FCFS rules
INPUT:
  - vfs/amino_acids/translations/*.json
  - vfs/phase_outputs/phase_2_corpus_intelligence.json
OUTPUT: vfs/amino_acids/legos/{uuid}.json

BATCH_PROCESSING:
  BATCH_SIZE: 20 seeds (complex work requires smaller batches)
  BATCHES: 34 total (668 ÷ 20 = 33.4, rounded up to 34)

CRITICAL_INTELLIGENCE:

### FD_LOOP TEST (MANDATORY FOR EVERY CHUNK)
DEFINITION: Forward-Deterministic Loop Test
RULE: Target → Known → Target MUST BE IDENTICAL
EXAMPLES:
  ✅ "importante" → "important" → "importante" (IDENTICAL - PASS)
  ❌ "bien" → "good" → "bueno" (DIFFERENT - FAIL)

PURPOSE: Ensures every LEGO chunk can be reliably translated back and forth
WHY_CRITICAL: Prevents ambiguous mappings that confuse learners

### FD_LOOP GENDER AND CONTEXT NEUTRALITY

LEGOs must be CONTEXT-INDEPENDENT and GENDER-NEUTRAL to ensure FD compliance.

GENDER-SPECIFIC TRANSLATIONS VIOLATE FD:
  ❌ "Vuole" / "He wants" → FD fails: "He wants" → "Lui vuole" or "Vuole"?
  ❌ "Vuole" / "She wants" → FD fails: "She wants" → "Lei vuole" or "Vuole"?
  ✅ "Vuole" / "Wants" → FD passes: "Wants" → "Vuole" (unambiguous)

POSSESSIVE AMBIGUITY VIOLATES FD:
  ❌ "il suo nome" / "his name" → FD fails: "his" could be "il suo" or "di lui"
  ❌ "il suo nome" / "her name" → FD fails: "her" could be "il suo" or "di lei"
  ✅ "il suo nome" / "their name" → FD passes: "their" → "il suo" (singular they)

CONTEXT-DEPENDENT TRANSLATIONS VIOLATE FD:
  ❌ "que" / "what" (could be "that", "which", "what")
  ❌ "bien" / "good" (could be "well", "good", "fine", "very")
  ✅ Apply FCFS to claim primary meaning with most frequent usage
  ✅ Less frequent must add context: "muy bien" / "very good"

THE CHUNK UP PRINCIPLE (FD Rescue Strategy):
  When a word alone violates FD → Don't just "apply context" → CHUNK UP!

  ALGORITHM:
    1. Test word alone for FD → FAIL?
    2. Add surrounding word (left or right) → Test FD
    3. Still FAIL? Keep expanding
    4. Create COMPOSITE LEGO with full context that PASSES FD
    5. Extract FD components as FEEDERS
    6. Add COMPONENTIZATION explanation

  EXAMPLES:
    ❌ WRONG: "parlare" / "speaking" (context-dependent - vague!)
    ✅ RIGHT: "sta parlando" / "is speaking" (COMPOSITE includes context)
              FEEDERS: "sta" / "is", "parlare" / "to speak"

    ❌ WRONG: "ricordare" / "remember" (could be infinitive or command)
    ✅ RIGHT: "voglio ricordare" / "I want to remember" (COMPOSITE clarifies)
              FEEDERS: "voglio" / "I want", "ricordare" / "to remember"

PRINCIPLE:
  LEGOs are reusable across multiple contexts.
  Gender, number, and semantic ambiguity must be resolved via:
    1. Gender-neutral translations (they/their instead of he/she)
    2. FCFS claiming (most frequent usage claims simple form)
    3. Context addition via CHUNKING UP (create larger COMPOSITE LEGOs)
    4. NEVER leave ambiguity unresolved

### FCFS RULE (First Come, First Served)
DEFINITION: Corpus frequency determines semantic territory claiming

UNIVERSAL PRINCIPLE:
  Most frequent variant CLAIMS simple translation (if grammatically valid)
  Less frequent variants must ADD context to differentiate
  This applies to ANY language pair combination

PROCESS:
  1. Count frequency of each mapping across ALL corpus seeds
  2. Most frequent CLAIMS the simple mapping (if grammatically valid)
  3. Less frequent must ADD context to differentiate
  4. If corpus edit needed to maintain FD, NOTE it for SEED_PAIR revision

ARTISTIC_CHOICE (Flexible mapping allowed):
  When multiple words can express the same meaning, frequency decides.

  Examples across language families:
    - Spanish: "quiero" (15x) claims "I want" → "deseo" (2x) uses "I desire"
    - Italian: "voglio" (15x) claims "I want" → "desidero" (2x) uses "I desire"
    - Welsh: "eisiau" (15x) claims "want" → other forms differentiate with context
    - Mandarin: "想 xiǎng" (15x) claims "want" → "要 yào" (3x) uses "need/want"
    - German: "wollen" (15x) claims "to want" → "möchten" (5x) uses "would like"

  Once claimed, the mapping is LOCKED for consistency.

GRAMMATICAL_CONSTRAINT (NO flexibility):
  When target language grammar makes semantic distinctions that known language lacks,
  LEGOs MUST preserve that distinction with required context.

  NEVER allow grammatically ambiguous mappings that lose critical distinctions.

  Examples by language family:

  Spanish (ser/estar distinction - permanent vs temporary):
    ✅ "estoy aprendiendo" / "I'm learning" (temporary state - estar)
    ✅ "soy profesor" / "I'm a teacher" (permanent identity - ser)
    ❌ "estoy" / "I am" (loses ser/estar distinction)
    ❌ "soy" / "I am" (loses ser/estar distinction)
    SOLUTION: Always include context that disambiguates

  German (du/Sie distinction - formal vs informal):
    ✅ "Wie geht es Ihnen" / "How are you (formal)"
    ✅ "Wie geht es dir" / "How are you (informal)"
    ❌ "Sie/du" / "you" (loses formality distinction)
    SOLUTION: Include context or use register markers

  Japanese (honorific levels - plain/polite/humble/respectful):
    ✅ "食べます (tabemasu)" / "to eat (polite)"
    ✅ "食べる (taberu)" / "to eat (plain)"
    ❌ Generic "eat" without register marker
    SOLUTION: Always mark register in known translation

  Mandarin (aspect markers - progressive/completed/experiential):
    ✅ "我在吃 (wǒ zài chī)" / "I'm eating (progressive 在)"
    ✅ "我吃了 (wǒ chī le)" / "I ate (completed 了)"
    ❌ "吃 (chī)" / "eat" (loses aspect distinction)
    SOLUTION: Include aspect marker in COMPOSITE LEGO

  French (tu/vous distinction):
    ✅ "Comment allez-vous" / "How are you (formal)"
    ✅ "Comment vas-tu" / "How are you (informal)"
    ❌ "tu/vous" / "you" (loses formality distinction)

CRITICAL RULE:
  If your target language has grammatical distinctions that known language doesn't,
  you MUST use CHUNK UP principle to preserve those distinctions in LEGOs.
  Never create ambiguous mappings that collapse critical grammar.

### AUTOMATIC REJECTION LIST
FUNCTION_WORDS (ALWAYS FAIL FD):
  - Articles: el/la/los/las, un/una (gender ambiguous)
  - Pronouns: le/lo/la (multiple meanings)
  - Prepositions: en (in/on/at), de (of/from/about), por/para
  - "que" (that/what/which) - context dependent

MULTI_MEANING_WITHOUT_CONSTRAINTS:
  - "bien" → well/good/fine (use FCFS to claim primary meaning)
  - "muy" → very/really (use FCFS for intensity)

### DUAL-PASS METHODOLOGY

PASS 1: Forward Analysis (Target → Known)
  1. Start with first word of target sentence
  2. Test for FD compliance using FD_LOOP
  3. If fails, expand to include next word
  4. Continue until FD passes or sentence complete
  5. Move to next unmapped word

PASS 2: Reverse Validation (Known → Target)
  1. Take each known chunk
  2. Verify it maps back to EXACT target chunk
  3. If different → REJECT and re-decompose

PASS 3: Corpus-Wide Validation
  For EVERY chunk, search ALL other SEED_PAIRS in batch:
  - Find every occurrence of this chunk
  - Count frequency of each mapping
  - Apply FCFS: most frequent claims simple mapping
  - Less frequent must differentiate with context
  - If conflicts cannot be resolved → FLAG for SEED_PAIR revision

PASS 4: SEED_PAIR Revision Notes
  If decomposition reveals FD conflicts:
  - Note which SEED_PAIRS need editing
  - Suggest specific changes to maintain FD
  - Example: "I want coffee" might need → "I'd like coffee" if "quiero" is claimed

### LEGO TYPES

BASE_LEGO:
  DEFINITION: Fundamental FD unit that cannot be broken down further
  CHARACTERISTICS:
    - Single, atomic unit
    - FD (passes target → known → target)
    - Not composed of other LEGOs
  EXAMPLES:
    - "Voglio" = "I want"
    - "voy" = "I'm going"
    - "algo" = "something"

COMPOSITE_LEGO:
  DEFINITION: FD unit comprising BASE LEGOs + non-LEGO glue words
  CHARACTERISTICS:
    - Itself is FD as a complete unit
    - Contains at least ONE BASE LEGO + glue words
    - BASE LEGOs within DO NOT TILE (don't concatenate cleanly)
    - Glue words are NOT LEGOs themselves
  EXAMPLES:
    - "voy a decir" = "I'm going to say" (glue: "a")
    - "sto per esercitarmi" = "I'm going to practice" (glue: "per")
  WHEN_TO_CREATE:
    - BASE LEGOs don't TILE if concatenated directly
    - Glue words (prepositions, particles) required between
    - Unit is more useful taught as one piece

FEEDERS:
  DEFINITION: BASE LEGOs that feed into a COMPOSITE LEGO
  CHARACTERISTICS:
    - They are BASE LEGOs themselves (FD, atomic, standalone)
    - Have dual existence:
      1. As independent BASE LEGOs (own baskets, used in phrases)
      2. As components within COMPOSITE LEGO
    - Stored with F## suffix (not L##) when part of COMPOSITE
    - NOT subordinate to COMPOSITE - full LEGOs used in multiple contexts
  EXAMPLE:
    - COMPOSITE: "voy a decir" (S0005L02)
    - FEEDER 1: "voy" (S0005F01) ← Also exists as BASE LEGO elsewhere
    - FEEDER 2: "decir" (S0005F02) ← Also exists as BASE LEGO elsewhere
    - Glue: "a" (NOT a LEGO, NOT a FEEDER)

### TILING CONCEPT

DEFINITION: LEGOs that concatenate cleanly without glue words

TILES (Concatenate directly):
  - No additional words needed between LEGOs
  - Direct concatenation reconstructs sentence
  - Keep as separate BASE LEGOs
  EXAMPLE: "Voglio parlare" = "Voglio" + "parlare" ✅ TILES

DOES_NOT_TILE (Needs glue):
  - Additional words required between LEGOs
  - Cannot concatenate directly
  - Create COMPOSITE LEGO
  EXAMPLE: "voy a decir" ≠ "voy" + "decir" ❌ DOESN'T TILE (needs "a")

DECISION_RULE:
  IF (BASE LEGOs TILE):
    → Keep as separate BASE LEGOs
  ELSE IF (BASE LEGOs DON'T TILE):
    → Create COMPOSITE LEGO with FEEDERs

### COMPONENTIZATION (Pedagogical Explanation)

PURPOSE: Help learners understand how multi-word LEGOs break down

TWO TYPES:

1. For BASE LEGOs that TILE:
   - LEGOs remain separate in structure
   - But add explanation for learner clarity
   - Example: "parlare italiano" stays as two LEGOs (parlare + italiano)
   - Add: "parler italien = parlare italiano, où parlare = parler et italiano = italien"

2. For COMPOSITE LEGOs:
   - LEGO is structurally one unit (doesn't tile)
   - Show FEEDERs to help learner understand components
   - Example: "voy a decir" is ONE COMPOSITE LEGO
   - FEEDERs: voy (F01), decir (F02)
   - Explanation: "voy a decir = I'm going to say, where voy = I'm going, a = [particle], decir = to say"

RULE: Add componentization when BOTH target AND known are multi-word

FORMAT: Simple word mappings in KNOWN language
  "[known LEGO] = [target LEGO], where [target1] = [known1] and [target2] = [known2]"

CRITICAL: Write ALL componentization in KNOWN language, NOT English!
  - French speakers: Use "où" (not "where"), "et" (not "and")
  - Spanish speakers: Use "donde" (not "where"), "y" (not "and")

### IRON RULE
ABSOLUTE_CONSTRAINT: No LEGO begins or ends with a STANDALONE preposition

CRITICAL CLARIFICATION - Prepositional Phrases:
  - Standalone prepositions WITHOUT objects: ❌ FORBIDDEN
  - Complete prepositional phrases WITH objects: ✅ ALLOWED

ALLOWED (Complete prepositional phrases):
  ✅ "con te" / "with you" (complete prepositional phrase)
  ✅ "con me" / "with me" (complete prepositional phrase)
  ✅ "in italiano" / "in Italian" (complete prepositional phrase)
  ✅ "avec tous les autres" / "with everyone else" (complete prepositional phrase)
  ✅ "con tutti gli altri" / "with everyone else" (complete prepositional phrase)

NOT ALLOWED (Standalone prepositions):
  ❌ "con" / "with" (standalone preposition)
  ❌ "in" / "in" (standalone preposition)
  ❌ "per" / "to" (standalone preposition)
  ❌ "de" / "of" (standalone preposition)
  ❌ "da" / "from" (standalone preposition)

INFINITIVE MARKER CLARIFICATION:
  - The infinitive marker "to" (as in "to speak") is NOT a preposition
  - It is a grammatical marker that forms part of the infinitive verb
  - Full infinitives like "to speak", "to learn" are ALLOWED and FD-compliant
  - Bare infinitives are NOT FD (conflict with commands and conjugations)

EXAMPLES:
  ✅ "to speak" / "parlare" (infinitive marker + verb)
  ✅ "to learn" / "imparare" (infinitive marker + verb)
  ❌ "to the" / "al" (directional preposition - needs object!)

PRINCIPLE: Prepositional phrases are complete, meaningful, FD-compliant units.
          The issue is orphaned prepositions without objects, not complete phrases.

NON_NEGOTIABLE: No standalone prepositions at LEGO boundaries

### UID FORMAT
MANDATORY_STRUCTURE:
  LEGOs: S{seed_id}L{position}
  FEEDERs: S{seed_id}F{position}

EXAMPLES:
  - Seed S0001 → LEGOs: S0001L01, S0001L02, S0001L03
  - Seed S0001 → FEEDERs: S0001F01, S0001F02

NEVER_USE:
  ❌ L0001 (missing parent seed ID)
  ❌ F0001 (missing parent seed ID)

### CONCRETE EXAMPLE

INPUT (from Phase 1):
{
  "seed_id": "S0001",
  "target": "Voglio parlare italiano con te adesso.",
  "known": "Je veux parler italien avec toi maintenant."
}

OUTPUT (Phase 3 decomposition):
{
  "seed_id": "S0001",
  "original_target": "Voglio parlare italiano con te adesso.",
  "original_known": "Je veux parler italien avec toi maintenant.",
  "lego_pairs": [
    {
      "lego_id": "S0001L01",
      "target_chunk": "Voglio",
      "known_chunk": "Je veux",
      "fd_validated": true
    },
    {
      "lego_id": "S0001L02",
      "target_chunk": "parlare italiano",
      "known_chunk": "parler italien",
      "fd_validated": true
    },
    {
      "lego_id": "S0001L03",
      "target_chunk": "con te",
      "known_chunk": "avec toi",
      "fd_validated": true
    },
    {
      "lego_id": "S0001L04",
      "target_chunk": "adesso",
      "known_chunk": "maintenant",
      "fd_validated": true
    }
  ],
  "feeder_pairs": [
    {
      "feeder_id": "S0001F01",
      "target_chunk": "parlare",
      "known_chunk": "parler"
    },
    {
      "feeder_id": "S0001F02",
      "target_chunk": "italiano",
      "known_chunk": "italien"
    }
  ],
  "componentization": [
    {
      "lego_id": "S0001L02",
      "explanation": "parler italien = parlare italiano, où parlare = parler et italiano = italien"
    },
    {
      "lego_id": "S0001L03",
      "explanation": "avec toi = con te, où con = avec et te = toi"
    }
  ]
}

### PHASE 3 REFINEMENTS (Validated from Italian 30-seed production test)

These 10 critical refinements emerged from real-world decomposition testing and
should be applied to ALL language pair combinations.

#### 1. IRON RULE CLARIFICATION - Prepositional Phrases
**Prepositional phrases WITH objects are FD-compliant and ALLOWED.**

See IRON RULE section above for complete details.

Key insight: The problem is orphaned prepositions, not complete prepositional phrases.
Complete phrases like "con te" / "with you" are meaningful FD units.

#### 2. Infinitive "to" Placement Rule
**English infinitives: "to" attaches to the FOLLOWING verb, not trailing on modals.**

CORRECT:
  - "poter" = "to be able" (NOT "to be able to")
  - "parlare" = "to speak"
  - Combined: "poter parlare" = "to be able to speak"

INCORRECT:
  - ❌ "poter" = "to be able to"
  - ❌ "parlare" = "speak"

RATIONALE:
  In "I want to be able to speak", the structure has TWO infinitives:
    - "want" (modal)
    - "to be able" (infinitive 1)
    - "to speak" (infinitive 2)
  Each infinitive carries its own "to" marker.

#### 3. Minimal FD Chunks Principle
**Break LEGOs into SMALLEST FD-compliant chunks that are PEDAGOGICALLY HELPFUL.**

PROCESS:
  1. Can this LEGO break into smaller FD components?
  2. Would learning components FIRST help understand the composite?
  3. If YES → Create BASE LEGOs + COMPOSITE + FEEDERS
  4. If NO → Keep as single LEGO

EXAMPLE - GOOD BREAKDOWN:
  "il più spesso possibile" / "as often as possible"

  BASE LEGOs:
    - "spesso" / "often" (FD ✓, pedagogically helpful ✓)
    - "possibile" / "possible" (FD ✓, pedagogically helpful ✓)

  COMPOSITE LEGO:
    - "il più spesso possibile" / "as often as possible"

  FEEDERS:
    - "spesso" (learned as BASE LEGO)
    - "possibile" (learned as BASE LEGO)

EXAMPLE - KEEP AS SINGLE:
  "il più possibile" / "as hard as I can"

  Why? English translation is idiomatic and doesn't map directly to components.
  Breaking down "possibile" = "possible" wouldn't help learner understand
  "as hard as I can" - the mapping is non-compositional.

#### 4. Glue Words Must Stay INSIDE Composites
**Function words (di, a, per, che, de, à, von, etc.) must NEVER appear at LEGO edges.**
**They must be CONTAINED within composite units.**

CORRECT:
  ✅ "Sto cercando di ricordare" / "I'm trying to remember" (full COMPOSITE)
  ✅ "cercare di spiegare" / "to try to explain" (full COMPOSITE)
  ✅ "smettere di parlare" / "to stop talking" (full COMPOSITE)

INCORRECT:
  ❌ "Sto cercando di" / "I'm trying to" + "ricordare" / "remember"
      (leaves "di" trailing - breaks recombination)
  ❌ "cercare di" / "to try to" + "spiegare" / "explain"
      (leaves "di" trailing - breaks recombination)

RATIONALE:
  Leaving glue words at edges makes basket recombination (Phase 5) nearly
  impossible and creates unnatural phrase boundaries.

#### 5. FEEDERS - Selective, Not Exhaustive
**Only include FD and PEDAGOGICALLY HELPFUL components as FEEDERs.**

OLD APPROACH (wrong):
  Include ALL components of a COMPOSITE as FEEDERs

NEW APPROACH (correct):
  Only include components that are:
    1. FD-compliant (pass FD_LOOP test independently)
    2. Pedagogically helpful (aid learner understanding)

EXAMPLE:
  Seed: "Sto per cercare di spiegare quello che intendo."
  English: "I'm going to try to explain what I mean."

  LEGO: "quello che intendo" / "what I mean"

  FEEDERS:
    ✅ "intendo" / "I mean" (FD ✓, helpful ✓)

  NOT FEEDERS:
    ❌ "quello che" / "what" (NOT FD - could be cosa, che cosa, quale, etc.)

PRINCIPLE:
  If a component is NOT FD, don't include it as a FEEDER.
  The componentization explanation can still MENTION it for learner context,
  but it shouldn't be a separate teaching unit.

#### 6. Componentization Language - "represents" vs "means"
**Use precise language to describe component relationships.**

USE "means" when:
  - Direct, literal, word-for-word translation
  - Clear 1:1 correspondence
  - Example: "dove con = with and me = me"

USE "represents" when:
  - Idiomatic or structural translations
  - Grammar that doesn't translate directly
  - Non-compositional mappings
  - Example: "where Non vedo l'ora represents looking forward"
  - Example: "where che finisci represents that you finish"

This helps learners understand which mappings are direct vs interpretive.

#### 7. Function Words - Avoid Standalone LEGOs
**Function words should NOT be standalone LEGOs unless genuinely useful alone.**

AVOID AS STANDALONE:
  ❌ "E" / "And" (rarely useful in isolation)
  ❌ "Ma" / "But" (rarely useful in isolation)
  ❌ "se" / "if" (combine with clause: "se posso ricordare" / "if I can remember")
  ❌ "per" / "to" (combine with verb: "per rispondere" / "to answer")

ACCEPTABLE STANDALONE:
  ✅ "Perché" / "Why" or "Because" (question word / connector, high utility)
  ✅ "con" / "with" (when it appears separately in useful contexts)

PRINCIPLE:
  If a word rarely appears alone in natural speech, don't make it a standalone LEGO.
  CHUNK UP to include context that makes it a complete, useful teaching unit.

#### 8. FD Violations - Gender and Context Ambiguity
**CRITICAL: Avoid gender-specific or context-dependent translations.**
(See FD_LOOP GENDER AND CONTEXT NEUTRALITY section above for complete details)

Quick reference:
  - Use gender-neutral translations: "wants" not "he wants" / "she wants"
  - Use singular "they/their" for possessives: "their name" not "his/her name"
  - Context provided in full seed, NOT in individual LEGO translations

#### 9. Building Composites Hierarchically
**Create LEGOs at each hierarchical level when phrases build up naturally.**

EXAMPLE:
  Seed: "con qualcun altro" / "with someone else"

  Hierarchical breakdown:
    L01: "con" / "with"
    L02: "qualcuno" / "someone"
    L03: "altro" / "else"
    L04: "qualcun altro" / "someone else"
        FEEDERS: qualcuno, altro
        COMPONENTIZATION: "someone else = qualcun altro, where qualcuno = someone and altro = else"
    L05: "con qualcun altro" / "with someone else"
        FEEDERS: con, qualcun altro
        COMPONENTIZATION: "with someone else = con qualcun altro, where con = with and qualcun altro = someone else"

RATIONALE:
  Learners build understanding from smallest units to complete phrases naturally.
  This hierarchical structure mirrors natural language acquisition.

#### 10. CHUNK UP Principle - The FD Rescue Strategy
**When context is needed for FD compliance → CHUNK UP to create larger COMPOSITE.**
(See THE CHUNK UP PRINCIPLE in FD_LOOP section above for complete algorithm)

DO NOT use vague "context-dependent" labels:
  ❌ WRONG: "parlare" / "speaking" (gerund in context) ← Vague! What context?
  ❌ WRONG: "ricordare" / "remember" (after modal) ← Ambiguous!

INSTEAD, CHUNK UP to include context:
  ✅ RIGHT: "sta parlando" / "is speaking" (COMPOSITE includes progressive marker)
            FEEDERS: "sta" / "is", "parlare" / "to speak"
            COMPONENTIZATION: "is speaking = sta parlando, where sta represents is and parlando represents speaking"

  ✅ RIGHT: "voglio ricordare" / "I want to remember" (COMPOSITE includes modal)
            FEEDERS: "voglio" / "I want", "ricordare" / "to remember"

  ✅ RIGHT: "sto cercando di ricordare" / "I'm trying to remember" (larger COMPOSITE)
            FEEDERS: "sto" / "I'm", "cercare" / "to try", "ricordare" / "to remember"
            COMPONENTIZATION: Shows how "cercando di" forms progressive + infinitive structure

THE ALGORITHM:
  1. Test word alone for FD → FAIL?
  2. Add surrounding word (left or right) → Test FD
  3. Still FAIL? Keep expanding
  4. Create COMPOSITE LEGO with full context that PASSES FD
  5. Extract FD components as FEEDERS
  6. Add COMPONENTIZATION explanation for learner understanding

This is the universal FD rescue strategy that works across ALL language pairs.

PROMPT: |
  # Phase 3: LEGO Decomposition

  Hi! I need help with Phase 3 of my language course project - LEGO decomposition.

  Working with ${targetLang} for ${knownLang} speakers.

  ## CORE PRINCIPLE
  Break each SEED_PAIR into LEGO chunks that:
  1. When placed side-by-side, EXACTLY reconstruct the original sentence
  2. Each LEGO passes the FD_LOOP test independently
  3. Are reusable across multiple sentences

  ## LEGO TYPES & ARCHITECTURE

  ### BASE LEGO (Simple/Atomic)
  - Fundamental FD unit
  - Cannot be broken down further
  - Examples: "Voglio", "parlare", "voy", "decir"

  ### COMPOSITE LEGO (Contains BASE + Glue)
  - FD unit with BASE LEGOs + non-LEGO glue words
  - BASE LEGOs DON'T TILE (can't concatenate directly)
  - Examples:
    - "voy a decir" (voy + a + decir) - "a" is glue
    - "sto per esercitarmi" (sto + per + esercitarmi) - "per" is glue

  ### FEEDERS
  - BASE LEGOs within a COMPOSITE
  - Stored separately with F## suffix
  - Help learners understand COMPOSITE structure

  ### TILING TEST
  **Question**: Can you concatenate these LEGOs directly?

  IF YES (TILES):
  → Keep as separate BASE LEGOs
  Example: "Voglio" + "parlare" = "Voglio parlare" ✅

  IF NO (DOESN'T TILE):
  → Create COMPOSITE LEGO + FEEDERs
  Example: "voy" + "decir" ≠ "voy decir" ❌ (need "a")
  → COMPOSITE: "voy a decir"
  → FEEDERs: "voy" (F01), "decir" (F02)

  ## YOUR EXTRACTION PROCESS

  For each seed:

  1. Break into potential chunks
  2. Validate each chunk is FD
  3. Check if chunks contain multiple BASE LEGOs
  4. Apply TILING TEST:
     - TILES? → Separate BASE LEGOs
     - DOESN'T TILE? → COMPOSITE LEGO + FEEDERs
  5. Add componentization explanation (pedagogical)

  ## MANDATORY UID FORMAT
  For seed S0001:
  - LEGOs: S0001L01, S0001L02, S0001L03
  - FEEDERs: S0001F01, S0001F02 (sub-components of multi-word LEGOs)
  NEVER use L0001 or F0001 (missing parent seed ID)

  ## 🔍 FD_LOOP TEST (MANDATORY FOR EVERY CHUNK)
  Target → Known → Target = MUST BE IDENTICAL
  ✅ "importante" → "important" → "importante" (IDENTICAL)
  ❌ "bien" → "good" → "bueno" (DIFFERENT = FAIL)

  ## 🎯 FCFS RULE (First Come, First Served)
  When multiple valid mappings exist, use corpus frequency to CLAIM semantic territory.

  **UNIVERSAL PRINCIPLE**: Most frequent variant claims simple translation (if grammatically valid).
  Less frequent variants must differentiate with context. Works for ANY language pair.

  ### ARTISTIC CHOICE (flexible mapping allowed):
  When multiple ${targetLang} words can express the same ${knownLang} meaning:
  - Most frequent (15x) → CLAIMS simple translation
  - Less frequent (2x) → must use more specific translation
  - Once claimed, mapping is LOCKED for consistency

  Example patterns:
    - If "word_A" appears 15x → claims simple meaning
    - If "word_B" appears 2x → must differentiate (e.g., add intensity/formality)

  ### GRAMMATICAL CONSTRAINT (NO flexibility):
  When ${targetLang} grammar makes distinctions that ${knownLang} doesn't:
  → LEGOs MUST preserve that distinction with context
  → NEVER create ambiguous mappings
  → Use CHUNK UP principle to include disambiguating context

  Common patterns to watch for:
    - Formal/informal distinctions (Spanish tú/usted, German du/Sie, French tu/vous)
    - Permanent/temporary states (Spanish ser/estar)
    - Aspect markers (Mandarin 了/在/过, Slavic perfective/imperfective)
    - Honorific levels (Japanese plain/polite/humble, Korean 해요/합니다)
    - Gender agreement (Romance languages, German, Slavic)

  **CRITICAL**: If ${targetLang} has grammatical distinctions, CHUNK UP to preserve them!

  ✅ RIGHT: Include context that disambiguates
  ❌ WRONG: Collapse distinctions into generic translation

  ### FCFS PROCESS:
  1. Count frequency of each mapping across ALL corpus seeds
  2. Most frequent CLAIMS simple mapping (if grammatically valid)
  3. Less frequent must ADD context to differentiate
  4. If corpus edit needed to maintain FD, NOTE it for SEED_PAIR revision

  ## 🚫 AUTOMATIC REJECTION LIST
  **Function Words (ALWAYS FAIL FD):**
  - Articles: el/la/los/las, un/una (gender ambiguous)
  - Pronouns: le/lo/la (multiple meanings)
  - Prepositions: en (in/on/at), de (of/from/about), por/para
  - "que" (that/what/which) - context dependent

  **Multi-meaning words WITHOUT grammar constraints:**
  - "bien" → well/good/fine (use FCFS to claim primary meaning)
  - "muy" → very/really (use FCFS for intensity)

  ## ✅ DUAL-PASS METHODOLOGY

  ### PASS 1: Forward Analysis (${targetLang} → ${knownLang})
  1. Start with first word of ${targetLang} sentence
  2. Test for FD compliance using FD_LOOP
  3. If fails, expand to include next word
  4. Continue until FD passes or sentence complete
  5. Move to next unmapped word

  ### PASS 2: Reverse Validation (${knownLang} → ${targetLang})
  1. Take each ${knownLang} chunk
  2. Verify it maps back to EXACT ${targetLang} chunk
  3. If different → REJECT and re-decompose

  ### PASS 3: Corpus-Wide Validation
  For EVERY chunk, search ALL other SEED_PAIRS in batch:
  - Find every occurrence of this chunk
  - Count frequency of each mapping
  - Apply FCFS: most frequent claims simple mapping
  - Less frequent must differentiate with context
  - If conflicts cannot be resolved → FLAG for SEED_PAIR revision

  ### PASS 4: SEED_PAIR Revision Notes
  If decomposition reveals FD conflicts:
  - Note which SEED_PAIRS need editing
  - Suggest specific changes to maintain FD
  - Example: "I want coffee" might need → "I'd like coffee" if "quiero" is claimed

  ## 📝 COMPONENTIZATION REQUIREMENT (BOTH languages must be multi-word!)
  COMPONENTIZATION is ONLY needed when BOTH target AND known are multi-word:
  - ✅ REQUIRED: "parlare italiano" ↔ "parler italien" (BOTH are 2 words)
  - ✅ REQUIRED: "para su hermana" ↔ "for his sister" (BOTH are 3 words)
  - ❌ NOT NEEDED: "construir" ↔ "build" (both single words)
  - ❌ NOT NEEDED: "una nueva vida" ↔ "a new life" (even though multi-word, simple 1:1 mapping)

  FORMAT: Simple word mappings ONLY (no grammar explanations):
  "[known LEGO] = [target LEGO], where [target1] = [known1] and [target2] = [known2]"

  ⚠️ CRITICAL: Write ALL componentization in ${knownLang}, NOT English!
  - French speakers: Use French words like "où" (not "where"), "et" (not "and")
  - Spanish speakers: Use Spanish words like "donde" (not "where"), "y" (not "and")
  - Chinese speakers: Use Chinese: "其中" (not "where"), "和" (not "and")

  Example for ${knownLang} speakers:
  French: "parler italien = parlare italiano, où parlare = parler et italiano = italien"
  Spanish: "hablar italiano = parlare italiano, donde parlare = hablar y italiano = italiano"
  NOT: "parler italien = parlare italiano, where parlare = parler and italiano = italien" ❌

  ## THE IRON RULE (ABSOLUTE)
  **No LEGO begins or ends with a STANDALONE preposition.**

  **CRITICAL CLARIFICATION - Prepositional Phrases**:
  - Standalone prepositions WITHOUT objects: ❌ FORBIDDEN
  - Complete prepositional phrases WITH objects: ✅ ALLOWED

  **ALLOWED (Complete prepositional phrases)**:
  - ✅ "con te" / "with you" (complete prepositional phrase)
  - ✅ "con me" / "with me" (complete prepositional phrase)
  - ✅ "in italiano" / "in Italian" (complete prepositional phrase)
  - ✅ "avec tous" / "with everyone" (complete prepositional phrase)

  **NOT ALLOWED (Standalone prepositions)**:
  - ❌ "con" / "with" (standalone preposition)
  - ❌ "in" / "in" (standalone preposition)
  - ❌ "per" / "to" (standalone preposition)
  - ❌ "de" / "of" (standalone preposition)

  **INFINITIVE MARKER CLARIFICATION**:
  - The infinitive marker "to" (as in "to speak") is NOT a preposition
  - It is a grammatical marker that forms part of the infinitive verb
  - Full infinitives like "to speak", "to learn" are ALLOWED and FD-compliant
  - Bare infinitives are NOT FD (conflict with commands and conjugations)

  **Examples**:
  - ✅ "to speak" / "parlare" (infinitive marker + verb)
  - ✅ "to learn" / "imparare" (infinitive marker + verb)
  - ❌ "to the" / "al" (directional preposition - needs object!)

  **PRINCIPLE**: Prepositional phrases are complete, meaningful, FD-compliant units.
              The issue is orphaned prepositions without objects.

  **NON-NEGOTIABLE**: No standalone prepositions at LEGO boundaries

  ## INPUT DATA
  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/

  Read ALL SEED_PAIRS from:
  SEED_PAIRS_COMPLETE.json (contains all 668 seeds)

  The files contain JSON with structure:
  {
    "seed_pairs": [
      {
        "seed_id": "S0001",
        "target": "[sentence in ${targetLang}]",
        "known": "[sentence in ${knownLang}]"
      }
    ]
  }

  ## OUTPUT FILES
  Save to course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/

  1. Process in batches of 20 seeds:
     - LEGO_BREAKDOWNS_BATCH_001.json (seeds 1-20)
     - LEGO_BREAKDOWNS_BATCH_002.json (seeds 21-40)
     - etc.

  2. ALSO create combined file with ALL breakdowns:
     - LEGO_BREAKDOWNS_COMPLETE.json (all seeds combined)

  Create this exact structure for each file:
  {
    "phase": "LEGO_BREAKDOWNS",
    "batch": "001",
    "target_language": "${targetLang}",
    "known_language": "${knownLang}",
    "lego_breakdowns": [
      // For EACH seed_pair in the input file:
      {
        "seed_id": "S0001",
        "canonical_id": "C0001",
        "original_target": "actual ${targetLang} sentence",
        "original_known": "actual ${knownLang} sentence",
        "lego_pairs": [
          // Break into FD-compliant chunks
        ],
        "feeder_pairs": [
          // Sub-components of multi-word LEGOs
        ],
        "componentization": [
          // ONLY when BOTH target AND known are multi-word!
          // Simple mappings format: known = target, where word1 = word1 and word2 = word2
          {
            "lego_id": "S0001L02",
            "explanation": "[known LEGO] = [target LEGO], where [word1] = [word1] and [word2] = [word2]"
          }
          // Skip if either side is single word or if it's a simple 1:1 mapping
        ]
      }
    ]
  }

  ## CRITICAL OUTPUT RULES
  - **SILENT OPERATION** - Work quietly, save to file
  - **NO PRINTING** - Don't display breakdowns
  - **VFS ONLY** - Save to VFS only, no console output

  Start decomposing immediately.

## Phase 3.5: Graph Construction

NAME: "Graph Construction"
PURPOSE: Build directed graph of LEGO adjacency relationships
INPUT:
  - vfs/amino_acids/legos/*.json
  - vfs/amino_acids/translations/*.json (for co-occurrence analysis)
OUTPUT: vfs/phase_outputs/phase_3.5_lego_graph.json

NEW_IN_V7: This phase is NEW in APML v7.0 - introduces graph intelligence

GRAPH_STRUCTURE:
  NODES: All LEGO amino acids
  EDGES: Directed edges LEGO_A → LEGO_B (when A precedes B in corpus)
  WEIGHTS: co-occurrence frequency × pedagogical value

PURPOSE_FOR_PHASE_5:
  - Graph edges represent legitimate LEGO sequence patterns
  - Phase 5 uses this to ensure pattern coverage in baskets
  - Replaces old DEBUT/ETERNAL pattern logic with measurable diversity

ADJACENCY_DETECTION:
  - Scan translations to find which LEGOs appear adjacent
  - Example: In "Dw i eisiau mynd", LEGOs "Dw i" and "eisiau" are adjacent
  - Direction matters: A→B ≠ B→A

VALIDATION:
  - Ensure graph is connected
  - Check for invalid cycles
  - Verify all LEGOs represented

PROMPT: |
  # Phase 3.5: Graph Construction (NEW in v7.0)

  ## Task
  Build directed graph of LEGO adjacency relationships to enable pattern-aware basket construction.

  ## Input
  - LEGO amino acids: vfs/amino_acids/legos/*.json
  - Translation amino acids: vfs/amino_acids/translations/*.json (for co-occurrence analysis)

  ## Your Mission
  1. **Detect Adjacency Patterns**:
     - Scan source translations to find which LEGOs appear adjacent to each other
     - Example: In "Dw i eisiau mynd", LEGOs "Dw i" and "eisiau" are adjacent

  2. **Build Directed Graph**:
     - Nodes: All LEGO amino acids
     - Edges: LEGO_A → LEGO_B (A precedes B in corpus)
     - Direction matters (A→B ≠ B→A)

  3. **Calculate Edge Weights**:
     - Weight = co-occurrence frequency × pedagogical value
     - Higher weight = more important pattern to teach

  4. **Validate Graph**:
     - Ensure graph is connected
     - Check for invalid cycles
     - Verify all LEGOs represented

  5. **Export Graph Structure**:
     - Adjacency list format
     - Include edge weights
     - Store metadata (total nodes, edges, density)

  ## Output Format
  vfs/phase_outputs/phase_3.5_lego_graph.json

  {
    "nodes": [ ... ],
    "edges": [
      { "from": "uuid_A", "to": "uuid_B", "weight": 42 },
      ...
    ],
    "metadata": { ... }
  }

  ## Critical Notes
  - This is NEW in APML v7.0 - graph intelligence!
  - Phase 5 uses this graph for pattern coverage optimization
  - Edges represent legitimate LEGO sequence patterns
  - Replaces old DEBUT/ETERNAL pattern logic

  ## Success Criteria
  ✓ All LEGO adjacencies mapped
  ✓ Directed edges created
  ✓ Edge weights calculated
  ✓ Graph validated (connected, no invalid cycles)
  ✓ Ready for Phase 5 consumption

## Phase 4: DEPRECATED - Merged into Phase 5.5

DEPRECATED: This phase has been replaced by Phase 5.5 (Basket Deduplication)
REASON: More efficient to create baskets for all LEGO_PAIRS first, then deduplicate baskets
OLD APPROACH: Deduplicate LEGOs → Create baskets
NEW APPROACH: Create baskets (with seed context) → Deduplicate baskets

See Phase 5.5 for new deduplication workflow.

---

## Phase 4 (OLD - DEPRECATED): Deduplication

NAME: "Deduplication"
PURPOSE: Merge duplicate LEGOs while preserving ALL provenance
INPUT: vfs/amino_acids/legos/*.json
OUTPUT: vfs/amino_acids/legos_deduplicated/*.json

WHY_CRITICAL:
  - Many LEGOs appear in multiple seeds
  - Example: "Dw i" might appear from S1L1, S4L2, S12L3
  - Provenance enables edit propagation
  - If seed S12 changes, we know which LEGOs to update

MERGING_PROCESS:
  1. Detect duplicates (identical text content, different UUIDs)
  2. Combine ALL S{seed}L{position} labels
  3. Example: S1L1, S4L2, S12L3 → "S1L1, S4L2, S12L3"
  4. Generate new deterministic UUID based on merged provenance
  5. Create deduplicated set (one LEGO per unique text)

IMMUTABILITY_PRESERVED:
  - Keep original LEGOs (immutable)
  - Deduplicated set is NEW amino acids
  - NEVER lose any provenance information

OUTPUT_STRUCTURE:
  uuid: new_deduplicated_uuid
  text: "the LEGO phrase"
  provenance: ["S1L1", "S4L2", "S12L3"]
  source_count: 3
  metadata: { ... }

PROMPT: |
  # Phase 4: Deduplication

  ## Task
  Identify and merge duplicate LEGOs while preserving ALL provenance information.

  ## Input
  - LEGO amino acids: vfs/amino_acids/legos/*.json

  ## Your Mission
  1. **Detect Duplicates**:
     - Find LEGOs with identical text content
     - May have different UUIDs (different provenance)
     - Example: "Dw i" might appear from S1L1, S4L2, S12L3

  2. **Merge Provenance**:
     - Combine all S{seed}L{position} labels
     - Example: Merge S1L1, S4L2, S12L3 → "S1L1, S4L2, S12L3"
     - NEVER lose any provenance information

  3. **Recalculate UUID**:
     - Generate new deterministic UUID based on:
       - LEGO text
       - ALL merged provenance labels
       - Metadata

  4. **Create Deduplicated Set**:
     - One LEGO per unique text
     - Complete provenance history preserved
     - Update graph references if needed

  5. **Store Results**:
     - vfs/amino_acids/legos_deduplicated/*.json
     - Keep original LEGOs (immutable)
     - Deduplicated set is NEW amino acids

  ## Why This Matters
  - Many LEGOs appear in multiple seeds
  - Provenance enables edit propagation
  - If seed S12 changes, we know which LEGOs to update
  - Birth-parent history must NEVER be lost

  ## Output Structure
  {
    "uuid": "new_deduplicated_uuid",
    "text": "the LEGO phrase",
    "provenance": ["S1L1", "S4L2", "S12L3"],
    "source_count": 3,
    "metadata": { ... }
  }

  ## Success Criteria
  ✓ All duplicates identified
  ✓ Provenance fully merged (no data loss)
  ✓ New UUIDs generated
  ✓ Deduplicated set created
  ✓ Original LEGOs preserved (immutable)

## Phase 5: Basket Generation (Edge-Aware + d-phrases/e-phrases)

NAME: "Basket Generation with Graph Intelligence and Progressive Vocabulary"
PURPOSE: Create practice phrase baskets for ALL LEGO_PAIRS (deduplication happens in Phase 5.5)
INPUT:
  - vfs/courses/{course_code}/translations.json (to get LEGO decomposition)
  - vfs/courses/{course_code}/phase_outputs/phase_3.5_lego_graph.json (for edge coverage)
  - vfs/courses/{course_code}/phase_outputs/phase_2_corpus_intelligence.json (for FCFS ordering)
OUTPUT: vfs/courses/{course_code}/baskets.json (ALL LEGO_PAIR baskets - includes duplicates)

CRITICAL_CHANGE:
  - OLD: Create baskets only for deduplicated LEGOs
  - NEW: Create baskets for ALL LEGO_PAIRS (every LEGO in every seed)
  - WHY: Each basket created with full SEED_PAIR context (culminating LEGO rule works naturally)
  - Deduplication happens AFTER in Phase 5.5 (delete duplicate baskets, keep first occurrence)

BATCH_PROCESSING:
  BATCH_SIZE: 20 LEGOs per batch
  PROCESSING: Forward (LEGO 1 → last LEGO, NOT backwards)

TWO_STAGE_PROCESS:
  STAGE 1 - Basket Selection (Graph-Driven):
    - Analyze LEGO adjacency graph from Phase 3.5
    - Select LEGOs to maximize edge coverage (pattern diversity)
    - Follow FCFS chronological progression from Phase 2
    - Ensure smooth difficulty progression
    - Goal: Learners experience maximum pattern variety

  STAGE 2 - Phrase Generation (Vocabulary-Constrained):
    - For each selected LEGO, generate d-phrases and e-phrases
    - Apply progressive vocabulary constraint
    - Each LEGO can ONLY use vocabulary from LEGOs that came before it
    - LEGO #1: NO vocabulary available = empty basket
    - LEGO #2: Can only use LEGO #1 = very limited
    - LEGO #N: Can use LEGOs #1 through #(N-1)
    - This creates natural progression where complexity builds gradually

COMBINING_BOTH_APPROACHES:
  - Edge coverage ensures corpus patterns are reflected
  - Progressive vocabulary ensures pedagogical soundness
  - FCFS ordering maintains chronological appropriateness
  - Result: Optimal learning sequence with rich practice

E_PHRASES (Eternal Practice Phrases):
  - 5 phrases per LEGO
  - Each 7-10 words long
  - Must contain the target LEGO
  - Perfect grammar in BOTH languages
  - Natural, conversational usage
  - Only use vocabulary from previous LEGOs

D_PHRASES (Deconstructed Practice Phrases):
  - Auto-generated from e_phrases using expanding windows
  - 2_lego: 2 phrases with 2 LEGOs each
  - 3_lego: 2 phrases with 3 LEGOs each
  - 4_lego: 2 phrases with 4 LEGOs each
  - 5_lego: 2 phrases with 5 LEGOs each
  - Must be syntactically correct (even as fragments) in BOTH languages

CULMINATING_LEGO_RULE:
  If this is the LAST LEGO in a seed (e.g., S0123L03 is last of S0123):
  - E-phrase #1 MUST be the COMPLETE SEED sentence
  - Use complete seed heavily in d-phrases (3+ times)
  - Gives learner satisfaction of understanding full seed

BASKET_STRUCTURE:
  {
    "S####L##": {
      "target": "target language LEGO",
      "known": "English translation",
      "e_phrases": [
        ["7-10 word phrase with LEGO", "English translation"],
        ... (5 total)
      ],
      "d_phrases": {
        "2_lego": [["phrase", "translation"], ...],
        "3_lego": [["phrase", "translation"], ...],
        "4_lego": [["phrase", "translation"], ...],
        "5_lego": [["phrase", "translation"], ...]
      }
    }
  }

PROMPT: |
  # Phase 5: Basket Generation - Graph Intelligence + Progressive Vocabulary

  ## TWO-STAGE PROCESS

  ### STAGE 1: Basket Selection (Graph-Driven)

  **Goal**: Select LEGO groupings that maximize pattern diversity

  1. **Load Graph Intelligence**:
     - Read: vfs/phase_outputs/phase_3.5_lego_graph.json
     - Adjacency graph showing which LEGOs appear near each other
     - Edge weights indicate co-occurrence frequency

  2. **Load FCFS Ordering**:
     - Read: vfs/phase_outputs/phase_2_corpus_intelligence.json
     - Chronological ordering from corpus frequency analysis
     - Ensures pedagogically sound sequence

  3. **Select LEGOs for Each Basket** (20 LEGOs per basket):
     - Maximize edge coverage (expose diverse patterns)
     - Follow FCFS chronological progression
     - Avoid redundant LEGO sequences across baskets
     - Ensure smooth difficulty progression
     - Balance novelty with reinforcement

  **Output of Stage 1**: Ordered list of LEGOs to process

  ### STAGE 2: Phrase Generation (Vocabulary-Constrained)

  **Goal**: Generate d-phrases and e-phrases for each selected LEGO

  ## CRITICAL PER-LEGO VOCABULARY CONSTRAINTS
  **ABSOLUTE RULE**: Each LEGO has DIFFERENT available vocabulary!
  - LEGO #1: NO VOCABULARY AVAILABLE = NO PHRASES POSSIBLE (empty basket)
  - LEGO #2: Can only use LEGO #1 = VERY LIMITED phrases possible
  - LEGO #3: Can only use LEGOs #1-2 = A FEW phrases possible
  - LEGO #N: Can only use LEGOs #1 through #(N-1)

  ## Input Data
  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/

  Read LEGOs from: vfs/amino_acids/legos_deduplicated/*.json
  Read Graph: vfs/phase_outputs/phase_3.5_lego_graph.json
  Read FCFS: vfs/phase_outputs/phase_2_corpus_intelligence.json

  ## E-PHRASES (5 Eternal Practice Phrases per LEGO)

  ## E-PHRASE CRITICAL REQUIREMENTS (NON-NEGOTIABLE)

  ### Length Requirements (ABSOLUTE)
  - **MINIMUM**: 7 words in target language
  - **IDEAL**: 10 words in target language
  - **MAXIMUM**: 15 words (hard cap)
  - Short e-phrases (< 7 words) are a CRITICAL FAILURE
  - Better to have NO e-phrase than a short/clunky one

  ### Quality Requirements (ABSOLUTE)
  - QUALITY > QUANTITY: Do not force bad phrases to hit a count
  - E-phrases must be NATURAL and conversational in BOTH languages
  - If vocabulary is insufficient for quality 10-word phrase, skip it
  - Aim for 3-5 excellent e-phrases per basket (not forced to 5)

  ### Target Language Grammar (UNFORGIVEABLE ERRORS)
  ⚠️ **POOR SYNTAX IN TARGET LANGUAGE IS UNFORGIVEABLE** ⚠️

  For Italian specifically:
  - "cercare" + infinitive REQUIRES "di": "cercando di parlare" NOT "cercando parlare"
  - "imparare" + infinitive REQUIRES "a": "imparando a parlare" NOT "imparando parlare"
  - "provare" + infinitive REQUIRES "a": "provando a dire" NOT "provando dire"
  - "continuare" + infinitive REQUIRES "a": "continuando a parlare" NOT "continuando parlare"
  - "finire" + infinitive REQUIRES "di": "finendo di parlare" NOT "finendo parlare"

  **VALIDATE EVERY E-PHRASE**:
  - Is the target language grammar PERFECT?
  - Would a native speaker say this naturally?
  - Are all required prepositions present?

  If you cannot ensure perfect target language grammar, DO NOT include the phrase.

  ---

  Create 5 phrases, each 7-10 words (balanced across 7/8/9/10):
  - **MUST contain the target LEGO**
  - **Perfect grammar** in BOTH languages - validate target AND known language
  - **Natural, conversational** - things people actually say in BOTH languages
  - **Smooth pronunciation** - not clunky or awkward in either language
  - **Variety in position** - LEGO at different positions in phrase
  - **BILINGUAL VALIDATION**: Each phrase must be:
    - Grammatically correct in target language
    - Grammatically correct in known language
    - Semantically meaningful in BOTH languages
    - Natural and idiomatic in BOTH cultures

  ### CRITICAL RULE - CULMINATING LEGOs (ABSOLUTE REQUIREMENT)

  **Definition**: A "culminating LEGO" is the LAST LEGO in a seed's decomposition

  **How to identify**:
  - Check the LEGO's seed_id (e.g., S0005L02)
  - Look up the seed in Phase 3 LEGO breakdown
  - If this is the highest L-number for that seed → it's culminating

  **ABSOLUTE RULE**:
  - **E-phrase #1 MUST be the COMPLETE SEED sentence itself**
  - Not a variation, not similar - the EXACT seed sentence
  - This complete seed MUST also appear 3+ times in D-phrases

  **Example**:
  - Seed S0005: "Sto per esercitarmi a parlare"
  - LEGOs: S0005L01 (sto per) + S0005L02 (esercitarmi a parlare)
  - S0005L02 is culminating (last LEGO)
  - Therefore: S0005L02 basket MUST have E-phrase #1 = "Sto per esercitarmi a parlare"

  **Validation**:
  - Before finalizing basket, check if LEGO is culminating
  - If yes, verify E-phrase #1 is complete seed
  - If not, regenerate basket

  ## VOCABULARY SELECTION (Recency Guidelines - for LEGOs 50+)
  **For early LEGOs (1-50):** Use whatever vocabulary is available - there's not enough yet for recency preferences.

  **For later LEGOs (50+):** When building E-phrases, PREFER recent vocabulary:
  - ~50% of vocabulary from recent seeds (N-5 to N-1)
  - ~25% from medium-recent (N-20 to N-1)
  - ~25% from all earlier seeds

  BUT ALWAYS PRIORITIZE natural, useful phrases over strict percentages.

  ## D-PHRASES (Auto-Generated Debuts)

  ### D-PHRASE QUALITY ALLOWANCE

  **Important**: D-phrases CAN be somewhat clunky or fragment-like
  - They are expanding windows from e-phrases (2-lego, 3-lego, 4-lego, 5-lego)
  - Syntactic correctness required, but naturalness is less critical
  - Focus: Help learners build up to full e-phrases gradually

  **Contrast with E-phrases**:
  - E-phrases: MUST be natural, conversational, perfect grammar
  - D-phrases: Can be awkward fragments as long as syntax is correct

  ---

  You will generate D-phrases using expanding window from E-phrases:
  - 2x 2-LEGO phrases
  - 2x 3-LEGO phrases
  - 2x 4-LEGO phrases
  - 2x 5-LEGO phrases
  ALL 5 E-phrases must contribute to D-phrases (variety is key).

  **CRITICAL RULE: OPERATIVE LEGO MUST BE PRESENT**
  - EVERY d-phrase MUST contain the operative LEGO (the LEGO this basket teaches)
  - Example: If basket is for "Quiero" (S0001L01), ALL d-phrases must contain "Quiero"
  - You CANNOT extract arbitrary contiguous windows - only windows containing the operative LEGO

  **CORRECT EXTRACTION (Basket for "Quiero"):**
    E-phrase: "Quiero hablar español contigo ahora"
    - 2-LEGO: "Quiero hablar" ✅ (contains "Quiero")
    - 3-LEGO: "Quiero hablar español" ✅ (contains "Quiero")
    - 4-LEGO: "Quiero hablar español contigo" ✅ (contains "Quiero")

  **INCORRECT EXTRACTION (Basket for "Quiero"):**
    - 2-LEGO: "hablar español" ❌ (missing "Quiero")
    - 3-LEGO: "español contigo ahora" ❌ (missing "Quiero")

  **BILINGUAL SYNTAX RULES FOR D-PHRASES:**
  - D-phrases can be fragments (don't need to be complete sentences)
  - BUT they MUST be syntactically correct as far as they go in BOTH languages
  - Examples:
    - ✅ "quiero hablar" / "I want to speak" (fragment but correct in both)
    - ✅ "español contigo" / "Spanish with you" (fragment but correct in both)
    - ❌ "quiero de" / "I want of" (syntactically broken in both)
    - ❌ "hablar yo" / "speak I" (wrong word order in both)
  - Always validate BOTH the target AND known language versions

  **For CULMINATING LEGOs:** Use the complete seed (E1) in at least:
  - 1x in 2-LEGO phrases
  - 1x in 3-LEGO phrases
  - 1x in 4 or 5-LEGO phrases
  This reinforces the complete seed understanding!

  ## VALIDATION REQUIREMENTS
  1. For EACH LEGO's basket:
     - If NO valid phrases can be made: Output {"e_phrases": [], "d_phrases": {}}
     - If only 1-2 phrases possible: Use what's available, don't force 5 phrases
     - EVERY word MUST come from the available vocabulary list

  2. NEVER use:
     - Words from LEGOs that haven't been learned yet
     - Words not in a LEGO (no "y", "de", "el" unless they're in a LEGO)
     - Made-up words to fill space

  3. Expected pattern for early LEGOs:
     - LEGO #1: NO PHRASES POSSIBLE (empty basket)
     - LEGO #2: Maybe 1 meaningful combination if semantically valid
     - LEGO #3: 1-3 phrases depending on semantic validity
     - Only after ~10-15 LEGOs will you have enough vocabulary for D-phrases
     - Only after ~50-100 LEGOs will you have enough vocabulary for full E-phrase baskets

  4. SEMANTIC VALIDITY RULES:
     - All phrases must be grammatically AND semantically correct in BOTH languages
     - Consider actual language usage and meaning
     - Validate each combination for real-world meaningfulness

  ## Output Format
  Save to: vfs/courses/{course_code}/baskets.json

  {
    "S0001L01": {
      "lego": ["Quiero", "I want"],
      "e": [
        ["Quiero hablar español.", "I want to speak Spanish."],
        ["Quiero practicar contigo ahora.", "I want to practice with you now."],
        ["No quiero adivinar.", "I don't want to guess."],
        ["Quiero recordar esto.", "I want to remember this."],
        ["Quiero intentar hablar más.", "I want to try to speak more."]
      ],
      "d": {
        "2": [["Quiero hablar", "I want to speak"], ["hablar español", "to speak Spanish"]],
        "3": [["Quiero hablar español", "I want to speak Spanish"], ["No quiero hablar", "I don't want to speak"]],
        "4": [["No quiero hablar ahora", "I don't want to speak now"], ...],
        "5": [["Quiero hablar español contigo ahora", "I want to speak Spanish with you now"], ...]
      }
    },
    "S0001L02": { ... }
  }

  Format: { "lego_id": { lego: [target, known], e: [[t,k]...], d: {window_size: [[t,k]...]} } }

  Notes:
  - LEGO field contains the core teaching unit itself
  - "e" array contains e-phrases (7-10 words, natural conversational phrases)
  - "d" object contains d-phrases organized by window size ("2", "3", "4", "5")
  - Window size refers to number of LEGOs combined in the phrase
  - All phrases are [target, known] pairs

  ## Success Criteria

  **Stage 1 (Selection):**
  ✓ All LEGOs assigned to baskets
  ✓ Maximum edge coverage per basket (diverse patterns)
  ✓ FCFS/chronological ordering maintained
  ✓ Smooth difficulty progression

  **Stage 2 (Generation):**
  ✓ Every LEGO has d-phrases and e-phrases (even if empty for early LEGOs)
  ✓ All vocabulary constraints respected
  ✓ E-phrases are natural and conversational in BOTH languages
  ✓ D-phrases are syntactically correct in BOTH languages
  ✓ Culminating LEGOs include complete seed as E-phrase #1
  ✓ Progressive difficulty from LEGO #1 to last LEGO

  **Combined Result:**
  ✓ Corpus patterns reflected through edge coverage
  ✓ Pedagogical soundness through vocabulary constraints
  ✓ Optimal learning sequence with rich practice

## Phase 5.5: Basket Deduplication

NAME: "Basket Deduplication"
PURPOSE: Remove duplicate LEGO baskets, keeping first occurrence with full provenance
INPUT: vfs/courses/{course_code}/baskets.json (ALL LEGO_PAIR baskets)
OUTPUT: vfs/courses/{course_code}/baskets_deduplicated.json

WHY_THIS_APPROACH:
  - Phase 5 creates baskets for ALL LEGO_PAIRS (e.g., 150 baskets)
  - Many LEGOs appear in multiple seeds (e.g., "parlare" in S0001, S0003, S0005)
  - Each basket created with full SEED_PAIR context (culminating LEGO rule works naturally)
  - Deduplication is simple: DELETE duplicate baskets, KEEP first occurrence

DEDUPLICATION_PROCESS:

  1. **Identify Duplicates**:
     - Group baskets by LEGO text (target + known)
     - Example: "parlare"/"to speak" appears as S0001L02, S0003L02, S0005L04

  2. **Determine First Occurrence**:
     - Sort by FCFS order (from Phase 2)
     - First occurrence = lowest seed number
     - Example: S0001L02 comes before S0003L02 and S0005L04

  3. **Delete Duplicates**:
     - KEEP: S0001L02 basket (first occurrence)
     - DELETE: S0003L02 basket (duplicate)
     - DELETE: S0005L04 basket (duplicate)

  4. **Track Provenance**:
     - Create mapping: {"S0003L02": "→ S0001L02", "S0005L04": "→ S0001L02"}
     - This enables seed reconstruction (S0005 needs "parlare" → use L0002)
     - Store in: vfs/courses/{course_code}/lego_provenance_map.json

CRITICAL_RULES:
  - NEVER merge basket phrases (just delete entire duplicate baskets)
  - ALWAYS keep first occurrence (FCFS principle)
  - ALWAYS track provenance mapping (for seed reconstruction)
  - Basket IDs stay as-is (S0001L02 remains S0001L02, not renumbered to L0002)

OUTPUT_STRUCTURE:

  baskets_deduplicated.json:
  {
    "S0001L01": { basket for "Voglio" },
    "S0001L02": { basket for "parlare" },    ← Kept (first occurrence)
    "S0001L03": { basket for "italiano" },
    // S0003L02 deleted (duplicate of S0001L02)
    "S0003L01": { basket for "come" },
    "S0003L03": { basket for "il più" },
    ...
  }

  lego_provenance_map.json:
  {
    "S0003L02": "S0001L02",
    "S0005L04": "S0001L02",
    ...
  }

EXAMPLE:

  Before deduplication (150 baskets):
  - S0001L02: "parlare"
  - S0003L02: "parlare" (duplicate)
  - S0005L04: "parlare" (duplicate)

  After deduplication (~80 baskets):
  - S0001L02: "parlare" (kept)
  - Mapping: {"S0003L02": "S0001L02", "S0005L04": "S0001L02"}

SUCCESS_CRITERIA:
  ✓ All duplicate baskets identified
  ✓ Only first occurrence baskets kept
  ✓ Provenance mapping complete
  ✓ Reduction from ~150 to ~80 baskets (typical)
  ✓ Ready for Phase 6 (introductions)

## Phase 6: Introductions

NAME: "Introductions"
PURPOSE: Generate known-only priming phrases
INPUT:
  - vfs/amino_acids/baskets/*.json
  - vfs/amino_acids/legos_deduplicated/*.json
OUTPUT: vfs/amino_acids/introductions/{uuid}.json

ABSOLUTE_RULE: Zero unknown elements allowed in introductions

KNOWN_ONLY_PRINCIPLE:
  - For each basket, identify ALL LEGOs from PREVIOUS baskets
  - These form the "known set"
  - Introduction phrases use ONLY known LEGOs
  - NO new vocabulary or structures
  - Goal: Activate prior knowledge, build confidence

WHY_CRITICAL:
  - Reduces cognitive load before new learning
  - Builds learner confidence (100% comprehension)
  - Primes brain for new content
  - Creates smooth entry point to each basket

VALIDATION:
  - Double-check: NO new LEGOs in introductions
  - Every word/phrase must be from known set
  - Absolute rule - no exceptions

INTRODUCTION_STRUCTURE:
  uuid: deterministic based on content + basket reference
  basket_uuid: which basket this introduction precedes
  phrases: ["phrase1", "phrase2", ...] (using only known LEGOs)
  known_legos_used: ["uuid1", "uuid2", ...] (which known LEGOs were used)
  validation:
    all_known: true
    unknown_count: 0 (MUST be zero)

PROMPT: |
  # Phase 6: Introductions

  ## Task
  Generate known-only introduction phrases for each basket to prime learners with zero unknowns.

  ## Input
  - Basket amino acids: vfs/amino_acids/baskets/*.json
  - Deduplicated LEGOs: vfs/amino_acids/legos_deduplicated/*.json

  ## Your Mission
  For each basket:
  1. **Identify Known LEGOs**:
     - Scan ALL previous baskets (baskets 1 to N-1)
     - Compile complete inventory of LEGOs learner has mastered
     - These are the ONLY LEGOs you can use

  2. **Generate Introduction Phrases**:
     - Create warm-up phrases using ONLY known LEGOs
     - ZERO unknown vocabulary or structures
     - Goal: Activate prior knowledge, build confidence
     - Prepare learner for new basket content

  3. **Validate Known-Only Rule**:
     - Double-check: NO new LEGOs in introductions
     - Every word/phrase must be from known set
     - Absolute rule - no exceptions

  4. **Create Introduction Amino Acids**:
     - Deterministic UUID based on content + basket reference
     - Store: vfs/amino_acids/introductions/{uuid}.json

  ## Introduction Amino Acid Structure
  {
    "uuid": "...",
    "basket_uuid": "...",
    "phrases": ["phrase1", "phrase2", ...],
    "known_legos_used": ["uuid1", "uuid2", ...],
    "validation": {
      "all_known": true,
      "unknown_count": 0
    }
  }

  ## Why This Matters
  - Reduces cognitive load before new learning
  - Builds learner confidence (100% comprehension)
  - Primes brain for new content
  - Creates smooth entry point to each basket

  ## CRITICAL RULE
  **ZERO unknown elements allowed in introductions.**
  If you're unsure, DON'T use it.

  ## Success Criteria
  ✓ Introduction generated for each basket
  ✓ All LEGOs verified as "known" from previous baskets
  ✓ Zero unknown elements (validated)
  ✓ Introduction amino acids stored
  ✓ Course ready for final compilation

# =============================================================================
# QUALITY VALIDATION & SELF-ASSESSMENT (v7.4)
# =============================================================================

## Overview: The Recursive Improvement Loop

The system implements a continuous quality improvement loop inspired by Self-Adapting Language Models (SEAL), combining automated Claude self-assessment with human oversight to achieve iterative convergence on high-quality output.

## The Complete Learning Cycle

```
ITERATION 1:
  Generate Course → Claude Self-Assessment → 85% quality → Flags issues
       ↓
  Human Review → Identifies prompt gaps → Updates APML → Learns patterns
       ↓
  Regenerate Course

ITERATION 2:
  Generate Course → Claude Self-Assessment → 92% quality → Minor issues
       ↓
  Quick human check → One prompt tweak → Pattern reinforced
       ↓
  Regenerate Course

ITERATION 3:
  Generate Course → Claude Self-Assessment → 97% quality → Meets threshold
       ↓
  ✅ Done! → Learned patterns committed → Next course starts better
```

## Dual Quality Signal (Better than Pure RL)

Unlike pure reinforcement learning approaches (e.g., SEAL), we use TWO quality signals:

1. **Claude's Self-Assessment**: Automated syntax, FD, and semantic validation
2. **Human Expert Review**: Pedagogical judgment and edge case identification

This hybrid approach provides:
- Higher signal quality (human expertise)
- Faster iteration (automated pre-filtering)
- No catastrophic forgetting (prompt-based accumulation)
- Explainable decisions (traceable to rules)

## Phase 3.9: Automated Quality Validation

TRIGGERED: Automatically after Phase 3 (LEGO Decomposition)
PURPOSE: Validate APML compliance before human review
IMPLEMENTATION: vfs/courses/validate-lego-breakdowns.cjs
OUTPUT: Terminal report + optional JSON log

VALIDATION_SCRIPT_USAGE:

```bash
# Validate single course
cd vfs/courses
node validate-lego-breakdowns.cjs spa_for_eng_30seeds

# Validate all courses
node validate-lego-breakdowns.cjs --all
```

AUTOMATED_CHECKS:

1. **FD_LOOP Compliance** (CRITICAL)
   - Tests: target → known → target must be IDENTICAL
   - Detects: Subjunctive/conditional forms without context
   - Example violation: "pueda" / "I can" (ambiguous)
   - Correct: "en cuanto pueda" / "as soon as I can"
   - Auto-detects: Spanish/Italian/French subjunctive patterns

2. **IRON RULE Enforcement** (CRITICAL)
   - No standalone prepositions without objects
   - Detects: "con" / "with", "de" / "of", "à" / "to"
   - Correct: "con te" / "with you" (complete prepositional phrase)
   - Checks: Both target and known chunks

3. **CHUNK UP Principle** (HIGH)
   - Context-dependent forms must include disambiguating context
   - Detects: Gender-ambiguous words without nouns
   - Example: "su" → should be "su nombre" for FD clarity
   - Language-aware: Checks Spanish/Italian/French/German patterns

4. **Translation Synchronization** (CRITICAL)
   - LEGO breakdown matches translations.json exactly
   - Detects: Mismatches in original_target/original_known
   - Ensures: Regenerated LEGOs use updated Phase 1 translations

5. **Structure Validation** (HIGH)
   - All required fields present (lego_id, lego_type, chunks, fd_validated)
   - No empty chunks
   - Valid lego_type values (BASE or COMPOSITE)

6. **COMPOSITE Validation** (MEDIUM)
   - COMPOSITEs have componentization explanations
   - COMPOSITE components listed in feeder_pairs (recommended)
   - Pedagogically useful decomposition

SEVERITY_LEVELS:

CRITICAL (Must Fix):
  - IRON_RULE_VIOLATION: Standalone prepositions
  - FD_VALIDATION_FAILED: fd_validated: false in output
  - TRANSLATION_MISMATCH: Doesn't match translations.json
  - EMPTY_CHUNK: Empty target_chunk or known_chunk

HIGH (Should Fix):
  - FD_CONTEXT_MISSING: Subjunctive without temporal clause
  - TRANSLATION_MISSING: Seed not found in translations.json
  - MISSING_FIELD: Required field absent

MEDIUM (Fix If Time):
  - FD_GENDER_AMBIGUOUS: Gender word without noun (reduces clarity)
  - MISSING_COMPONENTIZATION: COMPOSITE lacks explanation

LOW (Optional):
  - MISSING_FEEDERS: COMPOSITE has no feeder_pairs (may be intentional)

VALIDATION_OUTPUT_EXAMPLE:
```
══════════════════════════════════════════════════════════════
LEGO BREAKDOWNS VALIDATION REPORT
Course: spa_for_eng_30seeds
══════════════════════════════════════════════════════════════

SUMMARY
  Total Issues: 2
  CRITICAL: 0
  HIGH: 0
  MEDIUM: 0
  LOW: 2

ℹ️  MEDIUM/LOW PRIORITY ISSUES
  0 medium priority, 2 low priority
  Run with --verbose to see all issues

══════════════════════════════════════════════════════════════
✅ VALIDATION PASSED - No critical or high-priority issues
══════════════════════════════════════════════════════════════
```

ITERATION_STRATEGY:

When Validation Fails:
  1. CRITICAL/HIGH issues → MUST regenerate or manually fix
  2. MEDIUM issues → Fix if time permits
  3. LOW issues → Accept (agent non-determinism may not improve)

Regeneration Decision Matrix:
  - >10% seeds with CRITICAL → Full regeneration with improved prompt
  - Systematic pattern (e.g., all subjunctives fail) → Update prompt, regenerate
  - 1-2 isolated CRITICAL → Manual fix faster
  - Only LOW/MEDIUM → Ship it (next generation may be worse)

Multi-Pass Strategy (for non-deterministic agents):
  1. Generate version A
  2. Validate → Record scores
  3. Generate version B
  4. Validate → Record scores
  5. Compare: Pick version with fewer CRITICAL/HIGH issues
  6. If tied, pick version with higher MEDIUM/LOW tolerance

AUTOMATED_ORCHESTRATION:

Script: vfs/courses/process-phase-3-with-validation.cjs

Usage:
```bash
# Single course with automatic retries
node process-phase-3-with-validation.cjs spa_for_eng_30seeds

# Specify max retry attempts
node process-phase-3-with-validation.cjs spa_for_eng_30seeds --max-attempts=5

# Process all courses
node process-phase-3-with-validation.cjs --all
```

Features:
  - Automatic validation after generation
  - Multi-attempt strategy with backups
  - Comparative scoring across attempts
  - Recommendation of best attempt
  - Batch processing support

Workflow:
  1. Generate LEGO decompositions (Phase 3)
  2. Backup existing if regenerating
  3. Run validation (Phase 3.9)
  4. If PASS → Done
  5. If FAIL with CRITICAL/HIGH → Retry (up to max-attempts)
  6. Compare all attempts → Recommend best
  7. User selects final version

INTEGRATION_WITH_PHASE_3_PROMPT:

When generating LEGOs, the agent should be aware that validation will run.
Include in Phase 3 agent prompt:

"Your output will be automatically validated for:
- FD_LOOP compliance (CRITICAL)
- IRON RULE enforcement (CRITICAL)
- Translation synchronization (CRITICAL)
- CHUNK UP principle (HIGH)
- Structure completeness (HIGH)

Focus especially on:
1. Subjunctive forms → Must include temporal context
2. Standalone prepositions → Must include objects
3. Gender-ambiguous words → Must include nouns
4. fd_validated field → Must be true for all LEGOs

Validation severity levels will be reported. Aim for ZERO CRITICAL/HIGH issues."

## Automatic Self-Learning from Manual Edits

WHEN: User manually corrects LEGO breakdown in dashboard
TRIGGERED: PUT /api/courses/:code/seeds/:seedId/lego-breakdown

PROCESS:
1. **Pattern Extraction**: learnFromManualEdit() analyzes differences
2. **Rule Creation**: Pattern becomes "experimental" rule (confidence: 50%)
3. **Auto-Promotion**:
   - 5+ occurrences → "validated" (confidence: 80%)
   - 10+ occurrences → "committed" (confidence: 95%)
4. **Prompt Injection**: commitRuleToPrompt() updates Phase 3 DNA
5. **Next Generation**: New courses automatically use evolved prompts

STORAGE: vfs/courses/{courseCode}/learned_rules.json

STRUCTURE:
```json
{
  "rules": [
    {
      "type": "merge" | "split" | "boundary_shift",
      "description": "Consider larger LEGO chunks for verb + prep + inf",
      "occurrences": 12,
      "confidence": 0.95,
      "status": "committed",
      "first_seen": "2025-10-14T10:23:00Z",
      "last_seen": "2025-10-14T15:42:00Z",
      "effectiveness": {
        "courses_applied": ["ita_for_eng_574seeds", "spa_for_eng_668seeds"],
        "quality_impact": +0.08,
        "success_rate": 0.91
      }
    }
  ],
  "manual_edits": [
    {
      "seed_id": "S0042",
      "timestamp": "2025-10-14T15:42:00Z",
      "original_count": 3,
      "edited_count": 2,
      "patterns": [
        {
          "type": "merge",
          "description": "Human merged 3 LEGOs into 2",
          "learned_rule": "Consider larger LEGO chunks for this pattern"
        }
      ]
    }
  ]
}
```

PATTERN_TYPES:

MERGE: Human combines multiple AI-generated LEGOs into one
  - Learns: "Consider larger LEGO chunks for this pattern"
  - Example: ["voy", "a", "decir"] → ["voy a decir"]

SPLIT: Human breaks one AI-generated LEGO into multiple
  - Learns: "Consider smaller LEGO chunks for this pattern"
  - Example: ["quiero hablar español"] → ["quiero", "hablar español"]

BOUNDARY_SHIFT: Human adjusts LEGO boundaries
  - Learns: "Adjust chunk boundaries at this linguistic marker"
  - Example: ["estoy feliz"] → ["estoy", "feliz"] (temporary vs state)

## API Endpoints for Quality Loop

GET /api/courses/:code/quality-assessment
  - Retrieve Claude's self-assessment report
  - Returns quality_assessment.json with all metrics
  - Used by dashboard to show quality scores

GET /api/courses/:code/learned-rules
  - View all learned rules (experimental/validated/committed)
  - Returns learned_rules.json with effectiveness data
  - Powers LearnedRulesView.vue dashboard

POST /api/courses/:code/regenerate
  - Trigger regeneration after prompt improvements
  - Parameters: { phases: [3, 5], reason: "Fix FD compliance issues" }
  - Creates new quality assessment cycle

## Dashboard Components

QualityDashboard.vue:
  - Display overall quality scores
  - Show Claude's self-assessment metrics
  - Highlight issues flagged for human review
  - Track improvement across iterations

LearnedRulesView.vue:
  - Summary stats (experimental/validated/committed counts)
  - Rule lifecycle visualization
  - Recent manual edits display
  - Rule effectiveness tracking

PromptEvolutionView.vue:
  - Version history of prompt changes
  - Correlation with quality improvements
  - A/B comparison of different prompt versions

## Key Advantage Over Pure RL (e.g., SEAL)

SEAL Paper Problem: Catastrophic forgetting - new updates overwrite previous learning

OUR SOLUTION: Prompt-based accumulation with no forgetting
  ✅ Rules are additive (append, don't overwrite)
  ✅ Each rule is versioned and traceable
  ✅ Can selectively disable rules without data loss
  ✅ Human oversight prevents harmful updates
  ✅ Explainable: Every rule traces to specific manual edits

## The Meta-Insight

Every manual correction makes the system smarter. After 10 similar corrections, the pattern is automatically committed to prompt DNA and applied to all future courses.

**This is true recursive self-improvement: the system learns how to learn better.**

Unlike weight-based approaches, our prompt-based learning:
- Accumulates without forgetting
- Is human-auditable (can read the rules)
- Can be selectively controlled (enable/disable rules)
- Generalizes across language pairs (rules transfer)

IMPLEMENTATION:
  - learnFromManualEdit() [automation_server.cjs:2010-2127]
  - commitRuleToPrompt() [automation_server.cjs:2133-2170]
  - Quality assessment integration [planned]

# =============================================================================
# DASHBOARD INTERFACE SPECIFICATIONS
# =============================================================================

## Interface Section 1: Course Generation Pipeline

COMPONENTS:
  - CourseGeneration.vue (main generation interface)
  - ProcessOverview.vue (phase progress visualization)
  - TrainingPhase.vue (phase documentation and prompt display)

CRITICAL_FEATURE: TrainingPhase.vue displays ACTUAL prompts from registry
  - Fetches from: GET /api/registry/phase-prompts/:phase
  - Shows working reality (not generic docs)
  - Editable textarea allows prompt updates
  - Updates POST to: PUT /api/registry/phase-prompts/:phase
  - Creates version history for every change

DATA_FLOW:
  User selects languages + seed count
    ↓
  POST /api/courses/generate
    ↓
  automation_server.cjs creates job
    ↓
  cascadePhases() reads PHASE_PROMPTS from registry
    ↓
  spawnPhaseAgent() via osascript
    ↓
  Claude Code receives actual working prompts
    ↓
  Outputs saved to VFS
    ↓
  Dashboard polls: GET /api/courses/:code/status
    ↓
  Displays results in real-time

## Interface Section 2: Quality Review & Self-Healing

COMPONENTS:
  - QualityDashboard.vue (overview and metrics)
  - SeedQualityReview.vue (individual seed review)
  - PromptEvolutionView.vue (prompt version history)

PURPOSE:
  - Visual review of all phase outputs
  - Flag problematic seeds for regeneration
  - Track prompt evolution over time
  - Self-healing: automatic rerun of failed extractions

## Interface Section 3: Visualization & Editing

COMPONENTS:
  - LegoVisualizer.vue (visual LEGO breakdown display)
  - SeedVisualizer.vue (seed pair visualization)
  - PhraseVisualizer.vue (phrase pattern visualization)
  - CourseEditor.vue (edit translations and LEGOs)

EDIT_WORKFLOW:
  User edits translation in UI
    ↓
  PUT /api/courses/:code/translations/:uuid
    ↓
  Triggers regeneration of affected phases
    ↓
  Phase 3+ re-run with updated translation
    ↓
  Dashboard shows updated results

## Interface Section 4: APML Specification & Docs

COMPONENTS:
  - APMLSpec.vue (displays this specification)
  - Dashboard.vue (main navigation)
  - PROJECT-DASHBOARD.html (auto-generated from APML)

SELF_DOCUMENTATION:
  - This APML file is the single source of truth
  - Dashboard components fetch from this specification
  - Changes to APML regenerate documentation
  - No drift between docs and reality

# =============================================================================
# COMPILATION & DEPLOYMENT
# =============================================================================

## Compilation Process

1. **Parse APML Specification**
   - Read ssi-course-production.apml
   - Extract Variable Registry
   - Extract Phase Prompts
   - Extract Interface Specs

2. **Generate .apml-registry.json**
   - Machine-readable format for runtime access
   - Contains all PHASE_PROMPTS
   - Contains all API endpoints
   - Contains all configuration

3. **Update automation_server.cjs**
   - Replace hardcoded PHASE_PROMPTS with registry import
   - const apmlRegistry = require('./.apml-registry.json');
   - const PHASE_PROMPTS = apmlRegistry.variable_registry.PHASE_PROMPTS;

4. **Update TrainingPhase.vue**
   - Fetch prompts from: GET /api/registry/phase-prompts/:phase
   - Display in editable textarea
   - Enable prompt updates via API

5. **Generate PROJECT-DASHBOARD.html**
   - Auto-generated navigation interface
   - Links to all interface sections
   - Shows current system status

## Deployment

VERCEL_DEPLOYMENT:
  - Dashboard deployed to Vercel (frontend)
  - Includes .apml-registry.json (latest prompts)
  - Includes auto-generated documentation
  - User can access from anywhere

LOCAL_AUTOMATION:
  - automation_server.cjs runs on SSi Mac (port 3456)
  - ngrok tunnel exposes to internet
  - Dashboard connects via tunnel
  - Claude Code executes locally with full intelligence

# =============================================================================
# VERSION HISTORY
# =============================================================================

VERSION: 7.6.0
DATE: 2025-10-15
CHANGES:
  - 🎯 CRITICAL: Added COGNATE PREFERENCE heuristic for seeds 1-100
  - 🎯 CRITICAL: Added VARIATION REDUCTION principle (vocabulary claiming)
  - 🎯 CRITICAL: Added Phase 3.9 automated quality validation system
  - 🔧 NEW: validate-lego-breakdowns.cjs (automated APML compliance checking)
  - 🔧 NEW: process-phase-3-with-validation.cjs (orchestration with auto-retry)
  - Established Progressive Optimization Curve (seeds 1-100, 101-300, 301-668)
  - Heuristic priority now changes based on seed position
  - Seeds 1-100: Cognate-heavy + variation reduction (max learner confidence)
  - Seeds 101-300: Introduce natural alternatives gradually
  - Seeds 301-668: Full idiomatic/colloquial expressions
  - Updated Phase 1 spec (lines 369-477) with detailed examples
  - Updated Phase 1 prompt (lines 559-695) with VOCABULARY REGISTRY process
  - Updated Phase 3.9 spec (lines 2436-2605) with validation workflow
  - Added "First Word Wins" rule for early seeds
  - Cognate examples across Spanish/French/Italian/Mandarin
  - EXCEPTION handling for grammatically required variation (ser/estar, savoir/connaître)
  - Automated checks: FD_LOOP, IRON RULE, CHUNK UP, Translation Sync, Structure
  - Severity levels: CRITICAL/HIGH/MEDIUM/LOW with iteration strategies
  - Multi-attempt comparison strategy for non-deterministic agent generation
  - Based on analysis of overnight generation showing excessive variation in seeds 1-30
  - Principle: Get learners into conversation FASTER by reducing cognitive load early
  - Validation ensures quality before human review, supports iterative refinement

VERSION: 7.5.0
DATE: 2025-10-15
CHANGES:
  - 🌍 MAJOR: Complete language-agnostic transformation of Phase 3
  - Fixed IRON RULE contradiction: prepositional phrases WITH objects now explicitly ALLOWED
  - Replaced Spanish-only examples with universal principles + diverse language families
  - Added comprehensive FD_LOOP GENDER AND CONTEXT NEUTRALITY section
  - Introduced THE CHUNK UP PRINCIPLE as universal FD rescue strategy
  - Integrated all 10 Phase 3 refinements from Italian 30-seed validation:
    1. IRON RULE clarification (prepositional phrases OK)
    2. Infinitive "to" placement rule
    3. Minimal FD chunks principle
    4. Glue words must stay inside composites
    5. Selective FEEDERS (not exhaustive)
    6. "represents" vs "means" language precision
    7. Function word handling (avoid standalone)
    8. FD violations (gender/context ambiguity)
    9. Building composites hierarchically
    10. CHUNK UP principle (not "context-dependent" labels)
  - Updated FCFS examples to cover 6+ language families (Romance, Germanic, Celtic, Sino-Tibetan, Japonic, Slavic)
  - Added grammatical constraint examples for diverse languages (Spanish, German, Japanese, Mandarin, French)
  - Eliminated language bias: 97 Spanish/Italian-specific references replaced with ${targetLang}/${knownLang} variables
  - Updated both spec (lines 606-731) and prompt (lines 1250-1382) for consistency
  - Based on APML_Phase3_Updates_2025.md + extended language-agnostic analysis

VERSION: 7.4.0
DATE: 2025-10-14
CHANGES:
  - Added "Quality Validation & Self-Assessment" section
  - Documented Phase 3.9: Automated Quality Assessment
  - Formalized Claude self-assessment with quality thresholds
  - Added automatic self-learning from manual edits
  - Documented three-stage rule lifecycle (experimental → validated → committed)
  - Added learned_rules.json structure and pattern types
  - Integrated SEAL paper insights (recursive improvement without forgetting)
  - Added API endpoints for quality loop (quality-assessment, learned-rules, regenerate)
  - Updated dashboard fallback prompts to v7.0 architecture (TrainingPhase.vue)
  - Documented dual quality signal advantage over pure RL approaches
  - Implemented learnFromManualEdit() and commitRuleToPrompt() functions
  - Created LearnedRulesView.vue dashboard component
  - Based on SEAL paper analysis and recursive improvement requirements

VERSION: 7.3.0
DATE: 2025-10-13
CHANGES:
  - Added LEGO type definitions (BASE, COMPOSITE, FEEDERS)
  - Added TILING concept with decision tree
  - Clarified COMPONENTIZATION as pedagogical (not structural)
  - Updated Phase 3 prompt with LEGO architecture extraction logic
  - Examples use "voy a decir" pattern
  - Based on LEGO_ARCHITECTURE_CLARIFICATION_BRIEF.md

VERSION: 7.2.0
DATE: 2025-10-13
CHANGES:
  - Clarified Phase 1 two-step translation architecture (canonical→target→known)
  - Clarified IRON RULE: infinitive "to" is NOT a preposition (explicitly allowed)
  - Updated Phase 5 prompt with CRITICAL e-phrase length requirements (7-10 words)
  - Added UNFORGIVEABLE target language grammar validation
  - Strengthened culminating LEGO rule enforcement
  - Clarified e-phrase quality > quantity (3-5 excellent vs forced 5)
  - Added D-phrase quality allowance explanation
  - Based on 30-seed Italian validation findings (QUALITY_REPORT.md)

VERSION: 7.1.0
DATE: 2025-10-13
CHANGES:
  - Added "Human-AI Collaboration Model" section
  - Documented Claude Code agent's role as thinking partner
  - Defined orchestrator pattern for parallel work execution
  - Explained "The Meta-Game" - self-improving system vision
  - Added session initialization checklist
  - Documented self-upregulating intelligence loop
  - Clarified that dashboard IS the living system (not just UI)

VERSION: 7.0.0
DATE: 2025-10-13
CHANGES:
  - Created complete APML specification
  - Documented all 668 canonical seeds
  - Preserved critical Phase 3 intelligence (250+ lines)
  - Added Phase 3.5 (Graph Construction)
  - Updated all batch calculations
  - Defined Variable Registry as single source of truth
  - Specified dashboard interface components
  - Documented compilation and deployment process

PREVIOUS_VERSION: 6.x (scattered across multiple files)
MIGRATION: v6 → v7 consolidated all intelligence into this APML specification

# =============================================================================
# SUCCESS CRITERIA
# =============================================================================

✅ Complete specification preserves all intelligence
✅ No information loss during code refactors
✅ Dashboard shows actual working prompts (not generic docs)
✅ Edit in UI → updates source → execution and docs stay in sync
✅ Variable Registry eliminates naming inconsistencies
✅ APML standard compliance (PSS, Intent Capture, Variable Registry)
✅ Self-documenting system (specification IS implementation)
✅ Version controlled (Git tracks every change)
✅ Published with dashboard (Vercel has latest)
✅ Claude receives detailed, battle-tested prompts
✅ Generated courses work perfectly in SSi mobile app

# =============================================================================
# END OF SPECIFICATION
# =============================================================================

For implementation: https://apml.dev/toolchain/
For APML standards: /Users/tomcassidy/APML/apml-dev-website/specifications/

This specification is the永久的真理 (permanent truth) of the SSi Course Production System.

