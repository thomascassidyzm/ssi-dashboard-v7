# Storage Strategy: VFS, Git, Local, and AWS S3

**Date**: 2025-11-06
**Context**: Need clear data flow between local development, git, and AWS S3 for course files

---

## Current State Analysis

### 1. **Local VFS** (`vfs/courses/`)

**What it is:**
- Local working directory for course generation
- Gitignored content (`.gitignore` line 38: `vfs/courses/*/`)
- Directory structure tracked, content ignored

**What's in it:**
```
vfs/courses/
â”œâ”€â”€ spa_for_eng/
â”‚   â”œâ”€â”€ seed_pairs.json      (82KB) Phase 1 output
â”‚   â””â”€â”€ lego_pairs.json      (521KB) Phase 3 output
â”œâ”€â”€ ita_for_eng_668seeds/
â”‚   â”œâ”€â”€ seed_pairs.json
â”‚   â””â”€â”€ lego_pairs.json
â””â”€â”€ gle_for_eng_30seeds/     (older format)
    â”œâ”€â”€ baskets.json
    â””â”€â”€ translations.json
```

**Current status:**
- âœ… seed_pairs.json (Phase 1)
- âœ… lego_pairs.json (Phase 3)
- âŒ lego_baskets.json (Phase 5 - NOT YET INTEGRATED)

**Gitignore rule:**
```gitignore
# Line 38
vfs/courses/*/
```
This means:
- âœ… `vfs/courses/` directory is tracked
- âœ… `vfs/courses/ğŸ“_COURSE_INDEX.md` is tracked
- âŒ `vfs/courses/spa_for_eng/*` is ignored
- âŒ All course content files are ignored

---

### 2. **Public VFS** (`public/vfs/courses/`)

**What it is:**
- Static fallback files committed to git
- Used when API server unavailable
- Dashboard reads from here as fallback

**What's in it:**
```
public/vfs/courses/
â”œâ”€â”€ spa_for_eng_30seeds/
â”‚   â”œâ”€â”€ translations.json
â”‚   â”œâ”€â”€ baskets_deduplicated.json
â”‚   â””â”€â”€ LEGO_BREAKDOWNS_COMPLETE.json
â”œâ”€â”€ cmn_for_eng/
â”œâ”€â”€ ita_for_eng_10seeds/
â””â”€â”€ ... (13 courses)
```

**Current status:**
- Older format (Phase 5.5 deduplication format)
- Committed to git (in `public/`)
- Serves as static fallback when API down

---

### 3. **Baskets** (Current scattered locations)

**What it is:**
- Practice phrase baskets (Phase 5 output)
- Currently NOT in VFS structure

**Where they are:**
```
public/baskets/              â† Curated/hand-crafted
â”œâ”€â”€ lego_baskets_s0001.json
â”œâ”€â”€ lego_baskets_s0011.json  (v6 curated)
â”œâ”€â”€ lego_baskets_s0011_v3_backup.json
â””â”€â”€ ... (S0001-S0050)

public/generated_baskets/    â† AI-generated
â”œâ”€â”€ lego_baskets_s0011_conversational.json
â”œâ”€â”€ lego_baskets_s0021_conversational.json
â””â”€â”€ lego_baskets_s0031_conversational.json
```

**Current issues:**
- âŒ Not part of VFS structure
- âŒ No course association
- âŒ Can't sync with course files
- âŒ Committed to git (large binary-ish JSON)

---

### 4. **AWS S3** (Production storage)

**What it is:**
- Cloud storage for published courses
- Dashboard loads from here in production

**What's supposed to be there:**
- Complete courses (all phases)
- Publicly accessible course files

**Current status:**
- 7 courses uploaded (per api.js:81-90)
- No basket integration yet
- Dashboard has S3 fallback logic

---

## The Problem

**Current data flow is unclear:**
```
Local Development â†’ ??? â†’ Git â†’ ??? â†’ S3 â†’ Dashboard
     (vfs/)              (public/)      (cloud)  (browser)

Where do baskets fit? âŒ
```

**Specific issues:**

1. **Baskets are orphaned**
   - Live in `public/baskets/` and `public/generated_baskets/`
   - Not associated with courses
   - Committed to git (shouldn't be - they're large generated files)

2. **VFS is incomplete**
   - Has Phase 1 (seed_pairs.json) âœ…
   - Has Phase 3 (lego_pairs.json) âœ…
   - Missing Phase 5 (lego_baskets.json) âŒ

3. **Git stores generated content**
   - `public/baskets/*.json` committed
   - `public/vfs/courses/*` committed
   - These are 100KB+ generated files

4. **S3 sync unclear**
   - When to upload?
   - What to upload?
   - How to handle incomplete courses?

5. **Local â†’ S3 workflow undefined**
   - Work locally in `vfs/`
   - Want to share incomplete course for review
   - No mechanism to sync partial work

---

## Proposed Storage Strategy

### **Principle: 3-Layer Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 1: Local Development (vfs/)                      â”‚
â”‚ - Gitignored content                                    â”‚
â”‚ - All phases (1, 3, 5, 7, 8)                           â”‚
â”‚ - Working files, iterations, experiments                â”‚
â”‚ - Source of truth during development                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                    (Sync command)
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 2: AWS S3 (Cloud storage)                        â”‚
â”‚ - Published courses (complete OR in-progress)          â”‚
â”‚ - Versioned backups                                     â”‚
â”‚ - Team-accessible for review                            â”‚
â”‚ - Source of truth for production                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                  (Dashboard fetch)
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 3: Browser Cache (localStorage/IndexedDB)        â”‚
â”‚ - Cached course files                                   â”‚
â”‚ - Fast access after first load                          â”‚
â”‚ - Cleared on version mismatch                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GIT: Source Code Only                                   â”‚
â”‚ - Vue components, scripts, docs                         â”‚
â”‚ - NOT course content files                              â”‚
â”‚ - NOT generated baskets                                 â”‚
â”‚ - Static examples only (< 10KB samples)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Detailed Layer Specifications

### **LAYER 1: Local Development (`vfs/courses/{courseCode}/`)**

**Purpose:**
- Working directory for course generation
- All intermediate files
- Experimentation and iteration

**Structure:**
```
vfs/courses/{courseCode}/
â”œâ”€â”€ seed_pairs.json           # Phase 1 output
â”œâ”€â”€ lego_pairs.json           # Phase 3 output
â”œâ”€â”€ lego_baskets.json         # Phase 5 output (NEW!)
â”œâ”€â”€ lego_baskets_metadata.json # Phase 5 metadata (NEW!)
â”œâ”€â”€ compiled/                 # Phase 7 output
â”‚   â”œâ”€â”€ course.xml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ audio/                    # Phase 8 output
â”‚   â””â”€â”€ ...
â”œâ”€â”€ working/                  # Intermediate files
â”‚   â”œâ”€â”€ phase3_attempts/
â”‚   â”œâ”€â”€ basket_drafts/
â”‚   â””â”€â”€ ...
â””â”€â”€ .course_metadata.json     # Version, status, sync info
```

**Gitignore:**
```gitignore
# All course content (keep pattern as-is)
vfs/courses/*/
```

**Sync metadata** (`.course_metadata.json`):
```json
{
  "course_code": "spa_for_eng_30seeds",
  "version": "1.0.0",
  "last_sync": "2025-11-06T12:34:56Z",
  "sync_status": "synced",
  "phases_complete": [1, 3, 5],
  "s3_url": "s3://ssi-courses/spa_for_eng_30seeds/",
  "local_modifications": false
}
```

**When to use:**
- âœ… All development work
- âœ… Phase execution (1, 3, 5, 7, 8)
- âœ… Basket curation
- âœ… Quality validation
- âœ… Experimentation

**When NOT to use:**
- âŒ Production serving (use S3)
- âŒ Team collaboration (sync to S3 first)

---

### **LAYER 2: AWS S3 (`s3://ssi-courses/{courseCode}/`)**

**Purpose:**
- Published courses (complete or in-progress)
- Team-accessible storage
- Source of truth for dashboard
- Versioned backups

**Structure:**
```
s3://ssi-courses/
â”œâ”€â”€ spa_for_eng_30seeds/
â”‚   â”œâ”€â”€ v1.0.0/                    # Versioned backup
â”‚   â”‚   â”œâ”€â”€ seed_pairs.json
â”‚   â”‚   â”œâ”€â”€ lego_pairs.json
â”‚   â”‚   â””â”€â”€ lego_baskets.json
â”‚   â”œâ”€â”€ seed_pairs.json            # Latest version
â”‚   â”œâ”€â”€ lego_pairs.json
â”‚   â”œâ”€â”€ lego_baskets.json
â”‚   â”œâ”€â”€ lego_baskets_metadata.json
â”‚   â”œâ”€â”€ course_metadata.json       # Public metadata
â”‚   â””â”€â”€ compiled/
â”‚       â””â”€â”€ course.xml
â””â”€â”€ ita_for_eng_668seeds/
    â””â”€â”€ ... (same structure)
```

**Public metadata** (`course_metadata.json`):
```json
{
  "course_code": "spa_for_eng_30seeds",
  "version": "1.0.0",
  "source_language": "eng",
  "target_language": "spa",
  "total_seeds": 30,
  "phases_complete": [1, 3, 5],
  "published_at": "2025-11-06T12:34:56Z",
  "status": "in_progress",
  "basket_count": 30,
  "quality_score": 95,
  "download_urls": {
    "seed_pairs": "https://...",
    "lego_pairs": "https://...",
    "lego_baskets": "https://..."
  }
}
```

**Sync policy:**
- âœ… Sync on demand (manual trigger)
- âœ… Sync incomplete courses for review
- âœ… Version on each sync (backup to `v{X.Y.Z}/`)
- âœ… Update `course_metadata.json`

**When to use:**
- âœ… Publishing complete courses
- âœ… Sharing incomplete work for review
- âœ… Team collaboration
- âœ… Dashboard data source

**When NOT to use:**
- âŒ Active development (use local VFS)
- âŒ Rapid iteration (sync is slow)

---

### **LAYER 3: Browser Cache (localStorage/IndexedDB)**

**Purpose:**
- Fast access to recently viewed courses
- Reduce S3 fetch calls
- Offline capability

**Storage:**
```javascript
// localStorage
localStorage.setItem('course_spa_for_eng_30seeds_version', '1.0.0')

// IndexedDB
db.courses.put({
  courseCode: 'spa_for_eng_30seeds',
  version: '1.0.0',
  seedPairs: { ... },   // Full JSON
  legoPairs: { ... },
  legoBaskets: { ... },
  cachedAt: Date.now(),
  expiresAt: Date.now() + 86400000  // 24h
})
```

**Cache policy:**
- âœ… Cache after first fetch
- âœ… Check version before using cache
- âœ… Expire after 24 hours
- âœ… Clear on version mismatch

**When to use:**
- âœ… Dashboard loads
- âœ… Repeated basket viewing
- âœ… Offline browsing

**When NOT to use:**
- âŒ Development (always use local VFS)
- âŒ Editing (always fetch latest)

---

### **GIT: Source Code Only**

**What goes in git:**
```
âœ… Source code (*.vue, *.js, *.cjs)
âœ… Documentation (*.md)
âœ… Configuration (*.json configs, NOT data)
âœ… Small examples (< 10KB samples)
âœ… VFS directory structure (vfs/courses/)
âœ… VFS index (vfs/courses/ğŸ“_COURSE_INDEX.md)
```

**What does NOT go in git:**
```
âŒ Course content (vfs/courses/*/)
âŒ Generated baskets (public/baskets/*.json)
âŒ Large data files (> 10KB)
âŒ S3 uploads
âŒ Compiled outputs
âŒ Audio files
```

**Current exceptions to remove:**
```
âŒ public/vfs/courses/*  (move to S3 only)
âŒ public/baskets/*      (move to VFS â†’ S3)
âŒ public/generated_baskets/*  (move to VFS â†’ S3)
```

---

## Data Flow Workflows

### **Workflow 1: New Course Generation**

```
1. Developer runs: `npm run generate-course spa_for_eng_30seeds`

2. Automation server:
   â”œâ”€ Phase 1 â†’ vfs/courses/spa_for_eng_30seeds/seed_pairs.json
   â”œâ”€ Phase 3 â†’ vfs/courses/spa_for_eng_30seeds/lego_pairs.json
   â”œâ”€ Phase 5 â†’ vfs/courses/spa_for_eng_30seeds/lego_baskets.json
   â””â”€ Creates .course_metadata.json

3. Developer reviews locally:
   â”œâ”€ Opens basket viewer: loads from vfs/
   â”œâ”€ Curates baskets
   â””â”€ Validates quality

4. Developer syncs to S3:
   $ node scripts/sync-course-to-s3.cjs spa_for_eng_30seeds

5. S3 sync script:
   â”œâ”€ Uploads all course files to S3
   â”œâ”€ Creates versioned backup (v1.0.0/)
   â”œâ”€ Updates course_metadata.json
   â””â”€ Updates local .course_metadata.json (last_sync)

6. Team opens dashboard:
   â”œâ”€ Dashboard fetches from S3
   â”œâ”€ Caches in browser
   â””â”€ Can review baskets

7. Team provides feedback:
   â””â”€ Flags baskets for review

8. Developer syncs back (bi-directional):
   $ node scripts/sync-course-from-s3.cjs spa_for_eng_30seeds

9. Developer updates locally:
   â”œâ”€ Regenerates flagged baskets
   â””â”€ Re-syncs to S3
```

---

### **Workflow 2: Basket Curation**

```
1. Developer works locally:
   â”œâ”€ Edit vfs/courses/spa_for_eng_30seeds/lego_baskets.json
   â”œâ”€ Curate S0011 (15 â†’ 10 phrases)
   â””â”€ Validate GATE compliance

2. Developer syncs:
   $ node scripts/sync-course-to-s3.cjs spa_for_eng_30seeds --baskets-only

3. S3 updated:
   â”œâ”€ Uploads lego_baskets.json
   â”œâ”€ Uploads lego_baskets_metadata.json
   â””â”€ Increments version (v1.0.1)

4. Dashboard refreshes:
   â”œâ”€ Detects version change
   â”œâ”€ Clears cache
   â””â”€ Fetches new baskets
```

---

### **Workflow 3: Team Collaboration (Incomplete Course)**

```
1. Developer A generates Phase 1-3:
   â”œâ”€ vfs/courses/spa_for_eng_30seeds/seed_pairs.json âœ…
   â”œâ”€ vfs/courses/spa_for_eng_30seeds/lego_pairs.json âœ…
   â””â”€ lego_baskets.json not started âŒ

2. Developer A syncs partial work:
   $ node scripts/sync-course-to-s3.cjs spa_for_eng_30seeds --force

3. S3 has partial course:
   â”œâ”€ seed_pairs.json âœ…
   â”œâ”€ lego_pairs.json âœ…
   â”œâ”€ lego_baskets.json âŒ
   â””â”€ course_metadata.json (phases_complete: [1, 3])

4. Developer B fetches:
   $ node scripts/sync-course-from-s3.cjs spa_for_eng_30seeds

5. Developer B continues:
   â”œâ”€ Generates Phase 5 baskets
   â””â”€ Syncs back to S3

6. Developer A pulls updates:
   $ node scripts/sync-course-from-s3.cjs spa_for_eng_30seeds --pull
```

---

### **Workflow 4: Dashboard Loads Course**

```
1. User opens dashboard:
   â””â”€ Navigates to "Spanish for English"

2. Dashboard checks cache:
   const cachedVersion = localStorage.getItem('course_spa_for_eng_30seeds_version')

3. Dashboard fetches S3 metadata:
   GET s3://ssi-courses/spa_for_eng_30seeds/course_metadata.json

4. Compare versions:
   if (s3Version !== cachedVersion) {
     clearCache()
     fetchFromS3()
   } else {
     loadFromCache()
   }

5. If cache miss, fetch files:
   â”œâ”€ GET s3://.../seed_pairs.json
   â”œâ”€ GET s3://.../lego_pairs.json
   â””â”€ GET s3://.../lego_baskets.json

6. Cache in browser:
   â”œâ”€ IndexedDB: store full course data
   â””â”€ localStorage: store version
```

---

## Migration Plan

### **Phase 1: Consolidate Baskets into VFS** (Week 1)

**Goal**: Move baskets from `public/baskets/` into `vfs/courses/{courseCode}/lego_baskets.json`

**Steps:**

1. **Create migration script**: `scripts/migrate-baskets-to-vfs.cjs`
   ```javascript
   // For each basket in public/baskets/:
   // - Determine course code (hardcoded map for now)
   // - Load basket JSON
   // - Add to course's lego_baskets.json
   // - Update lego_baskets_metadata.json
   ```

2. **Run migration**:
   ```bash
   node scripts/migrate-baskets-to-vfs.cjs
   ```

3. **Verify**:
   ```bash
   ls vfs/courses/*/lego_baskets.json
   # Should see baskets in each course
   ```

4. **Update basket viewer**:
   - Change from `/baskets/lego_baskets_s0011.json`
   - To `/api/courses/{courseCode}/baskets/{seedId}`
   - API serves from `vfs/courses/{courseCode}/lego_baskets.json`

5. **Test locally**:
   - Dashboard loads baskets from VFS via API
   - No more hardcoded basket paths

6. **Keep backup** (don't delete yet):
   ```bash
   mv public/baskets public/baskets_BACKUP_2025-11-06
   mv public/generated_baskets public/generated_baskets_BACKUP_2025-11-06
   ```

---

### **Phase 2: Create S3 Sync Scripts** (Week 2)

**Goal**: Enable syncing VFS â†’ S3 and S3 â†’ VFS

**Scripts to create:**

1. **`scripts/sync-course-to-s3.cjs`**
   ```bash
   # Upload course to S3
   node scripts/sync-course-to-s3.cjs spa_for_eng_30seeds

   # Upload only baskets
   node scripts/sync-course-to-s3.cjs spa_for_eng_30seeds --baskets-only

   # Force sync incomplete course
   node scripts/sync-course-to-s3.cjs spa_for_eng_30seeds --force
   ```

2. **`scripts/sync-course-from-s3.cjs`**
   ```bash
   # Download course from S3
   node scripts/sync-course-from-s3.cjs spa_for_eng_30seeds

   # Pull updates only (don't overwrite local changes)
   node scripts/sync-course-from-s3.cjs spa_for_eng_30seeds --pull
   ```

3. **`scripts/list-s3-courses.cjs`**
   ```bash
   # List all courses in S3
   node scripts/list-s3-courses.cjs
   ```

**Features:**
- Version management (backup to `v{X.Y.Z}/`)
- Conflict detection (warn if local modified)
- Partial sync (only changed files)
- Progress tracking

---

### **Phase 3: Update Dashboard** (Week 3)

**Goal**: Dashboard loads from S3, not `public/vfs/`

**Changes:**

1. **Remove `public/vfs/courses/` from git**:
   ```bash
   git rm -r public/vfs/courses/
   git commit -m "Remove static VFS files (now served from S3)"
   ```

2. **Update API fallback logic** (`src/services/api.js`):
   ```javascript
   // OLD: Fallback to public/vfs/courses/
   const response = await fetch(`/vfs/courses/${courseCode}/seed_pairs.json`)

   // NEW: Fallback to S3
   const response = await fetch(`https://s3.amazonaws.com/ssi-courses/${courseCode}/seed_pairs.json`)
   ```

3. **Add cache layer**:
   ```javascript
   // Check IndexedDB cache first
   const cached = await db.courses.get(courseCode)
   if (cached && cached.version === latestVersion) {
     return cached.data
   }

   // Fetch from S3
   const data = await fetchFromS3(courseCode)

   // Cache in IndexedDB
   await db.courses.put({ courseCode, version, data, cachedAt: Date.now() })
   ```

4. **Version checking**:
   ```javascript
   // Always fetch course_metadata.json first (small, fast)
   const metadata = await fetch(`${S3_BASE}/${courseCode}/course_metadata.json`)

   // Compare with cached version
   if (metadata.version !== cachedVersion) {
     clearCache(courseCode)
     fetchAllFiles(courseCode)
   }
   ```

---

### **Phase 4: Clean Up Public Directory** (Week 4)

**Goal**: Remove generated files from git

**Steps:**

1. **Update `.gitignore`**:
   ```gitignore
   # Add these lines:
   public/baskets/
   public/generated_baskets/
   public/vfs/courses/
   ```

2. **Remove from git history** (optional, reduces repo size):
   ```bash
   # BFG Repo Cleaner or git filter-branch
   # This is destructive, coordinate with team
   ```

3. **Keep only**:
   ```
   public/
   â”œâ”€â”€ index.html
   â”œâ”€â”€ favicon.ico
   â””â”€â”€ (small static assets only)
   ```

4. **Verify repo size**:
   ```bash
   du -sh .git
   # Should be significantly smaller
   ```

---

## S3 Configuration

### **Bucket Structure**

```
Bucket: ssi-courses
Region: us-east-1
Access: Public read (for dashboard)
Versioning: Enabled (automatic backups)

ssi-courses/
â”œâ”€â”€ spa_for_eng_30seeds/
â”‚   â”œâ”€â”€ v1.0.0/              # Backup
â”‚   â”œâ”€â”€ v1.0.1/              # Backup
â”‚   â”œâ”€â”€ seed_pairs.json      # Latest
â”‚   â”œâ”€â”€ lego_pairs.json
â”‚   â”œâ”€â”€ lego_baskets.json
â”‚   â””â”€â”€ course_metadata.json
â””â”€â”€ ...
```

### **IAM Permissions**

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:DeleteObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::ssi-courses",
        "arn:aws:s3:::ssi-courses/*"
      ]
    }
  ]
}
```

### **CORS Configuration**

```json
[
  {
    "AllowedOrigins": ["*"],
    "AllowedMethods": ["GET"],
    "AllowedHeaders": ["*"],
    "MaxAgeSeconds": 3000
  }
]
```

---

## File Size Considerations

### **Typical Course Sizes**

| Course | Seeds | seed_pairs.json | lego_pairs.json | lego_baskets.json | Total |
|--------|-------|-----------------|-----------------|-------------------|-------|
| Test (30 seeds) | 30 | ~3KB | ~20KB | ~50KB | ~73KB |
| Medium (100 seeds) | 100 | ~10KB | ~70KB | ~170KB | ~250KB |
| Full (668 seeds) | 668 | ~80KB | ~520KB | ~1.2MB | ~1.8MB |

### **Git Impact** (before migration)

```
public/baskets/ (50 files Ã— ~6KB) = ~300KB
public/vfs/courses/ (13 courses Ã— ~200KB) = ~2.6MB
Total generated content in git: ~3MB
```

After migration:
```
Git only has source code: ~500KB (excluding node_modules)
Repo clone time: < 5 seconds (vs ~20 seconds)
```

---

## Security Considerations

### **S3 Public Access**

**Issue**: Course files must be publicly readable for dashboard.

**Mitigation**:
- Only `course_metadata.json` and data files public
- No credentials in files
- No PII in course content
- Versioning enabled (can roll back if issue)

### **API Access**

**Issue**: Local API has no authentication.

**Mitigation**:
- API only runs on localhost (not exposed)
- For production, add API key requirement
- Rate limiting for S3 fetches

---

## Success Metrics

After migration, we should achieve:

1. âœ… **Git repo < 1MB** (source code only)
2. âœ… **No generated files in git**
3. âœ… **All course data in VFS**
4. âœ… **S3 as source of truth for production**
5. âœ… **Sync incomplete courses for review**
6. âœ… **Team collaboration workflow works**
7. âœ… **Dashboard loads from S3 in < 2 seconds**
8. âœ… **Cache hit rate > 80% for repeat visits**
9. âœ… **Version management automatic**
10. âœ… **No manual file copying**

---

## Open Questions

1. **S3 bucket naming**: `ssi-courses` or `ssi-dashboard-courses`?
   - **Recommendation**: `ssi-courses` (shorter, clearer)

2. **Versioning scheme**: Semantic (1.0.0) or timestamp (20251106-123456)?
   - **Recommendation**: Semantic for releases, timestamp for development

3. **Sync triggers**: Manual only, or auto-sync on course completion?
   - **Recommendation**: Manual for now, add auto-sync later

4. **Cache duration**: 24 hours, 7 days, or until version change?
   - **Recommendation**: 24 hours OR version change (whichever first)

5. **Multi-region S3**: Single region or CloudFront?
   - **Recommendation**: Start single region, add CloudFront if latency issue

---

## Next Steps

**Priority order:**

1. **Week 1**: Phase 1 - Migrate baskets to VFS
   - Create migration script
   - Run migration
   - Test locally
   - Keep backups

2. **Week 2**: Phase 2 - Create S3 sync scripts
   - sync-course-to-s3.cjs
   - sync-course-from-s3.cjs
   - Test with spa_for_eng_30seeds

3. **Week 3**: Phase 3 - Update dashboard
   - Remove public/vfs fallback
   - Add S3 fetch logic
   - Add cache layer
   - Test production workflow

4. **Week 4**: Phase 4 - Clean up
   - Remove generated files from git
   - Update .gitignore
   - Document workflows
   - Train team

---

## Conclusion

**Storage strategy summary:**

```
LOCAL VFS (vfs/courses/)
â†“ (sync-to-s3)
S3 (s3://ssi-courses/)
â†“ (dashboard fetch)
BROWSER CACHE (IndexedDB)

GIT: Source code only (NOT course data)
```

**Key principles:**
1. VFS is source of truth during development
2. S3 is source of truth for production
3. Git is for source code only
4. Browser cache for performance
5. Sync on demand, version on sync

---

**Status**: Proposal ready for implementation
**Author**: Claude Code
**Date**: 2025-11-06
