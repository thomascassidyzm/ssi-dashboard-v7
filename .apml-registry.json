{
  "version": "7.0.0",
  "generated_at": "2025-10-13T17:13:36.664Z",
  "apml_file": "ssi-course-production.apml",
  "variable_registry": {
    "TOTAL_SEEDS": 668,
    "BATCH_SIZES": {
      "PHASE_1_TRANSLATION": 100,
      "PHASE_3_LEGO_DECOMPOSITION": 20,
      "PHASE_5_BASKETS": 20
    },
    "VFS_PATHS": {
      "BASE": "/Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses",
      "COURSE_FORMAT": "{target_code}_for_{known_code}_speakers"
    },
    "API_ENDPOINTS": {
      "COURSES_GENERATE": "/api/courses/generate",
      "COURSES_STATUS": "/api/courses/:courseCode/status",
      "COURSES_LIST": "/api/courses",
      "COURSES_GET": "/api/courses/:courseCode",
      "PROMPTS_GET": "/api/prompts/:phase",
      "PROMPTS_UPDATE": "/api/prompts/:phase",
      "PROMPTS_HISTORY": "/api/prompts/:phase/history"
    },
    "PHASE_PROMPTS": {
      "PHASE_0": {
        "phase": "0",
        "name": "Corpus Pre-Analysis",
        "prompt": "# Phase 0: Corpus Pre-Analysis\n\n  ## Task\n  Analyze the source corpus to generate intelligence data for pedagogical translation.\n\n  ## Input\n  - Source corpus (668 canonical seed pairs)\n  - Located in: vfs/seeds/canonical_seeds.json\n\n  ## Your Mission\n  1. Load and validate the canonical seed corpus\n  2. Perform linguistic analysis:\n     - Calculate word frequency distributions\n     - Identify high-frequency vocabulary and grammatical patterns\n     - Assess translation complexity (cognates, false friends, structural challenges)\n     - Map grammatical dependencies and prerequisite knowledge\n  3. Generate intelligence report with:\n     - Frequency rankings for words and phrases\n     - Complexity scores for each seed\n     - Translation guidance notes (tricky structures, idioms, etc.)\n     - Recommendations for Phase 1 heuristic application\n\n  ## Output Format\n  Store results as JSON:\n  vfs/phase_outputs/phase_0_intelligence.json\n\n  Structure:\n  {\n    \"frequency_analysis\": { ... },\n    \"complexity_scores\": { ... },\n    \"translation_guidance\": { ... },\n    \"recommendations\": { ... }\n  }\n\n  ## Important Notes\n  - DO NOT modify the source corpus - analysis only\n  - Focus on patterns that affect pedagogical decisions\n  - This intelligence informs Phase 1's 6 heuristics\n  - Consider learner perspective (what's easy/hard to learn)\n\n  ## Success Criteria\n  ‚úì All 668 seeds analyzed\n  ‚úì Intelligence report generated\n  ‚úì Frequency rankings accurate\n  ‚úì Complexity assessments complete\n  ‚úì Ready for Phase 1 consumption"
      },
      "PHASE_1": {
        "phase": "1",
        "name": "Pedagogical Translation",
        "prompt": "# Phase 1: Pedagogical Translation\n\n  ## Task\n  Apply 6 pedagogical heuristics to translate all 668 canonical seed pairs into optimized learning material.\n\n  ## Input\n  - Canonical seeds: vfs/seeds/canonical_seeds.json\n  - Phase 0 intelligence: vfs/phase_outputs/phase_0_intelligence.json\n\n  ## The 6 Pedagogical Heuristics\n  1. **Naturalness**: Target language should sound native, not transliterated\n  2. **Frequency**: Prefer high-frequency vocabulary and common structures\n  3. **Clarity**: Prioritize clear, unambiguous expressions over idiomatic complexity\n  4. **Brevity**: Shorter translations preferred when pedagogically equivalent\n  5. **Consistency**: Maintain consistent terminology across seeds\n  6. **Utility**: Maximize teaching value (versatile phrases, reusable structures)\n\n  ## Your Mission\n  For each seed:\n  1. Apply all 6 heuristics to create pedagogically optimized translation\n  2. Generate deterministic UUID: hash(source + target + metadata)\n  3. Store as translation amino acid JSON:\n     - UUID as filename\n     - Content: { source, target, seed_id, heuristics_applied, metadata }\n  4. Save to: vfs/amino_acids/translations/{uuid}.json\n\n  ## Critical Rules\n  - Translations are NOT literal - they are pedagogically optimized\n  - Each translation is an immutable amino acid component\n  - UUIDs are content-based (deterministic)\n  - Preserve seed_id for provenance tracking\n\n  ## Example Translation\n  Seed S42: \"I would like to go\"\n  Literal: \"Hoffwn i fynd\"\n  Pedagogical: \"Dw i eisiau mynd\" (more natural, higher frequency, clearer for learners)\n\n  ## Success Criteria\n  ‚úì All 668 seeds translated\n  ‚úì All 6 heuristics applied to each\n  ‚úì Deterministic UUIDs generated\n  ‚úì Amino acids stored in VFS\n  ‚úì Provenance preserved (seed_id in each amino acid)"
      },
      "PHASE_2": {
        "phase": "2",
        "name": "Corpus Intelligence",
        "prompt": "# Phase 2: Corpus Intelligence\n\n  ## Task\n  Analyze translated corpus to determine FCFS (First-Can-First-Say) order and calculate utility scores.\n\n  ## Input\n  - Translation amino acids: vfs/amino_acids/translations/*.json\n  - Phase 0 intelligence: vfs/phase_outputs/phase_0_intelligence.json\n\n  ## Your Mission\n  1. **FCFS Mapping**: Determine chronological teaching order\n     - Identify prerequisite knowledge (what must be learned first)\n     - Map dependency chains (word A requires word B)\n     - Establish natural learning progression\n\n  2. **Utility Scoring**: Calculate pedagogical value\n     - Formula: Frequency √ó Versatility √ó Simplicity\n     - Frequency: How often used in corpus\n     - Versatility: How many contexts it appears in\n     - Simplicity: How easy to learn/teach\n\n  3. **Generate Intelligence Report**:\n     - FCFS rankings for all translations\n     - Utility scores (0-100 scale)\n     - Dependency maps\n     - Teaching sequence recommendations\n\n  ## Output Format\n  vfs/phase_outputs/phase_2_corpus_intelligence.json\n\n  {\n    \"fcfs_order\": [ ... ],\n    \"utility_scores\": { translation_uuid: score, ... },\n    \"dependencies\": { ... },\n    \"recommendations\": { ... }\n  }\n\n  ## Critical Notes\n  - FCFS = \"natural\" chronological sequence\n  - Utility may override FCFS for high-value opportunities\n  - This data drives Phase 3 LEGO extraction algorithm\n\n  ## Success Criteria\n  ‚úì FCFS order complete\n  ‚úì Utility scores calculated for all translations\n  ‚úì Dependency maps generated\n  ‚úì Ready for Phase 3 consumption"
      },
      "PHASE_3": {
        "phase": "3",
        "name": "LEGO Extraction",
        "prompt": "# Phase 3: LEGO Decomposition\n\n  Hi! I need help with Phase 3 of my language course project - LEGO decomposition.\n\n  Working with ${targetLang} for ${knownLang} speakers.\n\n  ## CORE PRINCIPLE\n  Break each SEED_PAIR into LEGO chunks that:\n  1. When placed side-by-side, EXACTLY reconstruct the original sentence\n  2. Each LEGO passes the FD_LOOP test independently\n  3. Are reusable across multiple sentences\n\n  ## MANDATORY UID FORMAT\n  For seed S0001:\n  - LEGOs: S0001L01, S0001L02, S0001L03\n  - FEEDERs: S0001F01, S0001F02 (sub-components of multi-word LEGOs)\n  NEVER use L0001 or F0001 (missing parent seed ID)\n\n  ## üîç FD_LOOP TEST (MANDATORY FOR EVERY CHUNK)\n  Target ‚Üí Known ‚Üí Target = MUST BE IDENTICAL\n  ‚úÖ \"importante\" ‚Üí \"important\" ‚Üí \"importante\" (IDENTICAL)\n  ‚ùå \"bien\" ‚Üí \"good\" ‚Üí \"bueno\" (DIFFERENT = FAIL)\n\n  ## üéØ FCFS RULE (First Come, First Served)\n  When multiple valid mappings exist, use corpus frequency to CLAIM semantic territory:\n\n  ### ARTISTIC CHOICE (flexible mapping allowed):\n  - \"quiero\" appears 15x as \"I want\" in corpus ‚Üí CLAIM as \"I want\"\n  - \"deseo\" appears 2x ‚Üí must use MORE SPECIFIC: \"I desire\" or \"I really want\"\n  - Once claimed, \"I want\" ALWAYS ‚Üí \"quiero\" in this course\n\n  ### GRAMMATICAL CONSTRAINT (NO flexibility):\n  - \"estoy\" CANNOT claim generic \"I am\" - MUST include temporal aspect\n    ‚úÖ \"estoy aprendiendo\" ‚Üí \"I'm learning\" (temporary state)\n    ‚úÖ \"estoy feliz\" ‚Üí \"I'm happy (right now)\"\n    ‚ùå \"estoy\" ‚Üí \"I am\" (loses critical grammar distinction)\n\n  - \"soy\" CANNOT claim generic \"I am\" - MUST include permanent aspect\n    ‚úÖ \"soy de Inglaterra\" ‚Üí \"I'm from England\" (permanent origin)\n    ‚úÖ \"soy profesor\" ‚Üí \"I'm a teacher\" (identity/profession)\n    ‚ùå \"soy\" ‚Üí \"I am\" (loses critical grammar distinction)\n\n  ### FCFS PROCESS:\n  1. Count frequency of each mapping in corpus\n  2. Most frequent CLAIMS the simple mapping (if grammatically valid)\n  3. Less frequent must ADD context to differentiate\n  4. If corpus edit needed to maintain FD, NOTE it for SEED_PAIR revision\n\n  ## üö´ AUTOMATIC REJECTION LIST\n  **Function Words (ALWAYS FAIL FD):**\n  - Articles: el/la/los/las, un/una (gender ambiguous)\n  - Pronouns: le/lo/la (multiple meanings)\n  - Prepositions: en (in/on/at), de (of/from/about), por/para\n  - \"que\" (that/what/which) - context dependent\n\n  **Multi-meaning words WITHOUT grammar constraints:**\n  - \"bien\" ‚Üí well/good/fine (use FCFS to claim primary meaning)\n  - \"muy\" ‚Üí very/really (use FCFS for intensity)\n\n  ## ‚úÖ DUAL-PASS METHODOLOGY\n\n  ### PASS 1: Forward Analysis (${targetLang} ‚Üí ${knownLang})\n  1. Start with first word of ${targetLang} sentence\n  2. Test for FD compliance using FD_LOOP\n  3. If fails, expand to include next word\n  4. Continue until FD passes or sentence complete\n  5. Move to next unmapped word\n\n  ### PASS 2: Reverse Validation (${knownLang} ‚Üí ${targetLang})\n  1. Take each ${knownLang} chunk\n  2. Verify it maps back to EXACT ${targetLang} chunk\n  3. If different ‚Üí REJECT and re-decompose\n\n  ### PASS 3: Corpus-Wide Validation\n  For EVERY chunk, search ALL other SEED_PAIRS in batch:\n  - Find every occurrence of this chunk\n  - Count frequency of each mapping\n  - Apply FCFS: most frequent claims simple mapping\n  - Less frequent must differentiate with context\n  - If conflicts cannot be resolved ‚Üí FLAG for SEED_PAIR revision\n\n  ### PASS 4: SEED_PAIR Revision Notes\n  If decomposition reveals FD conflicts:\n  - Note which SEED_PAIRS need editing\n  - Suggest specific changes to maintain FD\n  - Example: \"I want coffee\" might need ‚Üí \"I'd like coffee\" if \"quiero\" is claimed\n\n  ## üìù COMPONENTIZATION REQUIREMENT (BOTH languages must be multi-word!)\n  COMPONENTIZATION is ONLY needed when BOTH target AND known are multi-word:\n  - ‚úÖ REQUIRED: \"parlare italiano\" ‚Üî \"parler italien\" (BOTH are 2 words)\n  - ‚úÖ REQUIRED: \"para su hermana\" ‚Üî \"for his sister\" (BOTH are 3 words)\n  - ‚ùå NOT NEEDED: \"construir\" ‚Üî \"build\" (both single words)\n  - ‚ùå NOT NEEDED: \"una nueva vida\" ‚Üî \"a new life\" (even though multi-word, simple 1:1 mapping)\n\n  FORMAT: Simple word mappings ONLY (no grammar explanations):\n  \"[known LEGO] = [target LEGO], where [target1] = [known1] and [target2] = [known2]\"\n\n  ‚ö†Ô∏è CRITICAL: Write ALL componentization in ${knownLang}, NOT English!\n  - French speakers: Use French words like \"o√π\" (not \"where\"), \"et\" (not \"and\")\n  - Spanish speakers: Use Spanish words like \"donde\" (not \"where\"), \"y\" (not \"and\")\n  - Chinese speakers: Use Chinese: \"ÂÖ∂‰∏≠\" (not \"where\"), \"Âíå\" (not \"and\")\n\n  Example for ${knownLang} speakers:\n  French: \"parler italien = parlare italiano, o√π parlare = parler et italiano = italien\"\n  Spanish: \"hablar italiano = parlare italiano, donde parlare = hablar y italiano = italiano\"\n  NOT: \"parler italien = parlare italiano, where parlare = parler and italiano = italien\" ‚ùå\n\n  ## THE IRON RULE (ABSOLUTE)\n  **No LEGO begins or ends with a preposition.**\n  - Examples: ‚úó \"to the\", ‚úó \"with me\", ‚úó \"in\"\n  - This is NON-NEGOTIABLE\n\n  ## INPUT DATA\n  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/\n\n  Read ALL SEED_PAIRS from:\n  SEED_PAIRS_COMPLETE.json (contains all 668 seeds)\n\n  The files contain JSON with structure:\n  {\n    \"seed_pairs\": [\n      {\n        \"seed_id\": \"S0001\",\n        \"target\": \"[sentence in ${targetLang}]\",\n        \"known\": \"[sentence in ${knownLang}]\"\n      }\n    ]\n  }\n\n  ## OUTPUT FILES\n  Save to course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/\n\n  1. Process in batches of 20 seeds:\n     - LEGO_BREAKDOWNS_BATCH_001.json (seeds 1-20)\n     - LEGO_BREAKDOWNS_BATCH_002.json (seeds 21-40)\n     - etc.\n\n  2. ALSO create combined file with ALL breakdowns:\n     - LEGO_BREAKDOWNS_COMPLETE.json (all seeds combined)\n\n  Create this exact structure for each file:\n  {\n    \"phase\": \"LEGO_BREAKDOWNS\",\n    \"batch\": \"001\",\n    \"target_language\": \"${targetLang}\",\n    \"known_language\": \"${knownLang}\",\n    \"lego_breakdowns\": [\n      // For EACH seed_pair in the input file:\n      {\n        \"seed_id\": \"S0001\",\n        \"canonical_id\": \"C0001\",\n        \"original_target\": \"actual ${targetLang} sentence\",\n        \"original_known\": \"actual ${knownLang} sentence\",\n        \"lego_pairs\": [\n          // Break into FD-compliant chunks\n        ],\n        \"feeder_pairs\": [\n          // Sub-components of multi-word LEGOs\n        ],\n        \"componentization\": [\n          // ONLY when BOTH target AND known are multi-word!\n          // Simple mappings format: known = target, where word1 = word1 and word2 = word2\n          {\n            \"lego_id\": \"S0001L02\",\n            \"explanation\": \"[known LEGO] = [target LEGO], where [word1] = [word1] and [word2] = [word2]\"\n          }\n          // Skip if either side is single word or if it's a simple 1:1 mapping\n        ]\n      }\n    ]\n  }\n\n  ## CRITICAL OUTPUT RULES\n  - **SILENT OPERATION** - Work quietly, save to file\n  - **NO PRINTING** - Don't display breakdowns\n  - **VFS ONLY** - Save to VFS only, no console output\n\n  Start decomposing immediately."
      },
      "PHASE_3_5": {
        "phase": "3.5",
        "name": "Graph Construction",
        "prompt": "# Phase 3.5: Graph Construction (NEW in v7.0)\n\n  ## Task\n  Build directed graph of LEGO adjacency relationships to enable pattern-aware basket construction.\n\n  ## Input\n  - LEGO amino acids: vfs/amino_acids/legos/*.json\n  - Translation amino acids: vfs/amino_acids/translations/*.json (for co-occurrence analysis)\n\n  ## Your Mission\n  1. **Detect Adjacency Patterns**:\n     - Scan source translations to find which LEGOs appear adjacent to each other\n     - Example: In \"Dw i eisiau mynd\", LEGOs \"Dw i\" and \"eisiau\" are adjacent\n\n  2. **Build Directed Graph**:\n     - Nodes: All LEGO amino acids\n     - Edges: LEGO_A ‚Üí LEGO_B (A precedes B in corpus)\n     - Direction matters (A‚ÜíB ‚â† B‚ÜíA)\n\n  3. **Calculate Edge Weights**:\n     - Weight = co-occurrence frequency √ó pedagogical value\n     - Higher weight = more important pattern to teach\n\n  4. **Validate Graph**:\n     - Ensure graph is connected\n     - Check for invalid cycles\n     - Verify all LEGOs represented\n\n  5. **Export Graph Structure**:\n     - Adjacency list format\n     - Include edge weights\n     - Store metadata (total nodes, edges, density)\n\n  ## Output Format\n  vfs/phase_outputs/phase_3.5_lego_graph.json\n\n  {\n    \"nodes\": [ ... ],\n    \"edges\": [\n      { \"from\": \"uuid_A\", \"to\": \"uuid_B\", \"weight\": 42 },\n      ...\n    ],\n    \"metadata\": { ... }\n  }\n\n  ## Critical Notes\n  - This is NEW in APML v7.0 - graph intelligence!\n  - Phase 5 uses this graph for pattern coverage optimization\n  - Edges represent legitimate LEGO sequence patterns\n  - Replaces old DEBUT/ETERNAL pattern logic\n\n  ## Success Criteria\n  ‚úì All LEGO adjacencies mapped\n  ‚úì Directed edges created\n  ‚úì Edge weights calculated\n  ‚úì Graph validated (connected, no invalid cycles)\n  ‚úì Ready for Phase 5 consumption"
      },
      "PHASE_4": {
        "phase": "4",
        "name": "Deduplication",
        "prompt": "# Phase 4: Deduplication\n\n  ## Task\n  Identify and merge duplicate LEGOs while preserving ALL provenance information.\n\n  ## Input\n  - LEGO amino acids: vfs/amino_acids/legos/*.json\n\n  ## Your Mission\n  1. **Detect Duplicates**:\n     - Find LEGOs with identical text content\n     - May have different UUIDs (different provenance)\n     - Example: \"Dw i\" might appear from S1L1, S4L2, S12L3\n\n  2. **Merge Provenance**:\n     - Combine all S{seed}L{position} labels\n     - Example: Merge S1L1, S4L2, S12L3 ‚Üí \"S1L1, S4L2, S12L3\"\n     - NEVER lose any provenance information\n\n  3. **Recalculate UUID**:\n     - Generate new deterministic UUID based on:\n       - LEGO text\n       - ALL merged provenance labels\n       - Metadata\n\n  4. **Create Deduplicated Set**:\n     - One LEGO per unique text\n     - Complete provenance history preserved\n     - Update graph references if needed\n\n  5. **Store Results**:\n     - vfs/amino_acids/legos_deduplicated/*.json\n     - Keep original LEGOs (immutable)\n     - Deduplicated set is NEW amino acids\n\n  ## Why This Matters\n  - Many LEGOs appear in multiple seeds\n  - Provenance enables edit propagation\n  - If seed S12 changes, we know which LEGOs to update\n  - Birth-parent history must NEVER be lost\n\n  ## Output Structure\n  {\n    \"uuid\": \"new_deduplicated_uuid\",\n    \"text\": \"the LEGO phrase\",\n    \"provenance\": [\"S1L1\", \"S4L2\", \"S12L3\"],\n    \"source_count\": 3,\n    \"metadata\": { ... }\n  }\n\n  ## Success Criteria\n  ‚úì All duplicates identified\n  ‚úì Provenance fully merged (no data loss)\n  ‚úì New UUIDs generated\n  ‚úì Deduplicated set created\n  ‚úì Original LEGOs preserved (immutable)"
      },
      "PHASE_5": {
        "phase": "5",
        "name": "Basket Generation with Progressive Vocabulary",
        "prompt": "# Phase 5: Basket Generation - Progressive Vocabulary Practice\n\n  ## CRITICAL PER-LEGO VOCABULARY CONSTRAINTS\n  **ABSOLUTE RULE**: Each LEGO has DIFFERENT available vocabulary!\n  - LEGO #1: NO VOCABULARY AVAILABLE = NO PHRASES POSSIBLE (empty basket)\n  - LEGO #2: Can only use LEGO #1 = VERY LIMITED phrases possible\n  - LEGO #3: Can only use LEGOs #1-2 = A FEW phrases possible\n  - LEGO #N: Can only use LEGOs #1 through #(N-1)\n\n  ## Input Data\n  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/\n\n  Read LEGOs from: vfs/amino_acids/legos_deduplicated/*.json\n\n  ## E-PHRASES (5 Eternal Practice Phrases per LEGO)\n  Create 5 phrases, each 7-10 words (balanced across 7/8/9/10):\n  - **MUST contain the target LEGO**\n  - **Perfect grammar** in BOTH languages - validate target AND known language\n  - **Natural, conversational** - things people actually say in BOTH languages\n  - **Smooth pronunciation** - not clunky or awkward in either language\n  - **Variety in position** - LEGO at different positions in phrase\n  - **BILINGUAL VALIDATION**: Each phrase must be:\n    - Grammatically correct in target language\n    - Grammatically correct in known language\n    - Semantically meaningful in BOTH languages\n    - Natural and idiomatic in BOTH cultures\n\n  ### CRITICAL RULE - CULMINATING LEGOs\n  **IF this is the LAST LEGO in a seed (e.g., S0123L03 is the last of S0123):**\n  - **E-phrase #1 MUST be the COMPLETE SEED PHRASE itself**\n  - This complete seed phrase should be used HEAVILY in D-phrases (3+ times)\n  - Why: The learner finally has ALL pieces to understand the full seed!\n  - Example: If S0123 = \"I want to speak Italian with you now\" and S0123L03 = \"now\",\n    then E1 must be exactly \"I want to speak Italian with you now\"\n\n  ## VOCABULARY SELECTION (Recency Guidelines - for LEGOs 50+)\n  **For early LEGOs (1-50):** Use whatever vocabulary is available - there's not enough yet for recency preferences.\n\n  **For later LEGOs (50+):** When building E-phrases, PREFER recent vocabulary:\n  - ~50% of vocabulary from recent seeds (N-5 to N-1)\n  - ~25% from medium-recent (N-20 to N-1)\n  - ~25% from all earlier seeds\n\n  BUT ALWAYS PRIORITIZE natural, useful phrases over strict percentages.\n\n  ## D-PHRASES (Auto-Generated Debuts)\n  You will generate D-phrases using expanding window from E-phrases:\n  - 2x 2-LEGO phrases\n  - 2x 3-LEGO phrases\n  - 2x 4-LEGO phrases\n  - 2x 5-LEGO phrases\n  ALL 5 E-phrases must contribute to D-phrases (variety is key).\n\n  **BILINGUAL SYNTAX RULES FOR D-PHRASES:**\n  - D-phrases can be fragments (don't need to be complete sentences)\n  - BUT they MUST be syntactically correct as far as they go in BOTH languages\n  - Examples:\n    - ‚úÖ \"quiero hablar\" / \"I want to speak\" (fragment but correct in both)\n    - ‚úÖ \"espa√±ol contigo\" / \"Spanish with you\" (fragment but correct in both)\n    - ‚ùå \"quiero de\" / \"I want of\" (syntactically broken in both)\n    - ‚ùå \"hablar yo\" / \"speak I\" (wrong word order in both)\n  - Always validate BOTH the target AND known language versions\n\n  **For CULMINATING LEGOs:** Use the complete seed (E1) in at least:\n  - 1x in 2-LEGO phrases\n  - 1x in 3-LEGO phrases\n  - 1x in 4 or 5-LEGO phrases\n  This reinforces the complete seed understanding!\n\n  ## VALIDATION REQUIREMENTS\n  1. For EACH LEGO's basket:\n     - If NO valid phrases can be made: Output {\"e_phrases\": [], \"d_phrases\": {}}\n     - If only 1-2 phrases possible: Use what's available, don't force 5 phrases\n     - EVERY word MUST come from the available vocabulary list\n\n  2. NEVER use:\n     - Words from LEGOs that haven't been learned yet\n     - Words not in a LEGO (no \"y\", \"de\", \"el\" unless they're in a LEGO)\n     - Made-up words to fill space\n\n  3. Expected pattern for early LEGOs:\n     - LEGO #1: NO PHRASES POSSIBLE (empty basket)\n     - LEGO #2: Maybe 1 meaningful combination if semantically valid\n     - LEGO #3: 1-3 phrases depending on semantic validity\n     - Only after ~10-15 LEGOs will you have enough vocabulary for D-phrases\n     - Only after ~50-100 LEGOs will you have enough vocabulary for full E-phrase baskets\n\n  4. SEMANTIC VALIDITY RULES:\n     - All phrases must be grammatically AND semantically correct in BOTH languages\n     - Consider actual language usage and meaning\n     - Validate each combination for real-world meaningfulness\n\n  ## Output Format\n  Save to: course_folder/phase_outputs/phase_5_baskets.json\n\n  {\n    \"baskets\": {\n      \"S####L##\": {\n        \"target\": \"[target lego]\",\n        \"known\": \"[known translation]\",\n        \"seed_origin\": \"S####\",\n        \"e_phrases\": [\n          [\"[7-10 word phrase with target LEGO]\", \"[translation]\"],\n          [\"[7-10 word phrase with target LEGO]\", \"[translation]\"],\n          [\"[7-10 word phrase with target LEGO]\", \"[translation]\"],\n          [\"[7-10 word phrase with target LEGO]\", \"[translation]\"],\n          [\"[7-10 word phrase with target LEGO]\", \"[translation]\"]\n        ],\n        \"d_phrases\": {\n          \"2_lego\": [\n            [\"[2-LEGO phrase]\", \"[translation]\"],\n            [\"[2-LEGO phrase]\", \"[translation]\"]\n          ],\n          \"3_lego\": [\n            [\"[3-LEGO phrase]\", \"[translation]\"],\n            [\"[3-LEGO phrase]\", \"[translation]\"]\n          ],\n          \"4_lego\": [\n            [\"[4-LEGO phrase]\", \"[translation]\"],\n            [\"[4-LEGO phrase]\", \"[translation]\"]\n          ],\n          \"5_lego\": [\n            [\"[5-LEGO phrase]\", \"[translation]\"],\n            [\"[5-LEGO phrase]\", \"[translation]\"]\n          ]\n        }\n      }\n    }\n  }\n\n  ## Success Criteria\n  ‚úì Every LEGO has a basket (even if empty for early LEGOs)\n  ‚úì All vocabulary constraints respected\n  ‚úì E-phrases are natural and conversational in BOTH languages\n  ‚úì D-phrases are syntactically correct in BOTH languages\n  ‚úì Culminating LEGOs include complete seed as E-phrase #1\n  ‚úì Progressive difficulty from LEGO #1 to last LEGO"
      },
      "PHASE_6": {
        "phase": "6",
        "name": "Introductions",
        "prompt": "# Phase 6: Introductions\n\n  ## Task\n  Generate known-only introduction phrases for each basket to prime learners with zero unknowns.\n\n  ## Input\n  - Basket amino acids: vfs/amino_acids/baskets/*.json\n  - Deduplicated LEGOs: vfs/amino_acids/legos_deduplicated/*.json\n\n  ## Your Mission\n  For each basket:\n  1. **Identify Known LEGOs**:\n     - Scan ALL previous baskets (baskets 1 to N-1)\n     - Compile complete inventory of LEGOs learner has mastered\n     - These are the ONLY LEGOs you can use\n\n  2. **Generate Introduction Phrases**:\n     - Create warm-up phrases using ONLY known LEGOs\n     - ZERO unknown vocabulary or structures\n     - Goal: Activate prior knowledge, build confidence\n     - Prepare learner for new basket content\n\n  3. **Validate Known-Only Rule**:\n     - Double-check: NO new LEGOs in introductions\n     - Every word/phrase must be from known set\n     - Absolute rule - no exceptions\n\n  4. **Create Introduction Amino Acids**:\n     - Deterministic UUID based on content + basket reference\n     - Store: vfs/amino_acids/introductions/{uuid}.json\n\n  ## Introduction Amino Acid Structure\n  {\n    \"uuid\": \"...\",\n    \"basket_uuid\": \"...\",\n    \"phrases\": [\"phrase1\", \"phrase2\", ...],\n    \"known_legos_used\": [\"uuid1\", \"uuid2\", ...],\n    \"validation\": {\n      \"all_known\": true,\n      \"unknown_count\": 0\n    }\n  }\n\n  ## Why This Matters\n  - Reduces cognitive load before new learning\n  - Builds learner confidence (100% comprehension)\n  - Primes brain for new content\n  - Creates smooth entry point to each basket\n\n  ## CRITICAL RULE\n  **ZERO unknown elements allowed in introductions.**\n  If you're unsure, DON'T use it.\n\n  ## Success Criteria\n  ‚úì Introduction generated for each basket\n  ‚úì All LEGOs verified as \"known\" from previous baskets\n  ‚úì Zero unknown elements (validated)\n  ‚úì Introduction amino acids stored\n  ‚úì Course ready for final compilation"
      }
    }
  },
  "system": {
    "name": "SSi Course Production System",
    "description": "Self-improving language course generation with recursive intelligence evolution",
    "architecture": "Vue3 + Node.js + Claude Code (Sonnet 4.5)",
    "deployment": "Vercel (dashboard) + Local Mac (automation)"
  }
}