{
  "version": "7.0.0",
  "generated_at": "2025-10-13T14:40:47.933Z",
  "apml_file": "ssi-course-production.apml",
  "variable_registry": {
    "TOTAL_SEEDS": 668,
    "BATCH_SIZES": {
      "PHASE_1_TRANSLATION": 100,
      "PHASE_3_LEGO_DECOMPOSITION": 20,
      "PHASE_5_BASKETS": 20
    },
    "VFS_PATHS": {
      "BASE": "/Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses",
      "COURSE_FORMAT": "{target_code}_for_{known_code}_speakers"
    },
    "API_ENDPOINTS": {
      "COURSES_GENERATE": "/api/courses/generate",
      "COURSES_STATUS": "/api/courses/:courseCode/status",
      "COURSES_LIST": "/api/courses",
      "COURSES_GET": "/api/courses/:courseCode",
      "PROMPTS_GET": "/api/prompts/:phase",
      "PROMPTS_UPDATE": "/api/prompts/:phase",
      "PROMPTS_HISTORY": "/api/prompts/:phase/history"
    },
    "PHASE_PROMPTS": {
      "PHASE_0": {
        "phase": "0",
        "name": "Corpus Pre-Analysis",
        "prompt": "# Phase 0: Corpus Pre-Analysis\n\n  ## Task\n  Analyze the source corpus to generate intelligence data for pedagogical translation.\n\n  ## Input\n  - Source corpus (668 canonical seed pairs)\n  - Located in: vfs/seeds/canonical_seeds.json\n\n  ## Your Mission\n  1. Load and validate the canonical seed corpus\n  2. Perform linguistic analysis:\n     - Calculate word frequency distributions\n     - Identify high-frequency vocabulary and grammatical patterns\n     - Assess translation complexity (cognates, false friends, structural challenges)\n     - Map grammatical dependencies and prerequisite knowledge\n  3. Generate intelligence report with:\n     - Frequency rankings for words and phrases\n     - Complexity scores for each seed\n     - Translation guidance notes (tricky structures, idioms, etc.)\n     - Recommendations for Phase 1 heuristic application\n\n  ## Output Format\n  Store results as JSON:\n  vfs/phase_outputs/phase_0_intelligence.json\n\n  Structure:\n  {\n    \"frequency_analysis\": { ... },\n    \"complexity_scores\": { ... },\n    \"translation_guidance\": { ... },\n    \"recommendations\": { ... }\n  }\n\n  ## Important Notes\n  - DO NOT modify the source corpus - analysis only\n  - Focus on patterns that affect pedagogical decisions\n  - This intelligence informs Phase 1's 6 heuristics\n  - Consider learner perspective (what's easy/hard to learn)\n\n  ## Success Criteria\n  ‚úì All 668 seeds analyzed\n  ‚úì Intelligence report generated\n  ‚úì Frequency rankings accurate\n  ‚úì Complexity assessments complete\n  ‚úì Ready for Phase 1 consumption"
      },
      "PHASE_1": {
        "phase": "1",
        "name": "Pedagogical Translation",
        "prompt": "# Phase 1: Pedagogical Translation\n\n  ## Task\n  Apply 6 pedagogical heuristics to translate all 668 canonical seed pairs into optimized learning material.\n\n  ## Input\n  - Canonical seeds: vfs/seeds/canonical_seeds.json\n  - Phase 0 intelligence: vfs/phase_outputs/phase_0_intelligence.json\n\n  ## The 6 Pedagogical Heuristics\n  1. **Naturalness**: Target language should sound native, not transliterated\n  2. **Frequency**: Prefer high-frequency vocabulary and common structures\n  3. **Clarity**: Prioritize clear, unambiguous expressions over idiomatic complexity\n  4. **Brevity**: Shorter translations preferred when pedagogically equivalent\n  5. **Consistency**: Maintain consistent terminology across seeds\n  6. **Utility**: Maximize teaching value (versatile phrases, reusable structures)\n\n  ## Your Mission\n  For each seed:\n  1. Apply all 6 heuristics to create pedagogically optimized translation\n  2. Generate deterministic UUID: hash(source + target + metadata)\n  3. Store as translation amino acid JSON:\n     - UUID as filename\n     - Content: { source, target, seed_id, heuristics_applied, metadata }\n  4. Save to: vfs/amino_acids/translations/{uuid}.json\n\n  ## Critical Rules\n  - Translations are NOT literal - they are pedagogically optimized\n  - Each translation is an immutable amino acid component\n  - UUIDs are content-based (deterministic)\n  - Preserve seed_id for provenance tracking\n\n  ## Example Translation\n  Seed S42: \"I would like to go\"\n  Literal: \"Hoffwn i fynd\"\n  Pedagogical: \"Dw i eisiau mynd\" (more natural, higher frequency, clearer for learners)\n\n  ## Success Criteria\n  ‚úì All 668 seeds translated\n  ‚úì All 6 heuristics applied to each\n  ‚úì Deterministic UUIDs generated\n  ‚úì Amino acids stored in VFS\n  ‚úì Provenance preserved (seed_id in each amino acid)"
      },
      "PHASE_2": {
        "phase": "2",
        "name": "Corpus Intelligence",
        "prompt": "# Phase 2: Corpus Intelligence\n\n  ## Task\n  Analyze translated corpus to determine FCFS (First-Can-First-Say) order and calculate utility scores.\n\n  ## Input\n  - Translation amino acids: vfs/amino_acids/translations/*.json\n  - Phase 0 intelligence: vfs/phase_outputs/phase_0_intelligence.json\n\n  ## Your Mission\n  1. **FCFS Mapping**: Determine chronological teaching order\n     - Identify prerequisite knowledge (what must be learned first)\n     - Map dependency chains (word A requires word B)\n     - Establish natural learning progression\n\n  2. **Utility Scoring**: Calculate pedagogical value\n     - Formula: Frequency √ó Versatility √ó Simplicity\n     - Frequency: How often used in corpus\n     - Versatility: How many contexts it appears in\n     - Simplicity: How easy to learn/teach\n\n  3. **Generate Intelligence Report**:\n     - FCFS rankings for all translations\n     - Utility scores (0-100 scale)\n     - Dependency maps\n     - Teaching sequence recommendations\n\n  ## Output Format\n  vfs/phase_outputs/phase_2_corpus_intelligence.json\n\n  {\n    \"fcfs_order\": [ ... ],\n    \"utility_scores\": { translation_uuid: score, ... },\n    \"dependencies\": { ... },\n    \"recommendations\": { ... }\n  }\n\n  ## Critical Notes\n  - FCFS = \"natural\" chronological sequence\n  - Utility may override FCFS for high-value opportunities\n  - This data drives Phase 3 LEGO extraction algorithm\n\n  ## Success Criteria\n  ‚úì FCFS order complete\n  ‚úì Utility scores calculated for all translations\n  ‚úì Dependency maps generated\n  ‚úì Ready for Phase 3 consumption"
      },
      "PHASE_3": {
        "phase": "3",
        "name": "LEGO Extraction",
        "prompt": "# Phase 3: LEGO Decomposition\n\n  Hi! I need help with Phase 3 of my language course project - LEGO decomposition.\n\n  Working with ${targetLang} for ${knownLang} speakers.\n\n  ## CORE PRINCIPLE\n  Break each SEED_PAIR into LEGO chunks that:\n  1. When placed side-by-side, EXACTLY reconstruct the original sentence\n  2. Each LEGO passes the FD_LOOP test independently\n  3. Are reusable across multiple sentences\n\n  ## MANDATORY UID FORMAT\n  For seed S0001:\n  - LEGOs: S0001L01, S0001L02, S0001L03\n  - FEEDERs: S0001F01, S0001F02 (sub-components of multi-word LEGOs)\n  NEVER use L0001 or F0001 (missing parent seed ID)\n\n  ## üîç FD_LOOP TEST (MANDATORY FOR EVERY CHUNK)\n  Target ‚Üí Known ‚Üí Target = MUST BE IDENTICAL\n  ‚úÖ \"importante\" ‚Üí \"important\" ‚Üí \"importante\" (IDENTICAL)\n  ‚ùå \"bien\" ‚Üí \"good\" ‚Üí \"bueno\" (DIFFERENT = FAIL)\n\n  ## üéØ FCFS RULE (First Come, First Served)\n  When multiple valid mappings exist, use corpus frequency to CLAIM semantic territory:\n\n  ### ARTISTIC CHOICE (flexible mapping allowed):\n  - \"quiero\" appears 15x as \"I want\" in corpus ‚Üí CLAIM as \"I want\"\n  - \"deseo\" appears 2x ‚Üí must use MORE SPECIFIC: \"I desire\" or \"I really want\"\n  - Once claimed, \"I want\" ALWAYS ‚Üí \"quiero\" in this course\n\n  ### GRAMMATICAL CONSTRAINT (NO flexibility):\n  - \"estoy\" CANNOT claim generic \"I am\" - MUST include temporal aspect\n    ‚úÖ \"estoy aprendiendo\" ‚Üí \"I'm learning\" (temporary state)\n    ‚úÖ \"estoy feliz\" ‚Üí \"I'm happy (right now)\"\n    ‚ùå \"estoy\" ‚Üí \"I am\" (loses critical grammar distinction)\n\n  - \"soy\" CANNOT claim generic \"I am\" - MUST include permanent aspect\n    ‚úÖ \"soy de Inglaterra\" ‚Üí \"I'm from England\" (permanent origin)\n    ‚úÖ \"soy profesor\" ‚Üí \"I'm a teacher\" (identity/profession)\n    ‚ùå \"soy\" ‚Üí \"I am\" (loses critical grammar distinction)\n\n  ### FCFS PROCESS:\n  1. Count frequency of each mapping in corpus\n  2. Most frequent CLAIMS the simple mapping (if grammatically valid)\n  3. Less frequent must ADD context to differentiate\n  4. If corpus edit needed to maintain FD, NOTE it for SEED_PAIR revision\n\n  ## üö´ AUTOMATIC REJECTION LIST\n  **Function Words (ALWAYS FAIL FD):**\n  - Articles: el/la/los/las, un/una (gender ambiguous)\n  - Pronouns: le/lo/la (multiple meanings)\n  - Prepositions: en (in/on/at), de (of/from/about), por/para\n  - \"que\" (that/what/which) - context dependent\n\n  **Multi-meaning words WITHOUT grammar constraints:**\n  - \"bien\" ‚Üí well/good/fine (use FCFS to claim primary meaning)\n  - \"muy\" ‚Üí very/really (use FCFS for intensity)\n\n  ## ‚úÖ DUAL-PASS METHODOLOGY\n\n  ### PASS 1: Forward Analysis (${targetLang} ‚Üí ${knownLang})\n  1. Start with first word of ${targetLang} sentence\n  2. Test for FD compliance using FD_LOOP\n  3. If fails, expand to include next word\n  4. Continue until FD passes or sentence complete\n  5. Move to next unmapped word\n\n  ### PASS 2: Reverse Validation (${knownLang} ‚Üí ${targetLang})\n  1. Take each ${knownLang} chunk\n  2. Verify it maps back to EXACT ${targetLang} chunk\n  3. If different ‚Üí REJECT and re-decompose\n\n  ### PASS 3: Corpus-Wide Validation\n  For EVERY chunk, search ALL other SEED_PAIRS in batch:\n  - Find every occurrence of this chunk\n  - Count frequency of each mapping\n  - Apply FCFS: most frequent claims simple mapping\n  - Less frequent must differentiate with context\n  - If conflicts cannot be resolved ‚Üí FLAG for SEED_PAIR revision\n\n  ### PASS 4: SEED_PAIR Revision Notes\n  If decomposition reveals FD conflicts:\n  - Note which SEED_PAIRS need editing\n  - Suggest specific changes to maintain FD\n  - Example: \"I want coffee\" might need ‚Üí \"I'd like coffee\" if \"quiero\" is claimed\n\n  ## üìù COMPONENTIZATION REQUIREMENT (BOTH languages must be multi-word!)\n  COMPONENTIZATION is ONLY needed when BOTH target AND known are multi-word:\n  - ‚úÖ REQUIRED: \"parlare italiano\" ‚Üî \"parler italien\" (BOTH are 2 words)\n  - ‚úÖ REQUIRED: \"para su hermana\" ‚Üî \"for his sister\" (BOTH are 3 words)\n  - ‚ùå NOT NEEDED: \"construir\" ‚Üî \"build\" (both single words)\n  - ‚ùå NOT NEEDED: \"una nueva vida\" ‚Üî \"a new life\" (even though multi-word, simple 1:1 mapping)\n\n  FORMAT: Simple word mappings ONLY (no grammar explanations):\n  \"[known LEGO] = [target LEGO], where [target1] = [known1] and [target2] = [known2]\"\n\n  ‚ö†Ô∏è CRITICAL: Write ALL componentization in ${knownLang}, NOT English!\n  - French speakers: Use French words like \"o√π\" (not \"where\"), \"et\" (not \"and\")\n  - Spanish speakers: Use Spanish words like \"donde\" (not \"where\"), \"y\" (not \"and\")\n  - Chinese speakers: Use Chinese: \"ÂÖ∂‰∏≠\" (not \"where\"), \"Âíå\" (not \"and\")\n\n  Example for ${knownLang} speakers:\n  French: \"parler italien = parlare italiano, o√π parlare = parler et italiano = italien\"\n  Spanish: \"hablar italiano = parlare italiano, donde parlare = hablar y italiano = italiano\"\n  NOT: \"parler italien = parlare italiano, where parlare = parler and italiano = italien\" ‚ùå\n\n  ## THE IRON RULE (ABSOLUTE)\n  **No LEGO begins or ends with a preposition.**\n  - Examples: ‚úó \"to the\", ‚úó \"with me\", ‚úó \"in\"\n  - This is NON-NEGOTIABLE\n\n  ## INPUT DATA\n  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/\n\n  Read ALL SEED_PAIRS from:\n  SEED_PAIRS_COMPLETE.json (contains all 668 seeds)\n\n  The files contain JSON with structure:\n  {\n    \"seed_pairs\": [\n      {\n        \"seed_id\": \"S0001\",\n        \"target\": \"[sentence in ${targetLang}]\",\n        \"known\": \"[sentence in ${knownLang}]\"\n      }\n    ]\n  }\n\n  ## OUTPUT FILES\n  Save to course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/\n\n  1. Process in batches of 20 seeds:\n     - LEGO_BREAKDOWNS_BATCH_001.json (seeds 1-20)\n     - LEGO_BREAKDOWNS_BATCH_002.json (seeds 21-40)\n     - etc.\n\n  2. ALSO create combined file with ALL breakdowns:\n     - LEGO_BREAKDOWNS_COMPLETE.json (all seeds combined)\n\n  Create this exact structure for each file:\n  {\n    \"phase\": \"LEGO_BREAKDOWNS\",\n    \"batch\": \"001\",\n    \"target_language\": \"${targetLang}\",\n    \"known_language\": \"${knownLang}\",\n    \"lego_breakdowns\": [\n      // For EACH seed_pair in the input file:\n      {\n        \"seed_id\": \"S0001\",\n        \"canonical_id\": \"C0001\",\n        \"original_target\": \"actual ${targetLang} sentence\",\n        \"original_known\": \"actual ${knownLang} sentence\",\n        \"lego_pairs\": [\n          // Break into FD-compliant chunks\n        ],\n        \"feeder_pairs\": [\n          // Sub-components of multi-word LEGOs\n        ],\n        \"componentization\": [\n          // ONLY when BOTH target AND known are multi-word!\n          // Simple mappings format: known = target, where word1 = word1 and word2 = word2\n          {\n            \"lego_id\": \"S0001L02\",\n            \"explanation\": \"[known LEGO] = [target LEGO], where [word1] = [word1] and [word2] = [word2]\"\n          }\n          // Skip if either side is single word or if it's a simple 1:1 mapping\n        ]\n      }\n    ]\n  }\n\n  ## CRITICAL OUTPUT RULES\n  - **SILENT OPERATION** - Work quietly, save to file\n  - **NO PRINTING** - Don't display breakdowns\n  - **VFS ONLY** - Save to VFS only, no console output\n\n  Start decomposing immediately."
      },
      "PHASE_3_5": {
        "phase": "3.5",
        "name": "Graph Construction",
        "prompt": "# Phase 3.5: Graph Construction (NEW in v7.0)\n\n  ## Task\n  Build directed graph of LEGO adjacency relationships to enable pattern-aware basket construction.\n\n  ## Input\n  - LEGO amino acids: vfs/amino_acids/legos/*.json\n  - Translation amino acids: vfs/amino_acids/translations/*.json (for co-occurrence analysis)\n\n  ## Your Mission\n  1. **Detect Adjacency Patterns**:\n     - Scan source translations to find which LEGOs appear adjacent to each other\n     - Example: In \"Dw i eisiau mynd\", LEGOs \"Dw i\" and \"eisiau\" are adjacent\n\n  2. **Build Directed Graph**:\n     - Nodes: All LEGO amino acids\n     - Edges: LEGO_A ‚Üí LEGO_B (A precedes B in corpus)\n     - Direction matters (A‚ÜíB ‚â† B‚ÜíA)\n\n  3. **Calculate Edge Weights**:\n     - Weight = co-occurrence frequency √ó pedagogical value\n     - Higher weight = more important pattern to teach\n\n  4. **Validate Graph**:\n     - Ensure graph is connected\n     - Check for invalid cycles\n     - Verify all LEGOs represented\n\n  5. **Export Graph Structure**:\n     - Adjacency list format\n     - Include edge weights\n     - Store metadata (total nodes, edges, density)\n\n  ## Output Format\n  vfs/phase_outputs/phase_3.5_lego_graph.json\n\n  {\n    \"nodes\": [ ... ],\n    \"edges\": [\n      { \"from\": \"uuid_A\", \"to\": \"uuid_B\", \"weight\": 42 },\n      ...\n    ],\n    \"metadata\": { ... }\n  }\n\n  ## Critical Notes\n  - This is NEW in APML v7.0 - graph intelligence!\n  - Phase 5 uses this graph for pattern coverage optimization\n  - Edges represent legitimate LEGO sequence patterns\n  - Replaces old DEBUT/ETERNAL pattern logic\n\n  ## Success Criteria\n  ‚úì All LEGO adjacencies mapped\n  ‚úì Directed edges created\n  ‚úì Edge weights calculated\n  ‚úì Graph validated (connected, no invalid cycles)\n  ‚úì Ready for Phase 5 consumption"
      },
      "PHASE_4": {
        "phase": "4",
        "name": "Deduplication",
        "prompt": "# Phase 4: Deduplication\n\n  ## Task\n  Identify and merge duplicate LEGOs while preserving ALL provenance information.\n\n  ## Input\n  - LEGO amino acids: vfs/amino_acids/legos/*.json\n\n  ## Your Mission\n  1. **Detect Duplicates**:\n     - Find LEGOs with identical text content\n     - May have different UUIDs (different provenance)\n     - Example: \"Dw i\" might appear from S1L1, S4L2, S12L3\n\n  2. **Merge Provenance**:\n     - Combine all S{seed}L{position} labels\n     - Example: Merge S1L1, S4L2, S12L3 ‚Üí \"S1L1, S4L2, S12L3\"\n     - NEVER lose any provenance information\n\n  3. **Recalculate UUID**:\n     - Generate new deterministic UUID based on:\n       - LEGO text\n       - ALL merged provenance labels\n       - Metadata\n\n  4. **Create Deduplicated Set**:\n     - One LEGO per unique text\n     - Complete provenance history preserved\n     - Update graph references if needed\n\n  5. **Store Results**:\n     - vfs/amino_acids/legos_deduplicated/*.json\n     - Keep original LEGOs (immutable)\n     - Deduplicated set is NEW amino acids\n\n  ## Why This Matters\n  - Many LEGOs appear in multiple seeds\n  - Provenance enables edit propagation\n  - If seed S12 changes, we know which LEGOs to update\n  - Birth-parent history must NEVER be lost\n\n  ## Output Structure\n  {\n    \"uuid\": \"new_deduplicated_uuid\",\n    \"text\": \"the LEGO phrase\",\n    \"provenance\": [\"S1L1\", \"S4L2\", \"S12L3\"],\n    \"source_count\": 3,\n    \"metadata\": { ... }\n  }\n\n  ## Success Criteria\n  ‚úì All duplicates identified\n  ‚úì Provenance fully merged (no data loss)\n  ‚úì New UUIDs generated\n  ‚úì Deduplicated set created\n  ‚úì Original LEGOs preserved (immutable)"
      },
      "PHASE_5": {
        "phase": "5",
        "name": "Pattern-Aware Baskets",
        "prompt": "# Phase 5: Pattern-Aware Baskets\n\n  ## Task\n  Construct learning baskets (lessons) optimized for graph edge coverage and pedagogical progression.\n\n  ## Input\n  - Deduplicated LEGOs: vfs/amino_acids/legos_deduplicated/*.json\n  - LEGO graph: vfs/phase_outputs/phase_3.5_lego_graph.json\n  - Corpus intelligence: vfs/phase_outputs/phase_2_corpus_intelligence.json\n\n  ## Your Mission\n  1. **Load Graph Intelligence**:\n     - LEGO adjacency graph with edges and weights\n     - This drives pattern coverage optimization\n\n  2. **Maximize Edge Coverage**:\n     - Select LEGOs to expose DIVERSE patterns\n     - Each basket should cover unique graph edges\n     - Avoid redundant LEGO sequences across baskets\n     - Goal: Learners experience maximum pattern variety\n\n  3. **Maintain Pedagogical Coherence**:\n     - Follow FCFS chronological progression\n     - Apply utility scoring for high-value sequences\n     - Ensure smooth difficulty progression\n     - Balance novelty with reinforcement\n\n  4. **Construct Basket Amino Acids**:\n     - Each basket = collection of LEGO UUIDs (manifest)\n     - Metadata: edge coverage stats, difficulty level, etc.\n     - Deterministic UUID based on manifest content\n\n  5. **Store Results**:\n     - vfs/amino_acids/baskets/{uuid}.json\n\n  ## Basket Amino Acid Structure\n  {\n    \"uuid\": \"...\",\n    \"lego_manifest\": [\"uuid1\", \"uuid2\", ...],\n    \"edge_coverage\": [\"edge_A_B\", \"edge_C_D\", ...],\n    \"fcfs_score\": 78,\n    \"difficulty_level\": \"intermediate\",\n    \"metadata\": { ... }\n  }\n\n  ## This Replaces OLD Logic\n  - OLD: DEBUT/ETERNAL pattern terminology\n  - NEW: Graph-driven edge coverage\n  - BETTER: Measurable pattern diversity\n\n  ## Success Criteria\n  ‚úì All LEGOs assigned to baskets\n  ‚úì Maximum edge coverage per basket\n  ‚úì FCFS/utility balance maintained\n  ‚úì Basket amino acids created with manifests\n  ‚úì Ready for Phase 6 (introductions)"
      },
      "PHASE_6": {
        "phase": "6",
        "name": "Introductions",
        "prompt": "# Phase 6: Introductions\n\n  ## Task\n  Generate known-only introduction phrases for each basket to prime learners with zero unknowns.\n\n  ## Input\n  - Basket amino acids: vfs/amino_acids/baskets/*.json\n  - Deduplicated LEGOs: vfs/amino_acids/legos_deduplicated/*.json\n\n  ## Your Mission\n  For each basket:\n  1. **Identify Known LEGOs**:\n     - Scan ALL previous baskets (baskets 1 to N-1)\n     - Compile complete inventory of LEGOs learner has mastered\n     - These are the ONLY LEGOs you can use\n\n  2. **Generate Introduction Phrases**:\n     - Create warm-up phrases using ONLY known LEGOs\n     - ZERO unknown vocabulary or structures\n     - Goal: Activate prior knowledge, build confidence\n     - Prepare learner for new basket content\n\n  3. **Validate Known-Only Rule**:\n     - Double-check: NO new LEGOs in introductions\n     - Every word/phrase must be from known set\n     - Absolute rule - no exceptions\n\n  4. **Create Introduction Amino Acids**:\n     - Deterministic UUID based on content + basket reference\n     - Store: vfs/amino_acids/introductions/{uuid}.json\n\n  ## Introduction Amino Acid Structure\n  {\n    \"uuid\": \"...\",\n    \"basket_uuid\": \"...\",\n    \"phrases\": [\"phrase1\", \"phrase2\", ...],\n    \"known_legos_used\": [\"uuid1\", \"uuid2\", ...],\n    \"validation\": {\n      \"all_known\": true,\n      \"unknown_count\": 0\n    }\n  }\n\n  ## Why This Matters\n  - Reduces cognitive load before new learning\n  - Builds learner confidence (100% comprehension)\n  - Primes brain for new content\n  - Creates smooth entry point to each basket\n\n  ## CRITICAL RULE\n  **ZERO unknown elements allowed in introductions.**\n  If you're unsure, DON'T use it.\n\n  ## Success Criteria\n  ‚úì Introduction generated for each basket\n  ‚úì All LEGOs verified as \"known\" from previous baskets\n  ‚úì Zero unknown elements (validated)\n  ‚úì Introduction amino acids stored\n  ‚úì Course ready for final compilation"
      }
    }
  },
  "system": {
    "name": "SSi Course Production System",
    "description": "Self-improving language course generation with recursive intelligence evolution",
    "architecture": "Vue3 + Node.js + Claude Code (Sonnet 4.5)",
    "deployment": "Vercel (dashboard) + Local Mac (automation)"
  }
}