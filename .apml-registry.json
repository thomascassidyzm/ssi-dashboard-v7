{
  "version": "7.7.1",
  "generated_at": "2025-10-23T12:30:00.000Z",
  "apml_file": "ssi-course-production.apml",
  "phase_intelligence": {
    "status": "ACTIVE - Static file serving",
    "location": "docs/phase_intelligence/*.md",
    "access": "GET http://localhost:3456/phase-intelligence/:phase",
    "format": "Markdown text files",
    "modules": {
      "phase_1": {
        "file": "phase_1_seed_pairs.md",
        "output": "seed_pairs.json",
        "version": "1.0",
        "status": "active"
      },
      "phase_2": {
        "file": "phase_2_corpus_intelligence.md",
        "output": "phase_2_corpus_intelligence.json",
        "version": "1.0",
        "status": "active"
      },
      "phase_3": {
        "file": "phase_3_lego_pairs.md",
        "output": "lego_pairs.json",
        "version": "2.0",
        "status": "active"
      },
      "phase_3_5": {
        "file": "phase_3.5_lego_graph.md",
        "output": "phase_3.5_lego_graph.json",
        "version": "1.0",
        "status": "active"
      },
      "phase_5": {
        "file": "phase_5_lego_baskets.md",
        "output": "lego_baskets.json",
        "version": "1.0",
        "status": "active"
      },
      "phase_5_5": {
        "file": "phase_5.5_basket_deduplication.md",
        "output": "lego_baskets_deduplicated.json",
        "version": "1.0",
        "status": "active"
      },
      "phase_6": {
        "file": "phase_6_introductions.md",
        "output": "introductions.json",
        "version": "1.0",
        "status": "active"
      },
      "phase_7": {
        "file": "phase_7_compilation.md",
        "output": "course_manifest.json",
        "version": "1.0",
        "status": "active"
      },
      "phase_8": {
        "file": "phase_8_audio_generation.md",
        "output": "audio/*.mp3 (S3)",
        "version": "1.0",
        "status": "documented_for_kai_implementation",
        "branch": "feature/phase8-audio-generation",
        "assignee": "Kai"
      }
    },
    "workflow": [
      "1. Edit: docs/phase_intelligence/phase_X.md",
      "2. Commit: git commit -m 'Update phase X'",
      "3. Restart: pm2 restart automation-server",
      "4. Done: Agents fetch from /phase-intelligence/X"
    ]
  },
  "variable_registry": {
    "TOTAL_SEEDS": 668,
    "BATCH_SIZES": {
      "PHASE_1_TRANSLATION": 100,
      "PHASE_3_LEGO_DECOMPOSITION": 20,
      "PHASE_5_BASKETS": 20
    },
    "VFS_PATHS": {
      "BASE": "/Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses",
      "COURSE_FORMAT": "{target_code}_for_{known_code}_speakers"
    },
    "API_ENDPOINTS": {
      "COURSES_GENERATE": "/api/courses/generate",
      "COURSES_STATUS": "/api/courses/:courseCode/status",
      "COURSES_LIST": "/api/courses",
      "COURSES_GET": "/api/courses/:courseCode",
      "PROMPTS_GET": "/api/prompts/:phase",
      "PROMPTS_UPDATE": "/api/prompts/:phase",
      "PROMPTS_HISTORY": "/api/prompts/:phase/history",
      "PHASE_INTELLIGENCE": "/phase-intelligence/:phase"
    },
    "PHASE_PROMPTS": {
      "PHASE_1": {
        "phase": "1",
        "name": "Pedagogical Translation",
        "prompt": "# Phase 1: Pedagogical Translation\n\nTEST UPDATE - This is a test of the live prompt editing system.\n\nAll previous content maintained...\n\n  # Phase 1: Pedagogical Translation\n\n  ## Task\n  Apply 6 pedagogical heuristics to translate all 668 canonical concepts into BOTH target\n  and known languages, creating optimized learning material.\n\n  ## Input\n  - Canonical seeds: vfs/seeds/canonical_seeds.json (668 concepts expressed in English)\n  - Target language code (e.g., \"ita\" for Italian)\n  - Known language code (e.g., \"fra\" for French)\n\n  ## Critical Understanding\n\n  Canonical seeds are **NOT English content** - they are language-agnostic concepts that\n  happen to be expressed in English as a reference. You will translate each concept into:\n  1. TARGET language (the language being learned) - pedagogically optimized\n  2. KNOWN language (the learner's language) - structurally matched to target\n\n  Exception: If target or known IS English, reuse the canonical expression (no translation needed).\n\n  ## The Pedagogical Heuristics (Progressive Optimization Curve)\n\n  **CRITICAL**: Heuristic priority changes based on seed position!\n\n  ### SEEDS 1-100 (Beginner Phase - You are translating these!)\n  **Priority order for first 100 seeds:**\n\n  1. **COGNATE PREFERENCE** ‚≠ê - Maximize vocabulary similarity to known language\n     - Spanish: \"intentar\" (cognate) > \"tratar\" (not cognate)\n     - French: \"pratiquer\" (cognate) > \"s'entra√Æner\" (not cognate)\n     - Accept slightly less common word if it's a cognate\n     - BENEFIT: Reduces cognitive load, learner recognizes words faster\n\n  2. **VARIATION REDUCTION** ‚≠ê - Once you establish a mapping, stick with it!\n     - First seed needs \"to try\" ‚Üí Pick ONE verb (e.g., \"intentar\")\n     - ALL subsequent \"to try\" contexts ‚Üí Use SAME verb\n     - Maintain VOCABULARY REGISTRY as you translate:\n       * \"to try\" ‚Üí CLAIMED by \"intentar\" (S0002)\n       * \"to speak\" ‚Üí CLAIMED by \"hablar\" (S0001)\n       * \"to want\" ‚Üí CLAIMED by \"querer\" (S0001)\n     - Do NOT introduce synonyms in seeds 1-100\n     - EXCEPTION: Only when grammatically necessary (ser vs estar, savoir vs conna√Ætre)\n\n  3. **Consistency** - Reinforce same patterns and vocabulary repeatedly\n  4. **Clarity** - Clear, unambiguous expressions\n  5. **Utility** - Maximize teaching value\n  6. **Frequency** - De-prioritized (cognates trump frequency for beginners)\n  7. **Naturalness** - De-prioritized (patterns trump naturalness for beginners)\n  8. **Brevity** - Lowest priority\n\n  ### SEEDS 101-300 (Intermediate Phase - Not translating now)\n  Start introducing natural alternatives while maintaining established patterns\n\n  ### SEEDS 301-668 (Advanced Phase - Not translating now)\n  Full natural/idiomatic expressions, variation encouraged\n\n  ---\n\n  ## Detailed Heuristic Definitions\n\n  ### 1. COGNATE PREFERENCE (Your #1 priority for seeds 1-100)\n\n  **Definition:** Prefer vocabulary with similar form/sound to known language\n\n  **How to identify cognates:**\n  - Spanish/French/Italian for English: Look for Latin-derived words\n  - Words ending in -tion, -ci√≥n, -zione are usually cognates\n  - Words with similar roots (practice/practicar, important/importante)\n\n  **Examples by language:**\n\n  **Spanish for English:**\n  - ‚úÖ \"intentar\" (intend) > \"tratar\" (try)\n  - ‚úÖ \"practicar\" (practice) > \"entrenar\" (train)\n  - ‚úÖ \"importante\" (important) > \"relevante\" (relevant)\n  - ‚úÖ \"usar\" (use), even better \"utilizar\" (utilize)\n  - ‚úÖ \"continuar\" (continue) > \"seguir\" (continue)\n  - ‚úÖ \"explicar\" (explain) > \"aclarar\" (clarify)\n\n  **French for English:**\n  - ‚úÖ \"pratiquer\" (practice) > \"s'entra√Æner\" (train)\n  - ‚úÖ \"important\" > \"significatif\"\n  - ‚úÖ \"utiliser\" (utilize) > \"employer\" (use)\n  - ‚úÖ \"essayer\" (essay/assay) is acceptable\n  - ‚úÖ \"expliquer\" (explain) > \"clarifier\"\n  - ‚úÖ \"continuer\" (continue) > \"poursuivre\"\n\n  **Italian for English:**\n  - ‚úÖ \"importante\" > \"rilevante\"\n  - ‚úÖ \"praticare\" > \"allenarsi\"\n  - ‚úÖ \"usare\", even better \"utilizzare\"\n  - ‚úÖ \"continuare\" > \"proseguire\"\n  - ‚úÖ \"spiegare\" is OK (explain)\n\n  **Mandarin for English:**\n  - No cognates available\n  - Use SIMPLEST high-frequency characters instead\n  - ‚úÖ Single character > two-character compounds when possible\n  - ‚úÖ ËØ¥ (shu≈ç - speak) > ËÆ≤ËØù (ji«énghu√† - speak)\n  - ‚úÖ Â≠¶ (xu√© - learn) > Â≠¶‰π† (xu√©x√≠ - study)\n\n  ### 2. VARIATION REDUCTION (Your #2 priority for seeds 1-100)\n\n  **Definition:** Once you establish a mapping, stick with it - \"First Word Wins\"\n\n  **Process:**\n  As you translate seeds 1-100, maintain an internal VOCABULARY REGISTRY:\n\n  ```\n  VOCABULARY REGISTRY (build as you translate):\n  - \"to speak\" ‚Üí \"hablar\" (claimed in S0001)\n  - \"to want\" ‚Üí \"querer\" (claimed in S0001)\n  - \"to try\" ‚Üí \"intentar\" (claimed in S0002)\n  - \"to learn\" ‚Üí \"aprender\" (claimed in S0002)\n  - \"to practice\" ‚Üí \"practicar\" (claimed in S0005)\n  - \"to remember\" ‚Üí \"recordar\" (claimed in S0006)\n  - \"to explain\" ‚Üí \"explicar\" (claimed in S0008)\n  - ... continue building registry\n  ```\n\n  **Rules:**\n  1. When you encounter a new concept, pick the BEST cognate\n  2. Record it in your registry\n  3. ALL future occurrences of that concept ‚Üí use SAME word\n  4. Do NOT introduce synonyms, even if \"more natural\"\n\n  **Example - BAD (current overnight generation):**\n  ```\n  S0002: \"tratando\" = trying\n  S0007: \"intentar\" = to try\n  S0008: \"tratar\" = to try\n  ```\n  ‚ùå Learner confused: \"Which word should I use for 'try'?\"\n\n  **Example - GOOD (what you should generate):**\n  ```\n  S0002: \"intentando\" = trying (CLAIM: \"intentar\" for \"to try\")\n  S0007: \"intentar\" = to try (use claimed word)\n  S0008: \"intentar\" = to try (use claimed word)\n  ```\n  ‚úÖ Learner confident: \"'intentar' is THE word for try!\"\n\n  **EXCEPTION - Grammatically Required Variation:**\n  Some variation is unavoidable when grammar requires it:\n  - Spanish: \"ser\" vs \"estar\" (both \"to be\" but permanent vs temporary)\n  - French: \"savoir\" vs \"conna√Ætre\" (both \"to know\" but facts vs people)\n\n  In these cases, introduce BOTH but explain the distinction clearly in seed context.\n\n  ### 3-8. Other Heuristics (lower priority for seeds 1-100)\n\n  3. **Consistency** - Maintain consistent terminology across seeds\n  4. **Clarity** - Prioritize clear, unambiguous expressions\n  5. **Utility** - Maximize teaching value (versatile phrases, reusable structures)\n  6. **Frequency** - Prefer high-frequency vocabulary (but AFTER cognates)\n  7. **Naturalness** - Target should sound native (but AFTER cognates/consistency)\n  8. **Brevity** - Shorter translations preferred when equivalent\n\n  ## Your Mission\n\nFor each canonical concept (expressed in English as reference):\n\n1. **STEP 1: Canonical ‚Üí Target (Pedagogical Optimization)**\n   - Apply all 6 pedagogical heuristics\n   - Generate optimized target language translation\n   - Validate: Natural, high-frequency, clear, brief, consistent, useful\n\n2. **STEP 2: Target ‚Üí Known (Back-Translation)**\n   - Take the optimized target translation\n   - Translate to known language\n   - Ensure known translation MATCHES target structure\n   - Goal: Known ‚Üî Target alignment for better FD_LOOP\n\n3. **Generate Output**\n   - Store ALL translations in single consolidated file\n   - Format: { \"S0001\": [target, known], \"S0002\": [target, known], ... }\n   - File: vfs/courses/{course_code}/seed_pairs.json\n\nIMPORTANT: For courses where known=English (e.g., ita_for_eng):\n- Step 1 produces optimized target\n- Step 2 can reuse canonical English (it's already the known language)\n- But verify the English phrasing aligns with target structure\n\nFor courses where known‚â†English (e.g., ita_for_fra):\n- Step 1 produces optimized Italian\n- Step 2 MUST translate Italian ‚Üí French (NOT English ‚Üí French)\n- This ensures French mirrors Italian structure\n\n  ## Critical Rules\n  - Translations are NOT literal - they are pedagogically optimized\n  - Each translation is an immutable amino acid component\n  - UUIDs are content-based (deterministic)\n  - Preserve seed_id for provenance tracking\n\n  ## Example Translation\n  Seed S42: \"I would like to go\"\n  Literal: \"Hoffwn i fynd\"\n  Pedagogical: \"Dw i eisiau mynd\" (more natural, higher frequency, clearer for learners)\n\n  ## Success Criteria\n  ‚úì All 668 seeds translated\n  ‚úì All 6 heuristics applied to each\n  ‚úì Deterministic UUIDs generated\n  ‚úì Amino acids stored in VFS\n  ‚úì Provenance preserved (seed_id in each amino acid)"
      },
      "PHASE_2": {
        "phase": "2",
        "name": "Corpus Intelligence",
        "prompt": "# Phase 2: Corpus Intelligence\n\n  ## Task\n  Analyze translated corpus to determine FCFS (First-Can-First-Say) order and calculate utility scores.\n\n  ## Input\n  - Translation amino acids: vfs/amino_acids/translations/*.json\n\n  ## Your Mission\n  1. **FCFS Mapping** (First-Can-First-Say - Semantic Priority):\n     - Determine which words/LEGOs appear first in the teaching sequence\n     - The FIRST word to teach a concept CLAIMS that meaning as a BASE LEGO\n     - Later words with overlapping meanings must be taught in more specific contexts\n     - Example: If \"estoy\" = \"I am\" appears before \"soy\" = \"I am\", then:\n       * \"estoy\" claims \"I am\" as its BASE meaning\n       * \"soy\" must be taught differently (e.g., \"soy profesor\" = \"I am a teacher (permanent)\")\n     - Map semantic priority: which word gets to \"own\" each core meaning\n\n  2. **Utility Scoring**: Calculate pedagogical value\n     - Formula: Frequency √ó Versatility √ó Simplicity\n     - Frequency: How often used in corpus\n     - Versatility: How many contexts it appears in\n     - Simplicity: How easy to learn/teach\n\n  3. **Generate Intelligence Report**:\n     - FCFS rankings for all translations\n     - Utility scores (0-100 scale)\n     - Dependency maps\n     - Teaching sequence recommendations\n\n  ## Output Format\n  vfs/phase_outputs/phase_2_corpus_intelligence.json\n\n  {\n    \"fcfs_order\": [ ... ],\n    \"utility_scores\": { translation_uuid: score, ... },\n    \"dependencies\": { ... },\n    \"recommendations\": { ... }\n  }\n\n  ## Critical Notes\n  - FCFS = \"natural\" chronological sequence\n  - Utility may override FCFS for high-value opportunities\n  - This data drives Phase 3 LEGO extraction algorithm\n\n  ## Success Criteria\n  ‚úì FCFS order complete\n  ‚úì Utility scores calculated for all translations\n  ‚úì Dependency maps generated\n  ‚úì Ready for Phase 3 consumption"
      },
      "PHASE_3": {
        "phase": "3",
        "name": "LEGO Extraction",
        "prompt": "# Phase 3: LEGO Decomposition\n\n  Hi! I need help with Phase 3 of my language course project - LEGO decomposition.\n\n  Working with ${targetLang} for ${knownLang} speakers.\n\n  ## CORE PRINCIPLE\n  Break each SEED_PAIR into LEGO chunks that:\n  1. When placed side-by-side, EXACTLY reconstruct the original sentence\n  2. Each LEGO passes the FD_LOOP test independently\n  3. Are reusable across multiple sentences\n\n  ## LEGO TYPES & ARCHITECTURE\n\n  ### BASE LEGO (Simple/Atomic)\n  - Fundamental FD unit\n  - Cannot be broken down further\n  - Examples: \"Voglio\", \"parlare\", \"voy\", \"decir\"\n\n  ### COMPOSITE LEGO (Contains BASE + Glue)\n  - FD unit with BASE LEGOs + non-LEGO glue words\n  - BASE LEGOs DON'T TILE (can't concatenate directly)\n  - Examples:\n    - \"voy a decir\" (voy + a + decir) - \"a\" is glue\n    - \"sto per esercitarmi\" (sto + per + esercitarmi) - \"per\" is glue\n\n  ### FEEDERS\n  - BASE LEGOs within a COMPOSITE\n  - Stored separately with F## suffix\n  - Help learners understand COMPOSITE structure\n\n  ### TILING TEST\n  **Question**: Can you concatenate these LEGOs directly?\n\n  IF YES (TILES):\n  ‚Üí Keep as separate BASE LEGOs\n  Example: \"Voglio\" + \"parlare\" = \"Voglio parlare\" ‚úÖ\n\n  IF NO (DOESN'T TILE):\n  ‚Üí Create COMPOSITE LEGO + FEEDERs\n  Example: \"voy\" + \"decir\" ‚â† \"voy decir\" ‚ùå (need \"a\")\n  ‚Üí COMPOSITE: \"voy a decir\"\n  ‚Üí FEEDERs: \"voy\" (F01), \"decir\" (F02)\n\n  ## YOUR EXTRACTION PROCESS\n\n  For each seed:\n\n  1. Break into potential chunks\n  2. Validate each chunk is FD\n  3. Check if chunks contain multiple BASE LEGOs\n  4. Apply TILING TEST:\n     - TILES? ‚Üí Separate BASE LEGOs\n     - DOESN'T TILE? ‚Üí COMPOSITE LEGO + FEEDERs\n  5. Add componentization explanation (pedagogical)\n\n  ## MANDATORY UID FORMAT\n  For seed S0001:\n  - LEGOs: S0001L01, S0001L02, S0001L03\n  - FEEDERs: S0001F01, S0001F02 (sub-components of multi-word LEGOs)\n  NEVER use L0001 or F0001 (missing parent seed ID)\n\n  ## üîç FD_LOOP TEST (MANDATORY FOR EVERY CHUNK)\n  Target ‚Üí Known ‚Üí Target = MUST BE IDENTICAL\n  ‚úÖ \"importante\" ‚Üí \"important\" ‚Üí \"importante\" (IDENTICAL)\n  ‚ùå \"bien\" ‚Üí \"good\" ‚Üí \"bueno\" (DIFFERENT = FAIL)\n\n  ## üéØ FCFS RULE (First Come, First Served)\n  When multiple valid mappings exist, use corpus frequency to CLAIM semantic territory.\n\n  **UNIVERSAL PRINCIPLE**: Most frequent variant claims simple translation (if grammatically valid).\n  Less frequent variants must differentiate with context. Works for ANY language pair.\n\n  ### ARTISTIC CHOICE (flexible mapping allowed):\n  When multiple ${targetLang} words can express the same ${knownLang} meaning:\n  - Most frequent (15x) ‚Üí CLAIMS simple translation\n  - Less frequent (2x) ‚Üí must use more specific translation\n  - Once claimed, mapping is LOCKED for consistency\n\n  Example patterns:\n    - If \"word_A\" appears 15x ‚Üí claims simple meaning\n    - If \"word_B\" appears 2x ‚Üí must differentiate (e.g., add intensity/formality)\n\n  ### GRAMMATICAL CONSTRAINT (NO flexibility):\n  When ${targetLang} grammar makes distinctions that ${knownLang} doesn't:\n  ‚Üí LEGOs MUST preserve that distinction with context\n  ‚Üí NEVER create ambiguous mappings\n  ‚Üí Use CHUNK UP principle to include disambiguating context\n\n  Common patterns to watch for:\n    - Formal/informal distinctions (Spanish t√∫/usted, German du/Sie, French tu/vous)\n    - Permanent/temporary states (Spanish ser/estar)\n    - Aspect markers (Mandarin ‰∫Ü/Âú®/Ëøá, Slavic perfective/imperfective)\n    - Honorific levels (Japanese plain/polite/humble, Korean Ìï¥Ïöî/Ìï©ÎãàÎã§)\n    - Gender agreement (Romance languages, German, Slavic)\n\n  **CRITICAL**: If ${targetLang} has grammatical distinctions, CHUNK UP to preserve them!\n\n  ‚úÖ RIGHT: Include context that disambiguates\n  ‚ùå WRONG: Collapse distinctions into generic translation\n\n  ### FCFS PROCESS:\n  1. Count frequency of each mapping across ALL corpus seeds\n  2. Most frequent CLAIMS simple mapping (if grammatically valid)\n  3. Less frequent must ADD context to differentiate\n  4. If corpus edit needed to maintain FD, NOTE it for SEED_PAIR revision\n\n  ## üö´ AUTOMATIC REJECTION LIST\n  **Function Words (ALWAYS FAIL FD):**\n  - Articles: el/la/los/las, un/una (gender ambiguous)\n  - Pronouns: le/lo/la (multiple meanings)\n  - Prepositions: en (in/on/at), de (of/from/about), por/para\n  - \"que\" (that/what/which) - context dependent\n\n  **Multi-meaning words WITHOUT grammar constraints:**\n  - \"bien\" ‚Üí well/good/fine (use FCFS to claim primary meaning)\n  - \"muy\" ‚Üí very/really (use FCFS for intensity)\n\n  ## ‚úÖ DUAL-PASS METHODOLOGY\n\n  ### PASS 1: Forward Analysis (${targetLang} ‚Üí ${knownLang})\n  1. Start with first word of ${targetLang} sentence\n  2. Test for FD compliance using FD_LOOP\n  3. If fails, expand to include next word\n  4. Continue until FD passes or sentence complete\n  5. Move to next unmapped word\n\n  ### PASS 2: Reverse Validation (${knownLang} ‚Üí ${targetLang})\n  1. Take each ${knownLang} chunk\n  2. Verify it maps back to EXACT ${targetLang} chunk\n  3. If different ‚Üí REJECT and re-decompose\n\n  ### PASS 3: Corpus-Wide Validation\n  For EVERY chunk, search ALL other SEED_PAIRS in batch:\n  - Find every occurrence of this chunk\n  - Count frequency of each mapping\n  - Apply FCFS: most frequent claims simple mapping\n  - Less frequent must differentiate with context\n  - If conflicts cannot be resolved ‚Üí FLAG for SEED_PAIR revision\n\n  ### PASS 4: SEED_PAIR Revision Notes\n  If decomposition reveals FD conflicts:\n  - Note which SEED_PAIRS need editing\n  - Suggest specific changes to maintain FD\n  - Example: \"I want coffee\" might need ‚Üí \"I'd like coffee\" if \"quiero\" is claimed\n\n  ## üìù COMPONENTIZATION REQUIREMENT (BOTH languages must be multi-word!)\n  COMPONENTIZATION is ONLY needed when BOTH target AND known are multi-word:\n  - ‚úÖ REQUIRED: \"parlare italiano\" ‚Üî \"parler italien\" (BOTH are 2 words)\n  - ‚úÖ REQUIRED: \"para su hermana\" ‚Üî \"for his sister\" (BOTH are 3 words)\n  - ‚ùå NOT NEEDED: \"construir\" ‚Üî \"build\" (both single words)\n  - ‚ùå NOT NEEDED: \"una nueva vida\" ‚Üî \"a new life\" (even though multi-word, simple 1:1 mapping)\n\n  FORMAT: Simple word mappings ONLY (no grammar explanations):\n  \"[known LEGO] = [target LEGO], where [target1] = [known1] and [target2] = [known2]\"\n\n  ‚ö†Ô∏è CRITICAL: Write ALL componentization in ${knownLang}, NOT English!\n  - French speakers: Use French words like \"o√π\" (not \"where\"), \"et\" (not \"and\")\n  - Spanish speakers: Use Spanish words like \"donde\" (not \"where\"), \"y\" (not \"and\")\n  - Chinese speakers: Use Chinese: \"ÂÖ∂‰∏≠\" (not \"where\"), \"Âíå\" (not \"and\")\n\n  Example for ${knownLang} speakers:\n  French: \"parler italien = parlare italiano, o√π parlare = parler et italiano = italien\"\n  Spanish: \"hablar italiano = parlare italiano, donde parlare = hablar y italiano = italiano\"\n  NOT: \"parler italien = parlare italiano, where parlare = parler and italiano = italien\" ‚ùå\n\n  ## THE IRON RULE (ABSOLUTE)\n  **No LEGO begins or ends with a STANDALONE preposition.**\n\n  **CRITICAL CLARIFICATION - Prepositional Phrases**:\n  - Standalone prepositions WITHOUT objects: ‚ùå FORBIDDEN\n  - Complete prepositional phrases WITH objects: ‚úÖ ALLOWED\n\n  **ALLOWED (Complete prepositional phrases)**:\n  - ‚úÖ \"con te\" / \"with you\" (complete prepositional phrase)\n  - ‚úÖ \"con me\" / \"with me\" (complete prepositional phrase)\n  - ‚úÖ \"in italiano\" / \"in Italian\" (complete prepositional phrase)\n  - ‚úÖ \"avec tous\" / \"with everyone\" (complete prepositional phrase)\n\n  **NOT ALLOWED (Standalone prepositions)**:\n  - ‚ùå \"con\" / \"with\" (standalone preposition)\n  - ‚ùå \"in\" / \"in\" (standalone preposition)\n  - ‚ùå \"per\" / \"to\" (standalone preposition)\n  - ‚ùå \"de\" / \"of\" (standalone preposition)\n\n  **INFINITIVE MARKER CLARIFICATION**:\n  - The infinitive marker \"to\" (as in \"to speak\") is NOT a preposition\n  - It is a grammatical marker that forms part of the infinitive verb\n  - Full infinitives like \"to speak\", \"to learn\" are ALLOWED and FD-compliant\n  - Bare infinitives are NOT FD (conflict with commands and conjugations)\n\n  **Examples**:\n  - ‚úÖ \"to speak\" / \"parlare\" (infinitive marker + verb)\n  - ‚úÖ \"to learn\" / \"imparare\" (infinitive marker + verb)\n  - ‚ùå \"to the\" / \"al\" (directional preposition - needs object!)\n\n  **PRINCIPLE**: Prepositional phrases are complete, meaningful, FD-compliant units.\n              The issue is orphaned prepositions without objects.\n\n  **NON-NEGOTIABLE**: No standalone prepositions at LEGO boundaries\n\n  ## THE ELISION RULE (ABSOLUTE)\n  **Never split after an elided word (apostrophe) without including the following word.**\n\n  **ELISION PATTERNS** (vary by language):\n  Romance languages commonly use elision where vowels are dropped before another vowel:\n  - French: d', l', n', s', t', qu', m', c', j' (de, le, ne, se, te, que, me, ce, je)\n  - Italian: d', l', un', all', dell', sull', nell' (di, lo/la, uno/una, alla, della, sulla, nella)\n  - Spanish: (less common, but exists in contractions like \"del\" = de + el)\n  - Catalan: d', l', n', s', t', m' (similar to French)\n\n  **THE PROBLEM**:\n  Elided words are grammatically incomplete - they MUST attach to the following word.\n  - ‚ùå \"d'\" alone means nothing - it's an incomplete preposition\n  - ‚ùå \"l'\" alone means nothing - it's an incomplete article\n  - ‚úÖ \"d'expliquer\" / \"to explain\" - complete meaningful unit\n  - ‚úÖ \"l'italiano\" / \"the Italian\" - complete meaningful unit\n\n  **CRITICAL RULE**: NEVER create a LEGO that ends with an apostrophe!\n\n  **EXAMPLES OF VIOLATIONS (DO NOT DO THIS)**:\n  - ‚ùå \"Je vais essayer d'\" / \"I'm going to try to\" (d' is orphaned)\n  - ‚ùå \"Voglio parlare l'\" / \"I want to speak the\" (l' is orphaned)\n  - ‚ùå \"Je n'\" / \"I don't\" (n' is orphaned)\n\n  **EXAMPLES OF CORRECT HANDLING**:\n  - ‚úÖ \"Je vais essayer d'expliquer\" / \"I'm going to try to explain\" (d' attached to expliquer)\n  - ‚úÖ \"Voglio parlare l'italiano\" / \"I want to speak Italian\" (l' attached to italiano)\n  - ‚úÖ \"Je n'aime pas\" / \"I don't like\" (n' attached to aime)\n\n  **TILING WITH ELISIONS**:\n  When you encounter elisions, apply the TILING TEST to the COMPLETE phrase (with elision + following word):\n\n  Example: \"Je vais essayer d'expliquer\"\n  1. Can we tile \"Je vais essayer\" + \"d'expliquer\"? ‚Üí Check if concatenation works\n  2. NO ‚Üí They don't tile (missing \"d'\"), so create COMPOSITE:\n     - COMPOSITE: \"Je vais essayer d'expliquer\" / \"I'm going to try to explain\"\n     - FEEDERs: \"Je vais\" (I'm going), \"essayer\" (to try), \"expliquer\" (to explain)\n\n  **DETECTION STRATEGY**:\n  1. Scan target language text for apostrophes (')\n  2. If apostrophe found, check if it's at end of current chunk\n  3. If yes ‚Üí EXTEND chunk to include next word\n  4. Then apply FD_LOOP test to extended chunk\n\n  **LANGUAGE-SPECIFIC GUIDANCE**:\n  - **French**: Very common - watch for d', l', n', s', t', qu', m', j', c'\n  - **Italian**: Common - watch for d', l', un', all', dell', sull', nell'\n  - **Spanish**: Rare - mostly in contractions (del, al) which are written as single words\n  - **English**: Contractions like \"I'm\", \"don't\", \"can't\" ‚Üí treat as single words (already FD-compliant)\n  - **Other languages**: Check for similar vowel elision patterns\n\n  **NON-NEGOTIABLE**: No LEGO may end with an apostrophe indicating elision\n\n  ## INPUT DATA\n  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/\n\n  Read ALL SEED_PAIRS from:\n  SEED_PAIRS_COMPLETE.json (contains all 668 seeds)\n\n  The files contain JSON with structure:\n  {\n    \"seed_pairs\": [\n      {\n        \"seed_id\": \"S0001\",\n        \"target\": \"[sentence in ${targetLang}]\",\n        \"known\": \"[sentence in ${knownLang}]\"\n      }\n    ]\n  }\n\n  ## OUTPUT FILES\n  Save to course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/\n\n  1. Process in batches of 20 seeds:\n     - LEGO_BREAKDOWNS_BATCH_001.json (seeds 1-20)\n     - LEGO_BREAKDOWNS_BATCH_002.json (seeds 21-40)\n     - etc.\n\n  2. ALSO create combined file with ALL breakdowns:\n     - LEGO_BREAKDOWNS_COMPLETE.json (all seeds combined)\n\n  Create this exact structure for each file:\n  {\n    \"phase\": \"LEGO_BREAKDOWNS\",\n    \"batch\": \"001\",\n    \"target_language\": \"${targetLang}\",\n    \"known_language\": \"${knownLang}\",\n    \"lego_breakdowns\": [\n      // For EACH seed_pair in the input file:\n      {\n        \"seed_id\": \"S0001\",\n        \"canonical_id\": \"C0001\",\n        \"original_target\": \"actual ${targetLang} sentence\",\n        \"original_known\": \"actual ${knownLang} sentence\",\n        \"lego_pairs\": [\n          // Break into FD-compliant chunks\n        ],\n        \"feeder_pairs\": [\n          // Sub-components of multi-word LEGOs\n        ],\n        \"componentization\": [\n          // ONLY when BOTH target AND known are multi-word!\n          // Simple mappings format: known = target, where word1 = word1 and word2 = word2\n          {\n            \"lego_id\": \"S0001L02\",\n            \"explanation\": \"[known LEGO] = [target LEGO], where [word1] = [word1] and [word2] = [word2]\"\n          }\n          // Skip if either side is single word or if it's a simple 1:1 mapping\n        ]\n      }\n    ]\n  }\n\n  ## CRITICAL OUTPUT RULES\n  - **SILENT OPERATION** - Work quietly, save to file\n  - **NO PRINTING** - Don't display breakdowns\n  - **VFS ONLY** - Save to VFS only, no console output\n\n  Start decomposing immediately."
      },
      "PHASE_3_5": {
        "phase": "3.5",
        "name": "Graph Construction",
        "prompt": "# Phase 3.5: Graph Construction (NEW in v7.0)\n\n  ## Task\n  Build directed graph of LEGO adjacency relationships to enable pattern-aware basket construction.\n\n  ## Input\n  - LEGO amino acids: vfs/amino_acids/legos/*.json\n  - Translation amino acids: vfs/amino_acids/translations/*.json (for co-occurrence analysis)\n\n  ## Your Mission\n  1. **Detect Adjacency Patterns**:\n     - Scan source translations to find which LEGOs appear adjacent to each other\n     - Example: In \"Dw i eisiau mynd\", LEGOs \"Dw i\" and \"eisiau\" are adjacent\n\n  2. **Build Directed Graph**:\n     - Nodes: All LEGO amino acids\n     - Edges: LEGO_A ‚Üí LEGO_B (A precedes B in corpus)\n     - Direction matters (A‚ÜíB ‚â† B‚ÜíA)\n\n  3. **Calculate Edge Weights**:\n     - Weight = co-occurrence frequency √ó pedagogical value\n     - Higher weight = more important pattern to teach\n\n  4. **Validate Graph**:\n     - Ensure graph is connected\n     - Check for invalid cycles\n     - Verify all LEGOs represented\n\n  5. **Export Graph Structure**:\n     - Adjacency list format\n     - Include edge weights\n     - Store metadata (total nodes, edges, density)\n\n  ## Output Format\n  vfs/phase_outputs/phase_3.5_lego_graph.json\n\n  {\n    \"nodes\": [ ... ],\n    \"edges\": [\n      { \"from\": \"uuid_A\", \"to\": \"uuid_B\", \"weight\": 42 },\n      ...\n    ],\n    \"metadata\": { ... }\n  }\n\n  ## Critical Notes\n  - This is NEW in APML v7.0 - graph intelligence!\n  - Phase 5 uses this graph for pattern coverage optimization\n  - Edges represent legitimate LEGO sequence patterns\n  - Replaces old DEBUT/ETERNAL pattern logic\n\n  ## Success Criteria\n  ‚úì All LEGO adjacencies mapped\n  ‚úì Directed edges created\n  ‚úì Edge weights calculated\n  ‚úì Graph validated (connected, no invalid cycles)\n  ‚úì Ready for Phase 5 consumption"
      },
      "PHASE_5": {
        "phase": "5",
        "name": "Basket Generation with Graph Intelligence and Progressive Vocabulary",
        "prompt": "# Phase 5: Basket Generation - Graph Intelligence + Progressive Vocabulary\n\n  ## TWO-STAGE PROCESS\n\n  ### STAGE 1: Basket Selection (Graph-Driven)\n\n  **Goal**: Select LEGO groupings that maximize pattern diversity\n\n  1. **Load Graph Intelligence**:\n     - Read: vfs/phase_outputs/phase_3.5_lego_graph.json\n     - Adjacency graph showing which LEGOs appear near each other\n     - Edge weights indicate co-occurrence frequency\n\n  2. **Load FCFS Ordering**:\n     - Read: vfs/phase_outputs/phase_2_corpus_intelligence.json\n     - Chronological ordering from corpus frequency analysis\n     - Ensures pedagogically sound sequence\n\n  3. **Select LEGOs for Each Basket** (20 LEGOs per basket):\n     - Maximize edge coverage (expose diverse patterns)\n     - Follow FCFS chronological progression\n     - Avoid redundant LEGO sequences across baskets\n     - Ensure smooth difficulty progression\n     - Balance novelty with reinforcement\n\n  **Output of Stage 1**: Ordered list of LEGOs to process\n\n  ### STAGE 2: Phrase Generation (Vocabulary-Constrained)\n\n  **Goal**: Generate d-phrases and e-phrases for each selected LEGO\n\n  ## CRITICAL PER-LEGO VOCABULARY CONSTRAINTS\n  **ABSOLUTE RULE**: Each LEGO has DIFFERENT available vocabulary!\n  - LEGO #1: NO VOCABULARY AVAILABLE = NO PHRASES POSSIBLE (empty basket)\n  - LEGO #2: Can only use LEGO #1 = VERY LIMITED phrases possible\n  - LEGO #3: Can only use LEGOs #1-2 = A FEW phrases possible\n  - LEGO #N: Can only use LEGOs #1 through #(N-1)\n\n  ## Input Data\n  Course folder: /Users/tomcassidy/SSi/SSi_Course_Production/vfs/courses/${targetCode}_for_${knownCode}_speakers/\n\n  Read LEGOs from: vfs/courses/{course_code}/LEGO_BREAKDOWNS_COMPLETE.json\n\n  **CRITICAL: Extract ALL LEGOs from two sources:**\n\n  1. **lego_pairs[]** - Both BASE and COMPOSITE LEGOs from Phase 3\n     ```javascript\n     for (const seed of legoBreakdowns.lego_breakdowns) {\n       for (const lego of seed.lego_pairs) {\n         allLegos.push({\n           lego_id: lego.lego_id,\n           target_chunk: lego.target_chunk,\n           known_chunk: lego.known_chunk,\n           seed_id: seed.seed_id\n         });\n       }\n     }\n     ```\n\n  2. **feeder_pairs[]** - Atomic components of COMPOSITE LEGOs (THESE ARE LEGOS TOO!)\n     ```javascript\n     for (const seed of legoBreakdowns.lego_breakdowns) {\n       for (const feeder of seed.feeder_pairs || []) {\n         allLegos.push({\n           lego_id: feeder.feeder_id,  // Note: feeder_id, not lego_id\n           target_chunk: feeder.target_chunk,\n           known_chunk: feeder.known_chunk,\n           seed_id: seed.seed_id,\n           parent_lego_id: feeder.parent_lego_id  // Track which COMPOSITE this feeds\n         });\n       }\n     }\n     ```\n\n  **WHY process feeder_pairs:**\n  - A feeder might introduce NEW vocabulary not yet seen (needs its own basket)\n  - A feeder might be a DUPLICATE of an existing LEGO (Phase 5.5 dedup handles this)\n  - We can't know which without processing ALL of them\n  - Phase 5.5 deduplication will remove duplicate baskets, keeping first occurrence\n\n  **Total LEGOs to process:**\n  - Spanish: ~115 (89 lego_pairs + 26 feeder_pairs)\n  - Italian: ~115 (90 lego_pairs + 25 feeder_pairs)\n  - French: ~116 (90 lego_pairs + 26 feeder_pairs)\n  - Mandarin: ~103 (92 lego_pairs + 11 feeder_pairs)\n\n  ## E-PHRASES (5 Eternal Practice Phrases per LEGO)\n\n  ## E-PHRASE CRITICAL REQUIREMENTS (NON-NEGOTIABLE)\n\n  ### Length Requirements (ABSOLUTE)\n  - **MINIMUM**: 7 words in target language\n  - **IDEAL**: 10 words in target language\n  - **MAXIMUM**: 15 words (hard cap)\n  - Short e-phrases (< 7 words) are a CRITICAL FAILURE\n  - Better to have NO e-phrase than a short/clunky one\n\n  ### Quality Requirements (ABSOLUTE)\n  - QUALITY > QUANTITY: Do not force bad phrases to hit a count\n  - E-phrases must be NATURAL and conversational in BOTH languages\n  - If vocabulary is insufficient for quality 10-word phrase, skip it\n  - Aim for 3-5 excellent e-phrases per basket (not forced to 5)\n\n  ### Target Language Grammar (UNFORGIVEABLE ERRORS)\n  ‚ö†Ô∏è **POOR SYNTAX IN TARGET LANGUAGE IS UNFORGIVEABLE** ‚ö†Ô∏è\n\n  For Italian specifically:\n  - \"cercare\" + infinitive REQUIRES \"di\": \"cercando di parlare\" NOT \"cercando parlare\"\n  - \"imparare\" + infinitive REQUIRES \"a\": \"imparando a parlare\" NOT \"imparando parlare\"\n  - \"provare\" + infinitive REQUIRES \"a\": \"provando a dire\" NOT \"provando dire\"\n  - \"continuare\" + infinitive REQUIRES \"a\": \"continuando a parlare\" NOT \"continuando parlare\"\n  - \"finire\" + infinitive REQUIRES \"di\": \"finendo di parlare\" NOT \"finendo parlare\"\n\n  **VALIDATE EVERY E-PHRASE**:\n  - Is the target language grammar PERFECT?\n  - Would a native speaker say this naturally?\n  - Are all required prepositions present?\n\n  If you cannot ensure perfect target language grammar, DO NOT include the phrase.\n\n  ---\n\n  Create 5 phrases, each 7-10 words (balanced across 7/8/9/10):\n  - **MUST contain the target LEGO**\n  - **Perfect grammar** in BOTH languages - validate target AND known language\n  - **Natural, conversational** - things people actually say in BOTH languages\n  - **Smooth pronunciation** - not clunky or awkward in either language\n  - **Variety in position** - LEGO at different positions in phrase\n  - **BILINGUAL VALIDATION**: Each phrase must be:\n    - Grammatically correct in target language\n    - Grammatically correct in known language\n    - Semantically meaningful in BOTH languages\n    - Natural and idiomatic in BOTH cultures\n\n  ### CRITICAL RULE - CULMINATING LEGOs (ABSOLUTE REQUIREMENT)\n\n  **Definition**: A \"culminating LEGO\" is the LAST LEGO in a seed's decomposition\n\n  **How to identify**:\n  - Check the LEGO's seed_id (e.g., S0005L02)\n  - Look up the seed in Phase 3 LEGO breakdown\n  - If this is the highest L-number for that seed ‚Üí it's culminating\n\n  **ABSOLUTE RULE**:\n  - **E-phrase #1 MUST be the COMPLETE SEED sentence itself**\n  - Not a variation, not similar - the EXACT seed sentence\n  - This complete seed MUST also appear 3+ times in D-phrases\n\n  **Example**:\n  - Seed S0005: \"Sto per esercitarmi a parlare\"\n  - LEGOs: S0005L01 (sto per) + S0005L02 (esercitarmi a parlare)\n  - S0005L02 is culminating (last LEGO)\n  - Therefore: S0005L02 basket MUST have E-phrase #1 = \"Sto per esercitarmi a parlare\"\n\n  **Validation**:\n  - Before finalizing basket, check if LEGO is culminating\n  - If yes, verify E-phrase #1 is complete seed\n  - If not, regenerate basket\n\n  ## VOCABULARY SELECTION (Recency Guidelines - for LEGOs 50+)\n  **For early LEGOs (1-50):** Use whatever vocabulary is available - there's not enough yet for recency preferences.\n\n  **For later LEGOs (50+):** When building E-phrases, PREFER recent vocabulary:\n  - ~50% of vocabulary from recent seeds (N-5 to N-1)\n  - ~25% from medium-recent (N-20 to N-1)\n  - ~25% from all earlier seeds\n\n  BUT ALWAYS PRIORITIZE natural, useful phrases over strict percentages.\n\n  ## D-PHRASES (Auto-Generated Debuts)\n\n  ### D-PHRASE QUALITY ALLOWANCE\n\n  **Important**: D-phrases CAN be somewhat clunky or fragment-like\n  - They are expanding windows from e-phrases (2-lego, 3-lego, 4-lego, 5-lego)\n  - Syntactic correctness required, but naturalness is less critical\n  - Focus: Help learners build up to full e-phrases gradually\n\n  **Contrast with E-phrases**:\n  - E-phrases: MUST be natural, conversational, perfect grammar\n  - D-phrases: Can be awkward fragments as long as syntax is correct\n\n  ---\n\n  You will generate D-phrases using expanding window from E-phrases:\n  - 2x 2-LEGO phrases\n  - 2x 3-LEGO phrases\n  - 2x 4-LEGO phrases\n  - 2x 5-LEGO phrases\n  ALL 5 E-phrases must contribute to D-phrases (variety is key).\n\n  **CRITICAL RULE: OPERATIVE LEGO MUST BE PRESENT**\n  - EVERY d-phrase MUST contain the operative LEGO (the LEGO this basket teaches)\n  - Example: If basket is for \"Quiero\" (S0001L01), ALL d-phrases must contain \"Quiero\"\n  - You CANNOT extract arbitrary contiguous windows - only windows containing the operative LEGO\n\n  **CORRECT EXTRACTION (Basket for \"Quiero\"):**\n    E-phrase: \"Quiero hablar espa√±ol contigo ahora\"\n    - 2-LEGO: \"Quiero hablar\" ‚úÖ (contains \"Quiero\")\n    - 3-LEGO: \"Quiero hablar espa√±ol\" ‚úÖ (contains \"Quiero\")\n    - 4-LEGO: \"Quiero hablar espa√±ol contigo\" ‚úÖ (contains \"Quiero\")\n\n  **INCORRECT EXTRACTION (Basket for \"Quiero\"):**\n    - 2-LEGO: \"hablar espa√±ol\" ‚ùå (missing \"Quiero\")\n    - 3-LEGO: \"espa√±ol contigo ahora\" ‚ùå (missing \"Quiero\")\n\n  **BILINGUAL SYNTAX RULES FOR D-PHRASES:**\n  - D-phrases can be fragments (don't need to be complete sentences)\n  - BUT they MUST be syntactically correct as far as they go in BOTH languages\n  - Examples:\n    - ‚úÖ \"quiero hablar\" / \"I want to speak\" (fragment but correct in both)\n    - ‚úÖ \"espa√±ol contigo\" / \"Spanish with you\" (fragment but correct in both)\n    - ‚ùå \"quiero de\" / \"I want of\" (syntactically broken in both)\n    - ‚ùå \"hablar yo\" / \"speak I\" (wrong word order in both)\n  - Always validate BOTH the target AND known language versions\n\n  **For CULMINATING LEGOs:** Use the complete seed (E1) in at least:\n  - 1x in 2-LEGO phrases\n  - 1x in 3-LEGO phrases\n  - 1x in 4 or 5-LEGO phrases\n  This reinforces the complete seed understanding!\n\n  ## VALIDATION REQUIREMENTS\n  1. For EACH LEGO's basket:\n     - If NO valid phrases can be made: Output {\"e_phrases\": [], \"d_phrases\": {}}\n     - If only 1-2 phrases possible: Use what's available, don't force 5 phrases\n     - EVERY word MUST come from the available vocabulary list\n\n  2. NEVER use:\n     - Words from LEGOs that haven't been learned yet\n     - Words not in a LEGO (no \"y\", \"de\", \"el\" unless they're in a LEGO)\n     - Made-up words to fill space\n\n  3. Expected pattern for early LEGOs:\n     - LEGO #1: NO PHRASES POSSIBLE (empty basket)\n     - LEGO #2: Maybe 1 meaningful combination if semantically valid\n     - LEGO #3: 1-3 phrases depending on semantic validity\n     - Only after ~10-15 LEGOs will you have enough vocabulary for D-phrases\n     - Only after ~50-100 LEGOs will you have enough vocabulary for full E-phrase baskets\n\n  4. SEMANTIC VALIDITY RULES:\n     - All phrases must be grammatically AND semantically correct in BOTH languages\n     - Consider actual language usage and meaning\n     - Validate each combination for real-world meaningfulness\n\n  ## Output Format\n  Save to: vfs/courses/{course_code}/lego_baskets.json\n\n  **IMPORTANT: Use BOTH lego_id AND feeder_id as keys**\n\n  {\n    \"S0001L01\": {\n      \"lego\": [\"Quiero\", \"I want\"],\n      \"e\": [\n        [\"Quiero hablar espa√±ol.\", \"I want to speak Spanish.\"],\n        [\"Quiero practicar contigo ahora.\", \"I want to practice with you now.\"],\n        [\"No quiero adivinar.\", \"I don't want to guess.\"],\n        [\"Quiero recordar esto.\", \"I want to remember this.\"],\n        [\"Quiero intentar hablar m√°s.\", \"I want to try to speak more.\"]\n      ],\n      \"d\": {\n        \"2\": [[\"Quiero hablar\", \"I want to speak\"], [\"hablar espa√±ol\", \"to speak Spanish\"]],\n        \"3\": [[\"Quiero hablar espa√±ol\", \"I want to speak Spanish\"], [\"No quiero hablar\", \"I don't want to speak\"]],\n        \"4\": [[\"No quiero hablar ahora\", \"I don't want to speak now\"], ...],\n        \"5\": [[\"Quiero hablar espa√±ol contigo ahora\", \"I want to speak Spanish with you now\"], ...]\n      }\n    },\n    \"S0001L02\": { ... },\n    \"S0015F01\": {\n      \"lego\": [\"parler\", \"to speak\"],\n      \"e\": [\n        [\"Je veux parler fran√ßais maintenant avec toi ici.\", \"I want to speak French now with you here.\"],\n        [\"Parler fran√ßais est important pour moi aujourd'hui.\", \"Speaking French is important to me today.\"]\n      ],\n      \"d\": {\n        \"2\": [[\"veux parler\", \"want to speak\"], [\"parler fran√ßais\", \"to speak French\"]],\n        \"3\": [[\"veux parler fran√ßais\", \"want to speak French\"], ...],\n        \"4\": [...],\n        \"5\": [...]\n      }\n    }\n  }\n\n  Format: { \"lego_id_or_feeder_id\": { lego: [target, known], e: [[t,k]...], d: {window_size: [[t,k]...]} } }\n\n  **Key naming rules:**\n  - Regular LEGOs use lego_id format: \"S0001L01\", \"S0001L02\", etc.\n  - Feeder LEGOs use feeder_id format: \"S0015F01\", \"S0015F02\", etc.\n  - Both are treated identically during basket generation\n  - Phase 5.5 deduplication will remove duplicates (e.g., if S0015F01 duplicates S0001L02)\n\n  Notes:\n  - LEGO field contains the core teaching unit itself\n  - \"e\" array contains e-phrases (7-10 words, natural conversational phrases)\n  - \"d\" object contains d-phrases organized by window size (\"2\", \"3\", \"4\", \"5\")\n  - Window size refers to number of LEGOs combined in the phrase\n  - All phrases are [target, known] pairs\n\n  ## Success Criteria\n\n  **Stage 1 (Extraction):**\n  ‚úì All lego_pairs[] extracted and processed\n  ‚úì All feeder_pairs[] extracted and processed (CRITICAL - don't miss these!)\n  ‚úì Both types use correct ID field (lego_id vs feeder_id)\n  ‚úì Total LEGO count matches expected: lego_pairs + feeder_pairs\n\n  **Stage 2 (Generation):**\n  ‚úì Every LEGO has d-phrases and e-phrases (even if empty for early LEGOs)\n  ‚úì All vocabulary constraints respected\n  ‚úì E-phrases are natural and conversational in BOTH languages\n  ‚úì D-phrases are syntactically correct in BOTH languages\n  ‚úì Culminating LEGOs include complete seed as E-phrase #1\n  ‚úì Progressive difficulty from LEGO #1 to last LEGO\n\n  **Combined Result:**\n  ‚úì Baskets generated for ALL LEGOs (both lego_pairs and feeder_pairs)\n  ‚úì Basket count = lego_pairs count + feeder_pairs count (before deduplication)\n  ‚úì Spanish: ~115 baskets, Italian: ~115, French: ~116, Mandarin: ~103\n  ‚úì Pedagogical soundness through vocabulary constraints\n  ‚úì Optimal learning sequence with rich practice"
      },
      "PHASE_5_5": {
        "phase": "5.5",
        "name": "Basket Deduplication",
        "prompt": "# Phase 6: Introductions\n\n  ## Task\n  Generate known-only introduction phrases for each basket to prime learners with zero unknowns.\n\n  ## Input\n  - Basket amino acids: vfs/amino_acids/baskets/*.json\n  - Deduplicated LEGOs: vfs/amino_acids/legos_deduplicated/*.json\n\n  ## Your Mission\n  For each basket:\n  1. **Identify Known LEGOs**:\n     - Scan ALL previous baskets (baskets 1 to N-1)\n     - Compile complete inventory of LEGOs learner has mastered\n     - These are the ONLY LEGOs you can use\n\n  2. **Generate Introduction Phrases**:\n     - Create warm-up phrases using ONLY known LEGOs\n     - ZERO unknown vocabulary or structures\n     - Goal: Activate prior knowledge, build confidence\n     - Prepare learner for new basket content\n\n  3. **Validate Known-Only Rule**:\n     - Double-check: NO new LEGOs in introductions\n     - Every word/phrase must be from known set\n     - Absolute rule - no exceptions\n\n  4. **Create Introduction Amino Acids**:\n     - Deterministic UUID based on content + basket reference\n     - Store: vfs/amino_acids/introductions/{uuid}.json\n\n  ## Introduction Amino Acid Structure\n  {\n    \"uuid\": \"...\",\n    \"basket_uuid\": \"...\",\n    \"phrases\": [\"phrase1\", \"phrase2\", ...],\n    \"known_legos_used\": [\"uuid1\", \"uuid2\", ...],\n    \"validation\": {\n      \"all_known\": true,\n      \"unknown_count\": 0\n    }\n  }\n\n  ## Why This Matters\n  - Reduces cognitive load before new learning\n  - Builds learner confidence (100% comprehension)\n  - Primes brain for new content\n  - Creates smooth entry point to each basket\n\n  ## CRITICAL RULE\n  **ZERO unknown elements allowed in introductions.**\n  If you're unsure, DON'T use it.\n\n  ## Success Criteria\n  ‚úì Introduction generated for each basket\n  ‚úì All LEGOs verified as \"known\" from previous baskets\n  ‚úì Zero unknown elements (validated)\n  ‚úì Introduction amino acids stored\n  ‚úì Course ready for final compilation"
      }
    }
  },
  "system": {
    "name": "SSi Course Production System",
    "description": "Self-improving language course generation with recursive intelligence evolution",
    "architecture": "Vue3 + Node.js + Claude Code (Sonnet 4.5)",
    "deployment": "Vercel (dashboard) + Local Mac (automation)"
  }
}